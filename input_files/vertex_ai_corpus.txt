Informatica® Cloud Application Integration
April 2025

Google Vertex AI Connector
Guide

Informatica Cloud Application Integration Google Vertex AI Connector Guide
April 2025
© Copyright Informatica LLC 2024, 2025

This software and documentation contain proprietary information of Informatica LLC and are provided under a license agreement containing restrictions on use and
disclosure and are also protected by copyright law. Reverse engineering of the software is prohibited. No part of this document may be reproduced or transmitted in any
form, by any means (electronic, photocopying, recording or otherwise) without prior consent of Informatica LLC. This Software may be protected by U.S. and/or
international Patents and other Patents Pending.
Use, duplication, or disclosure of the Software by the U.S. Government is subject to the restrictions set forth in the applicable software license agreement and as
provided in DFARS 227.7202-1(a) and 227.7702-3(a) (1995), DFARS 252.227-7013©(1)(ii) (OCT 1988), FAR 12.212(a) (1995), FAR 52.227-19, or FAR 52.227-14 (ALT III),
as applicable.
The information in this product or documentation is subject to change without notice. If you find any problems in this product or documentation, please report them to
us in writing.
Informatica, Informatica Platform, Informatica Data Services, PowerCenter, PowerCenterRT, PowerCenter Connect, PowerCenter Data Analyzer, PowerExchange,
PowerMart, Metadata Manager, Informatica Data Quality, Informatica Data Explorer, Informatica B2B Data Transformation, Informatica B2B Data Exchange Informatica
On Demand, Informatica Identity Resolution, Informatica Application Information Lifecycle Management, Informatica Complex Event Processing, Ultra Messaging,
Informatica Master Data Management, and Live Data Map are trademarks or registered trademarks of Informatica LLC in the United States and in jurisdictions
throughout the world. All other company and product names may be trade names or trademarks of their respective owners.
Portions of this software and/or documentation are subject to copyright held by third parties, including without limitation: Copyright DataDirect Technologies. All rights
reserved. Copyright © Sun Microsystems. All rights reserved. Copyright © RSA Security Inc. All Rights Reserved. Copyright © Ordinal Technology Corp. All rights
reserved. Copyright © Aandacht c.v. All rights reserved. Copyright Genivia, Inc. All rights reserved. Copyright Isomorphic Software. All rights reserved. Copyright © Meta
Integration Technology, Inc. All rights reserved. Copyright © Intalio. All rights reserved. Copyright © Oracle. All rights reserved. Copyright © Adobe Systems Incorporated.
All rights reserved. Copyright © DataArt, Inc. All rights reserved. Copyright © ComponentSource. All rights reserved. Copyright © Microsoft Corporation. All rights
reserved. Copyright © Rogue Wave Software, Inc. All rights reserved. Copyright © Teradata Corporation. All rights reserved. Copyright © Yahoo! Inc. All rights reserved.
Copyright © Glyph & Cog, LLC. All rights reserved. Copyright © Thinkmap, Inc. All rights reserved. Copyright © Clearpace Software Limited. All rights reserved. Copyright
© Information Builders, Inc. All rights reserved. Copyright © OSS Nokalva, Inc. All rights reserved. Copyright Edifecs, Inc. All rights reserved. Copyright Cleo
Communications, Inc. All rights reserved. Copyright © International Organization for Standardization 1986. All rights reserved. Copyright © ej-technologies GmbH. All
rights reserved. Copyright © Jaspersoft Corporation. All rights reserved. Copyright © International Business Machines Corporation. All rights reserved. Copyright ©
yWorks GmbH. All rights reserved. Copyright © Lucent Technologies. All rights reserved. Copyright © University of Toronto. All rights reserved. Copyright © Daniel
Veillard. All rights reserved. Copyright © Unicode, Inc. Copyright IBM Corp. All rights reserved. Copyright © MicroQuill Software Publishing, Inc. All rights reserved.
Copyright © PassMark Software Pty Ltd. All rights reserved. Copyright © LogiXML, Inc. All rights reserved. Copyright © 2003-2010 Lorenzi Davide, All rights reserved.
Copyright © Red Hat, Inc. All rights reserved. Copyright © The Board of Trustees of the Leland Stanford Junior University. All rights reserved. Copyright © EMC
Corporation. All rights reserved. Copyright © Flexera Software. All rights reserved. Copyright © Jinfonet Software. All rights reserved. Copyright © Apple Inc. All rights
reserved. Copyright © Telerik Inc. All rights reserved. Copyright © BEA Systems. All rights reserved. Copyright © PDFlib GmbH. All rights reserved. Copyright ©
Orientation in Objects GmbH. All rights reserved. Copyright © Tanuki Software, Ltd. All rights reserved. Copyright © Ricebridge. All rights reserved. Copyright © Sencha,
Inc. All rights reserved. Copyright © Scalable Systems, Inc. All rights reserved. Copyright © jQWidgets. All rights reserved. Copyright © Tableau Software, Inc. All rights
reserved. Copyright© MaxMind, Inc. All Rights Reserved. Copyright © TMate Software s.r.o. All rights reserved. Copyright © MapR Technologies Inc. All rights reserved.
Copyright © Amazon Corporate LLC. All rights reserved. Copyright © Highsoft. All rights reserved. Copyright © Python Software Foundation. All rights reserved.
Copyright © BeOpen.com. All rights reserved. Copyright © CNRI. All rights reserved.
This product includes software developed by the Apache Software Foundation (http://www.apache.org/), and/or other software which is licensed under various
versions of the Apache License (the "License"). You may obtain a copy of these Licenses at http://www.apache.org/licenses/. Unless required by applicable law or
agreed to in writing, software distributed under these Licenses is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
or implied. See the Licenses for the specific language governing permissions and limitations under the Licenses.
This product includes software which was developed by Mozilla (http://www.mozilla.org/), software copyright The JBoss Group, LLC, all rights reserved; software
copyright © 1999-2006 by Bruno Lowagie and Paulo Soares and other software which is licensed under various versions of the GNU Lesser General Public License
Agreement, which may be found at http:// www.gnu.org/licenses/lgpl.html. The materials are provided free of charge by Informatica, "as-is", without warranty of any
kind, either express or implied, including but not limited to the implied warranties of merchantability and fitness for a particular purpose.
The product includes ACE(TM) and TAO(TM) software copyrighted by Douglas C. Schmidt and his research group at Washington University, University of California,
Irvine, and Vanderbilt University, Copyright (©) 1993-2006, all rights reserved.
This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit (copyright The OpenSSL Project. All Rights Reserved) and
redistribution of this software is subject to terms available at http://www.openssl.org and http://www.openssl.org/source/license.html.
This product includes Curl software which is Copyright 1996-2013, Daniel Stenberg, <daniel@haxx.se>. All Rights Reserved. Permissions and limitations regarding this
software are subject to terms available at http://curl.haxx.se/docs/copyright.html. Permission to use, copy, modify, and distribute this software for any purpose with or
without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.
The product includes software copyright 2001-2005 (©) MetaStuff, Ltd. All Rights Reserved. Permissions and limitations regarding this software are subject to terms
available at http://www.dom4j.org/ license.html.
The product includes software copyright © 2004-2007, The Dojo Foundation. All Rights Reserved. Permissions and limitations regarding this software are subject to
terms available at http://dojotoolkit.org/license.
This product includes ICU software which is copyright International Business Machines Corporation and others. All rights reserved. Permissions and limitations
regarding this software are subject to terms available at http://source.icu-project.org/repos/icu/icu/trunk/license.html.
This product includes software copyright © 1996-2006 Per Bothner. All rights reserved. Your right to use such materials is set forth in the license which may be found at
http:// www.gnu.org/software/ kawa/Software-License.html.
This product includes OSSP UUID software which is Copyright © 2002 Ralf S. Engelschall, Copyright © 2002 The OSSP Project Copyright © 2002 Cable & Wireless
Deutschland. Permissions and limitations regarding this software are subject to terms available at http://www.opensource.org/licenses/mit-license.php.
This product includes software developed by Boost (http://www.boost.org/) or under the Boost software license. Permissions and limitations regarding this software
are subject to terms available at http:/ /www.boost.org/LICENSE_1_0.txt.
This product includes software copyright © 1997-2007 University of Cambridge. Permissions and limitations regarding this software are subject to terms available at
http:// www.pcre.org/license.txt.
This product includes software copyright © 2007 The Eclipse Foundation. All Rights Reserved. Permissions and limitations regarding this software are subject to terms
available at http:// www.eclipse.org/org/documents/epl-v10.php and at http://www.eclipse.org/org/documents/edl-v10.php.

This product includes software licensed under the terms at http://www.tcl.tk/software/tcltk/license.html, http://www.bosrup.com/web/overlib/?License, http://
www.stlport.org/doc/ license.html, http://asm.ow2.org/license.html, http://www.cryptix.org/LICENSE.TXT, http://hsqldb.org/web/hsqlLicense.html, http://
httpunit.sourceforge.net/doc/ license.html, http://jung.sourceforge.net/license.txt , http://www.gzip.org/zlib/zlib_license.html, http://www.openldap.org/software/
release/license.html, http://www.libssh2.org, http://slf4j.org/license.html, http://www.sente.ch/software/OpenSourceLicense.html, http://fusesource.com/downloads/
license-agreements/fuse-message-broker-v-5-3- license-agreement; http://antlr.org/license.html; http://aopalliance.sourceforge.net/; http://www.bouncycastle.org/
licence.html; http://www.jgraph.com/jgraphdownload.html; http://www.jcraft.com/jsch/LICENSE.txt; http://jotm.objectweb.org/bsd_license.html; . http://www.w3.org/
Consortium/Legal/2002/copyright-software-20021231; http://www.slf4j.org/license.html; http://nanoxml.sourceforge.net/orig/copyright.html; http://www.json.org/
license.html; http://forge.ow2.org/projects/javaservice/, http://www.postgresql.org/about/licence.html, http://www.sqlite.org/copyright.html, http://www.tcl.tk/
software/tcltk/license.html, http://www.jaxen.org/faq.html, http://www.jdom.org/docs/faq.html, http://www.slf4j.org/license.html; http://www.iodbc.org/dataspace/
iodbc/wiki/iODBC/License; http://www.keplerproject.org/md5/license.html; http://www.toedter.com/en/jcalendar/license.html; http://www.edankert.com/bounce/
index.html; http://www.net-snmp.org/about/license.html; http://www.openmdx.org/#FAQ; http://www.php.net/license/3_01.txt; http://srp.stanford.edu/license.txt;
http://www.schneier.com/blowfish.html; http://www.jmock.org/license.html; http://xsom.java.net; http://benalman.com/about/license/; https://github.com/CreateJS/
EaselJS/blob/master/src/easeljs/display/Bitmap.js; http://www.h2database.com/html/license.html#summary; http://jsoncpp.sourceforge.net/LICENSE; http://
jdbc.postgresql.org/license.html; http://protobuf.googlecode.com/svn/trunk/src/google/protobuf/descriptor.proto; https://github.com/rantav/hector/blob/master/
LICENSE; http://web.mit.edu/Kerberos/krb5-current/doc/mitK5license.html; http://jibx.sourceforge.net/jibx-license.html; https://github.com/lyokato/libgeohash/blob/
master/LICENSE; https://github.com/hjiang/jsonxx/blob/master/LICENSE; https://code.google.com/p/lz4/; https://github.com/jedisct1/libsodium/blob/master/
LICENSE; http://one-jar.sourceforge.net/index.php?page=documents&file=license; https://github.com/EsotericSoftware/kryo/blob/master/license.txt; http://www.scalalang.org/license.html; https://github.com/tinkerpop/blueprints/blob/master/LICENSE.txt; http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/
intro.html; https://aws.amazon.com/asl/; https://github.com/twbs/bootstrap/blob/master/LICENSE; https://sourceforge.net/p/xmlunit/code/HEAD/tree/trunk/
LICENSE.txt; https://github.com/documentcloud/underscore-contrib/blob/master/LICENSE, and https://github.com/apache/hbase/blob/master/LICENSE.txt.
This product includes software licensed under the Academic Free License (http://www.opensource.org/licenses/afl-3.0.php), the Common Development and
Distribution License (http://www.opensource.org/licenses/cddl1.php) the Common Public License (http://www.opensource.org/licenses/cpl1.0.php), the Sun Binary
Code License Agreement Supplemental License Terms, the BSD License (http:// www.opensource.org/licenses/bsd-license.php), the new BSD License (http://
opensource.org/licenses/BSD-3-Clause), the MIT License (http://www.opensource.org/licenses/mit-license.php), the Artistic License (http://www.opensource.org/
licenses/artistic-license-1.0) and the Initial Developer’s Public License Version 1.0 (http://www.firebirdsql.org/en/initial-developer-s-public-license-version-1-0/).
This product includes software copyright © 2003-2006 Joe WaInes, 2006-2007 XStream Committers. All rights reserved. Permissions and limitations regarding this
software are subject to terms available at http://xstream.codehaus.org/license.html. This product includes software developed by the Indiana University Extreme! Lab.
For further information please visit http://www.extreme.indiana.edu/.
This product includes software Copyright (c) 2013 Frank Balluffi and Markus Moeller. All rights reserved. Permissions and limitations regarding this software are subject
to terms of the MIT license.
See patents at https://www.informatica.com/legal/patents.html.
DISCLAIMER: Informatica LLC provides this documentation "as is" without warranty of any kind, either express or implied, including, but not limited to, the implied
warranties of noninfringement, merchantability, or use for a particular purpose. Informatica LLC does not warrant that this software or documentation is error free. The
information provided in this software or documentation may include technical inaccuracies or typographical errors. The information in this software and documentation
is subject to change at any time without notice.
NOTICES
This Informatica product (the "Software") includes certain drivers (the "DataDirect Drivers") from DataDirect Technologies, an operating company of Progress Software
Corporation ("DataDirect") which are subject to the following terms and conditions:
1. THE DATADIRECT DRIVERS ARE PROVIDED "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
2. IN NO EVENT WILL DATADIRECT OR ITS THIRD PARTY SUPPLIERS BE LIABLE TO THE END-USER CUSTOMER FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, CONSEQUENTIAL OR OTHER DAMAGES ARISING OUT OF THE USE OF THE ODBC DRIVERS, WHETHER OR NOT INFORMED OF THE POSSIBILITIES
OF DAMAGES IN ADVANCE. THESE LIMITATIONS APPLY TO ALL CAUSES OF ACTION, INCLUDING, WITHOUT LIMITATION, BREACH OF CONTRACT, BREACH
OF WARRANTY, NEGLIGENCE, STRICT LIABILITY, MISREPRESENTATION AND OTHER TORTS.
Publication Date: 2025-04-03

Table of Contents
Preface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
Chapter 1: Introduction to Google Vertex AI Connector. . . . . . . . . . . . . . . . . . . . . . . . 6
Google Vertex AI overview. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

Chapter 2: Google Vertex AI connections. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
Basic connection properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
Google Vertex AI connection properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
Google Vertex AI connection metadata. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
Publishing Google Vertex AI connections. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
Using a Google Vertex AI connection in a process. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

4

Table of Contents

Preface
Read the Google Vertex AI Connector Guide to learn how to set up and use Google Vertex AI connections. This
guide assumes that you have an understanding of the Google Vertex AI concepts.

5

Chapter 1

Introduction to Google Vertex AI
Connector
Use Google Vertex AI Connector to easily integrate Vertex AI with various data sources and tools, increasing
the functionality and reach of your machine learning workflows.
You can use Google Vertex AI Connector to achieve use cases, such as data ingestion, feature engineering,
model training and validation, and business intelligence integration.
Google Vertex AI Connector provides the following key features:
•

Streamlines the flow of data between Vertex AI and other Google Cloud services, such as BigQuery,
Google Cloud Storage, and Dataproc, allowing for seamless data management and processing.

•

Enables Vertex AI to connect with external data sources, enhancing the ability to build and train models on
diverse datasets.

•

Provides a smooth data integration experience, reducing the manual workload of moving and preparing
data for machine learning tasks.

•

Supports live data streams, ensuring that models can be trained and updated with the latest information.

•

Facilitates automated workflows by integrating with other tools, helping to streamline model development,
deployment, and monitoring processes.

•

Provides a unified interface to access various data sources and manage machine learning (ML)
workflows.

•

Ensures secure data handling and compliance with industry standards when working with sensitive
information.

Google Vertex AI overview
Google Vertex AI is a managed machine learning platform provided by Google Cloud that enables users to
build, deploy, and scale machine learning models. It is designed to streamline the development and
deployment of ML models. Vertex AI combines Google Cloud’s powerful services into a unified environment.
Google Vertex AI provides the following key features:

6

•

Provides a single interface to manage all stages of the ML workflow, including data preprocessing, model
training, verification, deployment, and monitoring.

•

Includes access to pre-trained APIs for common tasks, such as image analysis and text processing.

•

Supports custom model development using frameworks, such as TensorFlow, PyTorch, and Scikit-learn. It
simplifies the training process with a managed infrastructure.

•

Offers tools for managing model operations (MLOps) to automate and streamline the deployment, scaling,
and maintenance of models.

•

Vertex AI's AutoML feature automates the model training process, enabling users with minimal ML
expertise to build models effectively.

•

Provides scalable compute resources, allowing models to be trained and deployed on an infrastructure
that automatically scales according to demand.

•

Simplifies versioning, deployment, and monitoring of models, ensuring that they perform as expected in
production environments.

•

Offers tools to understand model predictions and eliminate possible issues.

•

Integrates with other Google Cloud services and supports collaboration.

Google Vertex AI overview

7

Chapter 2

Google Vertex AI connections
Use a Google Vertex AI connection to integrate with various data sources and services, and build
comprehensive and flexible machine learning workflows.
You can perform various actions, such as generating content, function calling, grounding, text embeddings,
and multimodal embeddings using the access token and model ID.
After you create a Google Vertex AI connection, you can validate, test, and save the connection.
You can then publish the Google Vertex AI connection and click the Metadata tab to view the generated
process objects for the connection.

Basic connection properties
The following table describes the basic properties that you can configure on the Properties tab of the
connection creation page:
Property

Description

Name

Required. Unique name for the Google Vertex AI connection that identifies it in the Process
Designer. The name must start with an alphabet and can contain only alphabets, numbers, and
hyphens (-).

Location

The location of the project or folder where you want to save the connection. Click Browse to
select a location.
If the Explore page is currently active and a project or folder is selected, the default location for
the connection is the selected project or folder. Otherwise, the default location is the location of
the most recently saved asset.

Description

Optional. Description of the connection.

Type

Required. The type of connection you want to use for the connector or service connector.
Select Google Vertex AI.

8

Runtime
Environment

Required. The runtime environment for the connection. You can run the connection on the Cloud
Server, a Secure Agent group, or a Secure Agent machine.

Connection Test

Not supported for Google Vertex AI Connector.

OData-Enabled

Not supported for Google Vertex AI Connector.

Google Vertex AI connection properties
To use Google Vertex AI, you need the project ID and private key to access the service account.
The following table defines the Google Vertex AI connection properties that you must configure in the
Connection Properties section:
Property

Description

Project_ID

The project ID to generate a valid access token.

Location

The region to process the request.

Private_Key_ID

The private key ID associated with the service account.

Client_Email

The email address associated with the service account.

Private_Key

The Google Vertex AI private key associated with the service account. Enter the PKCS1 certificate as
a Base64-encoded string in the following format:
-----BEGIN PRIVATE KEY----- ..... n-----END PRIVATE KEY-----

Google Vertex AI connection metadata
After you create a Google Vertex AI connection, you can validate and save the connection. You can then
publish the Google Vertex AI connection and click the Metadata tab to view the generated process objects for
the connection.
When you publish a Google Vertex AI connection in Application Integration, the Actions and Objects appear
on the Metadata tab.
The following image shows the Metadata tab for a published Google Vertex AI connection:

Google Vertex AI connection properties

9

Publishing Google Vertex AI connections
When you publish a Google Vertex AI connection in Application Integration, the Actions and Objects appear
on the Metadata tab.
Consider the following information when you use specific actions and objects:
•

The Generate content action generates a response from the model based on the given input. It creates a
requestBody that contains fields with different types, such as string or array.
You must insert the access_token field from the Get access token action and the model_ID field to call the
model, and create a payload. For example, the model_ID value can be gemini-1.5-flash-001 or
gemini-1.5-pro-001.
The following snippet is a sample to build a requestBody object:
<root>
<contents>
<role>user</role>
<parts>
<text>Describe what you hear in this audio</text>
</parts>
<parts>
<inlineData>
<mimeType>audio/aac</mimeType>
<data>{BASE64ENCODED}</data>
</inlineData>
</parts>
</contents>
<generationConfig>
<temperature>0.5</temperature>
<maxOutputTokens>200</maxOutputTokens>
<topP>0.8</topP>
<topK>10</topK>

10

Chapter 2: Google Vertex AI connections

</generationConfig>
</root>
If fields in the requestBody need to be in different formats, you must add additional namespaces as
shown in the following sample code:
<root xmlns:m="urn:informatica:ae:xquery:json2xml:meta-data">
<field_array m:isArray="true">
<property_1> ...</property_1>
</field_array>
<field_boolean m:type="xs:boolean">true</field_boolean>
<field_double m:type="xs:double">20.2</field_double>
<field_integer m:type="xs:int">10</field_integer>
</root>
•

The Function calling action generates a response from the model based on the given input with the
Function Calling API.
You must insert the access_token field from the Get access token action and the model_ID field to call the
model, and create a payload. For example, the model_ID value can be gemini-1.5-flash-001 or
gemini-1.5-pro-001.
The following snippet is a sample to build a requestBody object:
<root xmlns:m="urn:informatica:ae:xquery:json2xml:meta-data">
<contents>
<role>user</role>
<parts>
<text>What is the weather in Boston, MA?</text>
</parts>
</contents>
<tools>
<functionDeclarations>
<name>get_current_weather</name>
<description>Get the current weather in a given location</description>
<parameters>
<type>object</type>
<properties>
<location>
<type>string</type>
<description>The city and state, e.g. San Francisco, CA or a
zip code e.g. 95616</description>
</location>
</properties>
<required m:isArray="true">location</required>
</parameters>
</functionDeclarations>
</tools>
</root>
If fields in the requestBody need to be in different formats, you must add additional namespaces as
shown in the following sample code:
<root xmlns:m="urn:informatica:ae:xquery:json2xml:meta-data">
<field_array m:isArray="true">
<property_1> ...</property_1>
</field_array>
<field_boolean m:type="xs:boolean">true</field_boolean>
<field_double m:type="xs:double">20.2</field_double>
<field_integer m:type="xs:int">10</field_integer>
</root>

•

The Grounding action generates a response from the model based on the given input and connects the
model output to verifiable sources of information.
You must insert the access_token field from the Get access token action and the model_ID field to call the
model, and create a payload. For example, the model_ID value can be gemini-1.5-flash-001 or
gemini-1.5-pro-001.

Publishing Google Vertex AI connections

11

The following snippet is a sample to build a requestBody object:
<root>
<contents>
<role>user</role>
<parts>
<text>Can you provide the latest information on climate change's impact
on polar bears?</text>
</parts>
</contents>
<tools>
<googleSearchRetrieval />
</tools>
</root>
If fields in the requestBody need to be in different formats, you must add additional namespaces as
shown in the following sample code:
<root xmlns:m="urn:informatica:ae:xquery:json2xml:meta-data">
<field_array m:isArray="true">
<property_1> ...</property_1>
</field_array>
<field_boolean m:type="xs:boolean">true</field_boolean>
<field_double m:type="xs:double">20.2</field_double>
<field_integer m:type="xs:int">10</field_integer>
</root>
•

The Text embeddings action generates an embedding from the model based on the given input.
You must insert the access_token field from the Get access token action and the model_ID field to call the
model, and create a payload. For example, the model_ID value can be textembedding-geckomultilingual@001 or text-multilingual-embedding-002.
The following snippet is a sample to build a requestBody object:
<root>
<instances>
<task_type>RETRIEVAL_DOCUMENT</task_type>
<title>document title</title>
<content>I would like embeddings for this text!</content>
</instances>
</root>
If fields in the requestBody need to be in different formats, you must add additional namespaces as
shown in the following sample code:
<root xmlns:m="urn:informatica:ae:xquery:json2xml:meta-data">
<field_array m:isArray="true">
<property_1> ...</property_1>
</field_array>
<field_boolean m:type="xs:boolean">true</field_boolean>
<field_double m:type="xs:double">20.2</field_double>
<field_integer m:type="xs:int">10</field_integer>
</root>

•

The Multimodal embeddings action generates an embedding from the model based on the given input,
which can include a combination of image, text, and video data.
You must insert the access_token field from the Get access token action and the model_ID field to call the
model, and create a payload. For example, the model_ID value can be multimodalembedding@001.
The following snippet is a sample to build a requestBody object:
<root>
<instances>
<text>Describe what you see</text>
<video>
<bytesBase64Encoded>{BASE64ENCODED}</bytesBase64Encoded>
<videoSegmentConfig>
<endOffsetSec>1</endOffsetSec>
</videoSegmentConfig>
</video>
<parameters>

12

Chapter 2: Google Vertex AI connections

<dimension>1536</dimension>
</parameters>
</instances>
</root>
If fields in the requestBody need to be in different formats, you must add additional namespaces as
shown in the following sample code:
<root xmlns:m="urn:informatica:ae:xquery:json2xml:meta-data">
<field_array m:isArray="true">
<property_1> ...</property_1>
</field_array>
<field_boolean m:type="xs:boolean">true</field_boolean>
<field_double m:type="xs:double">20.2</field_double>
<field_integer m:type="xs:int">10</field_integer>
</root>

Using a Google Vertex AI connection in a process
After you create a Google Vertex AI connection, you can use it in a Service step in a process.
1.

Add a Service step to the process.

2.

Click the Service tab.

3.

From the Service Type list, select Connection.

4.

From the Connection list, browse and select the Google Vertex AI connection that you created.

5.

From the Action list, select the action that you want to perform. For example, select the Generate
content action to generate a response from the model based on the given input as shown in the
following image:

In this case, Application Integration populates the access_token, model_ID, and requestBody objects
under the input fields and response under the output fields.
6.

Configure further steps as needed.

7.

Validate, save, and publish the process.

Using a Google Vertex AI connection in a process

13

02/10/2025, 16:10

Topics

What is Retrieval-Augmented Generation (RAG)? | Google Cloud

RAG

What is Retrieval-Augmented Generation
(RAG)?
RAG (Retrieval-Augmented Generation) is an AI framework that combines the
strengths of traditional information retrieval systems (such as search and
databases) with the capabilities of generative large language models (LLMs).
By combining your data and world knowledge with LLM language skills,
grounded generation is more accurate, up-to-date, and relevant to your
specific needs. Check out this ebook to unlock your “Enterprise Truth.”
Get started for free

35:30
Grounding for Gemini with Vertex AI Search and DIY RAG

How does Retrieval-Augmented Generation work?
RAGs operate with a few main steps to help enhance generative AI outputs:

https://cloud.google.com/use-cases/retrieval-augmented-generation

1/7

02/10/2025, 16:10

What is Retrieval-Augmented Generation (RAG)? | Google Cloud

Retrieval and pre-processing: RAGs leverage powerful search
algorithms to query external data, such as web pages, knowledge bases,
and databases. Once retrieved, the relevant information undergoes preprocessing, including tokenization, stemming, and removal of stop words.
Grounded generation: The pre-processed retrieved information is then
seamlessly incorporated into the pre-trained LLM. This integration
enhances the LLM's context, providing it with a more comprehensive
understanding of the topic. This augmented context enables the LLM to
generate more precise, informative, and engaging responses.

Why use RAG?
RAG offers several advantages augmenting traditional methods of text
generation, especially when dealing with factual information or data-driven
responses. Here are some key reasons why using RAG can be beneficial:

Access to fresh information
LLMs are limited to their pre-trained data. This leads to outdated and
potentially inaccurate responses. RAG overcomes this by providing up-to-date
information to LLMs.

Factual grounding
LLMs are powerful tools for generating creative and engaging text, but they
can sometimes struggle with factual accuracy. This is because LLMs are
trained on massive amounts of text data, which may contain inaccuracies or
biases.
Providing “facts” to the LLM as part of the input prompt can mitigate “gen AI
hallucinations.” The crux of this approach is ensuring that the most relevant
facts are provided to the LLM, and that the LLM output is entirely grounded on
those facts while also answering the user’s question and adhering to system
instructions and safety constraints.

https://cloud.google.com/use-cases/retrieval-augmented-generation

2/7

02/10/2025, 16:10

What is Retrieval-Augmented Generation (RAG)? | Google Cloud

Using Gemini’s long context window (LCW) is a great way to provide source
materials to the LLM. If you need to provide more information than fits into the
LCW, or if you need to scale up performance, you can use a RAG approach
that will reduce the number of tokens, saving you time and cost.

Search with vector databases and relevancy re-rankers
RAGs usually retrieve facts via search, and modern search engines now
leverage vector databases to efficiently retrieve relevant documents. Vector
databases store documents as embeddings in a high-dimensional space,
allowing for fast and accurate retrieval based on semantic similarity. Multimodal embeddings can be used for images, audio and video, and more and
these media embeddings can be retrieved alongside text embeddings or
multi-language embeddings.
Advanced search engines like Vertex AI Search use semantic search and
keyword search together (called hybrid search), and a re-ranker which scores
search results to ensure the top returned results are the most
relevant. Additionally searches perform better with a clear, focused query
without misspellings; so prior to lookup, sophisticated search engines will
transform a query and fix spelling mistakes.

Relevance, accuracy, and quality
The retrieval mechanism in RAG is critically important. You need the best
semantic search on top of a curated knowledge base to ensure that the
retrieved information is relevant to the input query or context. If your retrieved
information is irrelevant, your generation could be grounded but off-topic or
incorrect.
By fine-tuning or prompt-engineering the LLM to generate text entirely based
on the retrieved knowledge, RAG helps to minimize contradictions and
inconsistencies in the generated text. This significantly improves the quality of
the generated text, and improves the user experience.
The Vertex Eval Service now scores LLM generated text and retrieved chunks
on metrics like “coherence,” “fluency,” “groundedness,” "safety,"
“instruction_following,” “question_answering_quality,” and more. These
https://cloud.google.com/use-cases/retrieval-augmented-generation

3/7

02/10/2025, 16:10

What is Retrieval-Augmented Generation (RAG)? | Google Cloud

metrics help you measure the grounded text you get from the LLM (for some
metrics that is a comparison to a ground truth answer you have
provided). Implementing these evaluations gives you a baseline measurement
and you can optimize for RAG quality by configuring your search engine,
curating your source data, improving source layout parsing or chunking
strategies, or refining the user’s question prior to search. A RAG Ops, metrics
driven approach like this will help you hill climb to high quality RAG and
grounded generation.

RAGs, agents, and chatbots
RAG and grounding can be integrated into any LLM application or agent which
needs access to fresh, private, or specialized data. By accessing external
information, RAG-powered chatbots and conversational agents leverage
external knowledge to provide more comprehensive, informative, and contextaware responses, improving the overall user experience.
Your data and your use case are what differentiate what you are building with
gen AI. RAG and grounding bring your data to LLMs efficiently and scalably.

What Google Cloud products and services are related to
RAG?
The following Google Cloud products are related to Retrieval-Augmented Generation:

Vertex AI RAG Engine
Data framework for developing context-augmented LLM applications, and
facilitates retrieval-augmented generation (RAG.)

https://cloud.google.com/use-cases/retrieval-augmented-generation

4/7

02/10/2025, 16:10

What is Retrieval-Augmented Generation (RAG)? | Google Cloud

Vertex AI Search
Vertex AI Search is Google Search for your data, a fully managed, out-of-thebox search and RAG builder.

Vertex AI Vector Search
The ultra performant vector index that powers Vertex AI Search; it enables
semantic and hybrid search and retrieval from huge collections of embeddings
with high recall at high query rate.

BigQuery
Large datasets that you can use to train machine learning models, including
models for Vertex AI Vector Search.

Grounded Generation API
https://cloud.google.com/use-cases/retrieval-augmented-generation

5/7

02/10/2025, 16:10

What is Retrieval-Augmented Generation (RAG)? | Google Cloud

Gemini high-fidelity mode grounded with Google Search or inline facts or bring
your own search engine.

AlloyDB AI
Run models in Vertex AI and access them in your application using familiar SQL
queries. Use Google models, such as Gemini, or your own custom models.

Further reading
Learn more about using retrieval augmented generation with these resources.
Using Vertex AI to build next-gen search applications
RAGs powered by Google Search technology
RAG with databases on Google Cloud
APIs to build your own search and Retrieval Augmented Generation (RAG)
systems
How to use RAG in BigQuery to bolster LLMs
Code sample and quickstart to get familiar with RAG
Infrastructure for a RAG-capable generative AI application using Vertex AI
and Vector Search
Infrastructure for a RAG-capable generative AI application using Vertex AI
and AlloyDB for PostgreSQL
Infrastructure for a RAG-capable generative AI application using GKE

Take the next step
Start building on Google Cloud with $300 in free credits and 20+ always free
products.
https://cloud.google.com/use-cases/retrieval-augmented-generation

6/7

02/10/2025, 16:10

What is Retrieval-Augmented Generation (RAG)? | Google Cloud

Get started for free

Need help getting started?
Contact sales
Work with a trusted partner
Find a partner
Continue browsing
See all products

https://cloud.google.com/use-cases/retrieval-augmented-generation

7/7

﻿9 Min Read
What Is Vertex AI? Features, Uses, and Benefits
Learn all about Vertex AI, a Google Cloud tool for building generative AI solutions. Discover its features, how to use it, and its benefits.


What Is Vertex AI? Features, Uses, and Benefits
The Upwork Team
Published


May 12, 2025
Share:
What Is Vertex AI? Features, Uses, and Benefits
Google’s Vertex AI is Google Cloud’s unified platform for building, deploying, and scaling machine learning (ML) and artificial intelligence (AI) models. It supports custom model training, AutoML, and foundation models—offering tools for data preparation, model monitoring, MLOps, and real-time inference within one end-to-end system.


As AI adoption accelerates across industries, more teams are looking for tools that simplify complex machine learning workflows and bring models to production faster. That’s where Vertex AI comes in. Whether you're building AI-powered chatbots, predictive analytics models, or generative AI applications, Vertex AI gives you the infrastructure and flexibility to get there—without managing compute resources or stitching together multiple platforms.


Built for both beginners and experienced data scientists, Vertex AI supports a wide range of frameworks, including TensorFlow, PyTorch, and open-source models. Its fully managed services reduce setup time and help teams focus on what matters most: delivering high-quality AI solutions that scale.


What is Vertex AI?
Vertex AI is a unified machine learning platform used for building and using generative AI systems. Vertex AI includes over 100 foundation models, along with Search and Conversation and other AI solutions. Vertex AI is useful for accelerating ML development, building generative apps quickly, and training and fine-tuning ML models—all on the same platform.


In the Google Cloud ecosystem, Vertex AI’s role is to offer a scalable and efficient solution for the development and deployment of ML models. Google Cloud offers a number of AI and machine learning services to help users build generative AI applications, improve customer service through the use of AI agents, and generate AI-powered code across different Google Cloud tools. In total, Google Cloud services include over 150 products.


The Vertex AI platform is used by data scientists and machine learning engineers who are looking to automate or streamline their machine learning projects. Much of the automation happens through Vertex AI Pipelines, which orchestrate your ML lifecycle or workflow in a serverless fashion. Other key functionalities include data preparation, model training, model evaluation, and more.


Pricing is based on compute usage, model type, and API calls, which vary across products like AutoML, foundation models, and custom model training. In each scenario, pricing correlates with the amount of data being used, stored, or processed.


Google Cloud Vertex AI has a streamlined machine learning workflow, making the ML journey more approachable for data scientists. It also integrates with popular machine learning frameworks such as TensorFlow and PyTorch. Its practicality and accuracy make it a popular choice for companies looking for cutting-edge technology.


Key features of Vertex AI
Now that we have an overview of what Vertex AI is and what it does, we’ll discuss several of the key features of Vertex AI in greater detail.


Machine learning models
Vertex AI hosts a wide spectrum of machine learning models, including pretrained models and custom model creation. Each model has a different name, modality, and description. Broadly speaking, foundation models are trained large models that are customizable for different tasks, while fine-tunable models can be adjusted with a pipeline or custom notebook. Prebuilt, task-specific solutions are also available and are both ready to use and customizable based on the data you have on hand.


Model Garden provides access to a wide selection of pretrained models from Google and the open-source community. This includes Gemini, Google’s most advanced large language model (LLM), which is natively integrated into Vertex AI for text generation, summarization, and chat-based applications.


As you can imagine, these models offer a wide range of applications in different industries and sectors. Typically, ML models are employed for art creation, text generation, and image synthesis. They can also retrieve real-time data, sort it into preselected categories, and make predictions or identify trends based on the data presented.


Fully managed tools
Vertex AI provides several helpful tools to take the grunt work out of the machine learning process. For example, AutoML helps you train data from images, texts, and videos while eliminating the need for code or prepared data splits. Custom training allows you to use your preferred ML framework and select from different hyperparameter tuning options. Finally, generative AI offers access to Google’s selection of generative AI models within multiple modalities. You’ll be able to deploy them inside all your AI-powered applications.


Part of what makes Vertex AI easy to use is that its ML models require no physical infrastructure administration; you don’t have to provide or manage your own servers. Vertex AI will also take care of all necessary logging and queuing. It also offers several security features to protect your data and limit unauthorized network access.


Data science workflow
The data science workflow supported by Vertex AI includes essential stages like data preparation, model training, and evaluation. Usually, this is done using structured (or tabular) data. Each component of the process is efficient and user-friendly for maximum optimization.


Vertex AI Workbench is a Jupyter-based development environment integrated with Google Cloud, allowing teams to build, train, and deploy models without switching between tools. It supports Python, TensorFlow, PyTorch, and tight integration with BigQuery and Cloud Storage.


Data structuring and preparation require setting up your input source and adding different weights to the training data. Your metrics must conform to a list of requirements, including standards for size, number of columns and rows, and the data format.  


Google Cloud Vertex AI provides two different methods for model training. With AutoML, beginners can train models even with little prior knowledge or experience. If you would rather customize or create your own training models using any ML framework, custom training allows you to do so.


Regardless of what method you use, you’ll be able to evaluate the data using Vertex AI afterward. This starts with uploading your test dataset to a platform like BigQuery or Cloud Storage and setting up specific AI IAM permissions in your default Compute Engine account.


Customization and integration
Vertex AI includes multiple customization options, such as the ability to integrate with other tools. Vertex AI works with popular platforms such as Slack, Google Sheets, Typeform, Calendly, YouTube, and more. Vertex AI also includes functionality with other ML frameworks like TensorFlow, GPTConsole, Slingshot, Cameralyze, and Kedro.


This all comes in addition to the ability to customize Vertex AI to meet your unique needs. Vertex AI offers different functions for users with limited AI knowledge and experience. Still, the ability to tailor solutions and systems to specific applications is a nice bonus for anyone with the ability to build and develop their own models.


MLOps tools
Machine learning operations (MLOps) is a core function of ML engineering. MLOps has to do with the process of streaming and producing machine learning models in addition to upholding and monitoring them on an ongoing basis. Usually, this process requires attention from data scientists and machine learning engineers.


Vertex AI’s MLOps tools are instrumental in the automation and streamlining of model deployment and monitoring. These tools will help you implement various MLOps tools across your ML workflows while also improving operations over time through predictive monitoring, alerting, and diagnosis.‍


As AI development matures, companies are shifting from experimental models to production-ready systems. That’s why platforms like Vertex AI are increasingly focused on MLOps—bringing together version control, monitoring, governance, and retraining into one continuous pipeline. This shift makes machine learning workflows more scalable and sustainable across real-world applications.


Do the work you love, your way
Sign Up


Getting started with Vertex AI: No ML experience needed
If you’re new to machine learning or just starting to explore AI development, Vertex AI offers several beginner-friendly tools to help you get up and running—no coding background required.


Start with AutoML, which lets you train high-quality models using your own datasets through a simple interface. For inspiration and ready-to-use resources, browse the Model Garden, where you’ll find pretrained models for common tasks like image classification, text summarization, and natural language processing.


If you’re ready to try hands-on training, Vertex AI Workbench offers a Jupyter-based environment with guided notebooks and tutorials. It’s an easy way to learn the basics, experiment with sample data, and build your first AI-powered application in the Google Cloud ecosystem.


What can you use Vertex AI for?
Clearly, Vertex AI has a number of capabilities, but what applications do these functionalities have? We’ll discuss different scenarios below.


Data management and analysis
Vertex AI eases the data ingestion process from sources like Cloud Storage and BigQuery. Specifically, the Vertex AI data labeling feature enhances prediction accuracy and helps in generating high-quality training data. You can import both labeled and unlabeled data in addition to adding new labels and deleting existing labels from previously imported datasets.


In addition, the Vertex AI Feature Store is a fully managed, feature-rich repository that facilitates the serving, reusing, and sharing of ML features. It acts as a central location for organizing and storing different ML features. This can streamline data management and data analysis in machine learning projects ​while also making it easier for organizations to find and share a wide range of ML applications.


Pretrained APIs
APIs enable different forms of software to communicate in real time with each other. Pretrained APIs provided by Vertex AI cover domains such as vision, natural language processing, and video analysis. You can enable these pretrained APIs in your Google Distributed Cloud Hosted (GDCH) console after signing in and confirming any required prerequisites are verified.


These APIs can be seamlessly integrated into existing applications, and they make building new applications easy for use cases like translation or speech-to-text. Use cases may include conversational assistants, automated workflows, and search engines, along with data ingestion and feature extraction supporting gradual model improvement. Once deployed, these APIs are served via endpoints, allowing real-time inference and seamless integration into existing systems and applications.


Industry-specific applications
Vertex AI is highly versatile, with applications in a wide range of industries, including health care, financial services, manufacturing, and retail. Doctors can quickly extract data from patient records, financial analysts can measure performance and make predictions, and consumer goods organizations can accurately forecast future demand. While Vertex AI has value in many industries, these are a few of the most notable uses.


Organizations can employ Vertex AI for predictive analytics, fraud detection, and other machine learning-driven solutions tailored for specific industries. The ability to customize solutions to meet individual needs further expands the possibilities.


Optimizing supply chain operations
Companies like Wayfair have harnessed Vertex AI for optimizing supply chain operations. They find features like Pipelines, Hyperparameter Tuning, and Experiments are especially helpful for enhancing the efficiency of supply chain processes. They continue to look for ways to speed up the development of their models while also lowering maintenance efforts and enhancing the overall reliability of the system.


Automated machine learning (AutoML)
The concept of AutoML is significant for reducing the manual effort required in model development. Vertex AI’s AutoML features empower users to develop high-quality models with less manual intervention. These models are a tremendous option for first-time users and developers of AI with limited prior knowledge.


Benefits of Vertex AI
The benefits of using Vertex AI are many; let’s go over a few of the most notable:


Unified platform. Vertex AI integrates several functions—including data preparation, model training, monitoring, and deployment—into the same platform, reducing complexity and making management and oversight easier.
Support for open-source models. By incorporating open-source models, Vertex AI equips users to enhance their productivity and more effectively scale their workloads.
Simplicity and scalability. Vertex AI’s models are not overly complicated or intricate, making it easy for users to build models using their own training data or customize a solution that meets their needs.
Efficient infrastructure. Vertex AI’s scalable, cost-effective infrastructure allows for quick orchestration and easy management of large data clusters.
Seamless data-to-AI integration. Since Vertex AI’s tools are fully managed, they are easy to integrate and deploy within a variety of applications. You can browse open-source frameworks and models in Model Garden, or you can install extensions that allow your models to retrieve data from different applications in real time.
Limitations and challenges of Vertex AI
Like all AI applications, Vertex AI isn’t perfect. Drawbacks can include challenges such as ensuring data privacy and security and preventing model bias. That said, Google has taken steps to address some of these challenges. You can also avoid or mitigate these issues by following best practices and using AI tools available within Vertex AI. These include implementing IAM policies to regulate access across teams and using auto-scaling to reduce costs.


Who should use Vertex AI?
Vertex AI is ideal for teams already using Google Cloud Platform (GCP) or working with BigQuery, Looker, or Cloud Storage. Compared to AWS and Azure, it stands out for its integration with open-source frameworks, accessible AutoML, and strong support for generative AI. It’s a smart choice for fast-moving teams who want to iterate quickly and scale efficiently.


Find AI engineers on Upwork
Vertex AI is a unique ML solution with several potential uses and applications. With a wide range of features, many users will find benefit and value from incorporating it into their AI workflow. As you get started with Vertex AI, consider setting aside time to learn about the different features and consider what applications might best benefit your workflow.


If you’re looking to engage an AI engineer to work with your team, you’ll find many experienced and talented professionals on the Upwork marketplace. There, you can also find AI talent to fill nearly any skills gaps your team might have.Skip to main content 

[ ![Google Codelabs](https://www.gstatic.com/devrel-devsite/prod/v0a8f38b07c3863b7ced1d678d2584c8bd483c306fc4b8f547093e71dea088feb/codelabs/images/lockup.svg) ](/)

`/`

  * English
  * Deutsch
  * Español
  * Español – América Latina
  * Français
  * Indonesia
  * Italiano
  * Polski
  * Português – Brasil
  * Tiếng Việt
  * Türkçe
  * Русский
  * עברית
  * العربيّة
  * فارسی
  * हिंदी
  * বাংলা
  * ภาษาไทย
  * 中文 – 简体
  * 中文 – 繁體
  * 日本語
  * 한국어

Sign in




#  Building AI Agents with Vertex AI Agent Builder

##  1\. Before you begin 

This self-paced codelab will guide you through building AI Agents with Google Cloud's Vertex AI Agent Builder. Each step will highlight a specific Agent Builder feature and explain its purpose.

## **Prerequisites**

  * A basic understanding of [Generative AI on Google Cloud](https://cloud.google.com/ai/generative-ai)
  * A basic understanding of [AI Agent Concepts](https://cloud.google.com/dialogflow/vertex/docs/concept/agents)
  * A basic understanding of [Gemini CodeAssist](https://codeassist.google/products/business) (Optional)



## **What you'll learn**

  * How to create a simple AI Agent using Vertex AI Agent Builder
  * How to ground the created agent by attaching a datastore
  * How to integrate AI Agent to your website(Optional)



## **What you'll need**

  * A curious mind
  * A working computer and reliable wifi
  * A Google Cloud project with billing attached.



Note: If you don't have a Google Cloud project yet, you can create one by following [the instructions](https://developers.google.com/workspace/guides/create-project). You may also check out the [Google Cloud Free Tier Services](http://cloud.google.com/free).

##  2\. Designing Your First AI Agent 

Now you're ready to create your own AI agent. But before diving into development, it's essential to establish a clear vision for your agent. Ask yourself these key questions:

  * **What problem will it solve?** Will it automate tasks, provide information, offer entertainment, or facilitate creative exploration?
  * **What are its primary functions?** Will it execute tasks or delegate tasks? Will it generate text, or generate a combination of different media?
  * **What are its limitations?** Will it be able to do everything autonomously?
  * **What personality or persona should it have?** Will it be formal, informal, humorous, helpful, or informative?
  * **What are the success metrics?** How will you measure the agent's effectiveness?



To speed up the process, here are the answers to those questions for the travel agent you will be creating today:

  * **What problem will it solve?**
  * Planning a trip can be time-consuming and overwhelming. This travel agent will help users discover destinations, plan itineraries, book flights and accommodations.
  * **What are its primary functions?**
  * The agent should be able to
  * answer questions about destinations, such as visa requirements
  * plan itineraries that work for users' schedules and objectives
  * book flights and accommodations
  * **What are its limitations?**
  * The agent might not be able to answer complicated queries by default
  * The agent won't be able to generate visual images
  * The agent's knowledge will limited by the underlying model
  * **What personality or persona should it have?**
  * This agent should be knowledgeable, helpful, and enthusiastic about travel. It should be able to communicate information clearly and concisely.
  * **What are the success metrics?**
  * Success for this agent could be measured by how satisfied users are with its recommendations (exploring, planning, booking)



##  3\. Building an AI Agent with Vertex AI Agent Builder 

With Vertex AI Agent Builder, AI Agents can be created in just a few steps.

**Step 1:**

  * Head over to [Vertex AI Agent Builder](https://console.cloud.google.com/gen-app-builder/engines).
  * You should see the welcome page. ![833886ce0d2645ba.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/833886ce0d2645ba.png)
  * Click on the **CONTINUE AND ACTIVATE THE API** button.



**Step 2:**

  * You will be redirected to the App Creation page. ![f2d45cc76d62edeb.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/f2d45cc76d62edeb.png)
  * Click on the **CREATE A NEW APP** button.



**Step 3:**

  * Choose **Conversational agent** , and click on **CREATE**



![732d2cd9e10c9a79.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/732d2cd9e10c9a79.png)

**Note:**

  1. Once you click on **CREATE** a new tab of **Diaglogflow Conversational Agents** will open.
  2. If it asks you to **choose a Google Cloud Project** , please select your Google Cloud project associated with your **correct gmail** account.
  3. If you're doing this lab in a new account, it will ask you to enable the Dialogflow API, click **Enable API** to enable it.



![238281df06301db0.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/238281df06301db0.png)

  * If clicking the button doesn't work, you can enable it manually by going to the [API page ](https://console.cloud.google.com/apis/api/dialogflow.googleapis.com)directly.
  * In the newly opened Diaglogflow page, click on **Create Agent**



![42515e46bc63506d.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/42515e46bc63506d.png)

  * Now, It will give you some **options for creating an agent,** choose **Build your own.**



![8af6bf0853f20768.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/8af6bf0853f20768.png)

**Step 4:**

  * Pick a **Display Name** (e.g. Travel Buddy)
  * For Location, Select **global (Global serving, data-at-rest in US)** as **Region**
  * Keep other configuration, **default**
  * Click on the **CREATE** button



![4e0dea29e5d8acde.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/4e0dea29e5d8acde.png)

**Step 5:**

  * Pick a **Playbook Name** (e.g. Info Agent)
  * Add a **Goal** (e.g. Help customers answer travel related queries)
  * Define an **Instruction** (e.g. - Greet the users, then ask how you can help them today)
  * Press **Save** once everything is finalized



![f8bfd605ddd97cf8.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/f8bfd605ddd97cf8.png)

**Step 6:**

  * Click on the **Toggle Simulator** icon ![72588cbe8734f54e.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/72588cbe8734f54e.png)
  * Select the agent that you just created (e.g. _Info Agent_)
  * Choose the underlying generative AI model for your agent (e.g. _gemini-1.5-flash_)
  * Test your agent by having a conversation with it (i.e. Type something in "Enter User Input" text box)



![3ac3cf54a1e2098.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/3ac3cf54a1e2098.png)

Congratulations! You just successfully created an AI Agent using Vertex AI Agent Builder.

##  4\. Attaching Datastores to the Agent 

Try asking your agent about getting to Wakanda (e.g. "What's the best way to reach Wakanda?"), you will get a response like this:

![5baa2dbabe2941a2.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/5baa2dbabe2941a2.png)

While this is factually correct, instead of simply stating "I can't provide information" and ending the conversation, it would be more helpful to the user if the agent suggested similar places. This approach could potentially lead to users actually booking a trip through the agent.

In order for the agent to recommend similar places, you can provide more information to the agent through Datastores. It acts as an additional knowledge base for the agent to refer to if the agent is not able to answer user questions based on their built-in knowledge.

**Note:** If you want to close the simulator, **click on the toggle simulator icon** again

Creating a datastore is straight-forward, click on **\+ Data store** button at the bottom of the Agent Basics page.

![6c3ef19fefc46af7.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/6c3ef19fefc46af7.png)

Fill up the following information:

  * **Tool name:** Alternative Location
  * **Type:** Data store
  * **Description:** Use this tool if user's request contains a location that doesn't exist



Click **Save** when you are done.

This creates a datastore tool for the agent to communicate with the datastore, but you still need to create an actual datastore that contains the information. To do that, click on **add data stores and Create a data store.**

![65c790a87de8fba8.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/65c790a87de8fba8.png)

![7648d478a6f35cf0.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/7648d478a6f35cf0.png)

Once you click on **Create new data store** , you'll be redirected to the Vertex AI agent builder page like below

Choose on Cloud Storage option

![bff5455fac531509.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/bff5455fac531509.png)

Once you are done with the step,

  * click on **FILE** (This is **very important** otherwise your import will fail)
  * type **ai-workshops/agents/data/wakanda.txt**
  * click on **CONTINUE**



![d1983baa579eb78c.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/d1983baa579eb78c.png)

If you are curious, here is the content of the provided text file:

`Places that are similar to Wakanda`

`- Oribi Gorge in South Africa: The rock formations here are reminiscent of the Warrior Falls in Wakanda.`

`- Iguazu Falls: Located on the border of Argentina and Brazil, these massive waterfalls were a major inspiration for the Warrior Falls.`

`- Immerse yourself in Wakandan culture: Read the Black Panther comics, watch the movies, and explore online resources to learn more about Wakandan culture, language, and technology.`

`- Visit a Disney theme park: While there isn't a dedicated Wakanda land yet, you might be able to meet Black Panther at Disneyland or on a Marvel Day at Sea Disney cruise.`



On the next page, name your datastore (e.g. Wakanda Alternative) and click **CREATE**.

![93eb71e8d019ae24.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/93eb71e8d019ae24.png)

As a final step, **SELECT** the data source that you just created and click on **CREATE,** You can see the progress of your data store import by clicking on your data store**.**

![de1ac9256cc96f29.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/de1ac9256cc96f29.png)

**Note:** Import activity will take some time to be successfully completed so meanwhile this activity is ongoing you can explore more data store options available for your Vertex AI agent [here](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest#datastores-engines)

![9b5c4a2831728a6b.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/9b5c4a2831728a6b.png)

If everything went smoothly, go back to your **dialogflow tab** and click on **refresh** , you should see the datastore created under the **Available data stores** page.

![a44373b78bd95ff0.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/a44373b78bd95ff0.png)

In order to prevent Agent from hallucinations, in the grounding configuration for your data store, set the setting to **Very Low** which applies tighter restrictions on Agent from making things up, for now keep it default but anytime you can explore it with different settings.

![c1605bd076258050.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/c1605bd076258050.png)

Now, select the added data store, click on **confirm** , then click on **save.**

![40082aebe8b82d7c.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/40082aebe8b82d7c.png)

Now, Head back to your [Agent Basics](https://vertexaiconversation.cloud.google.com/projects) page, at the bottom of the playbook configuration, you'll see your newly created data store(e.g. Alternative Location) will be available to use, check the Data Store (e.g. Alternative Location), and click on Save button at top of the page.

![1b6b82fd7f30a598.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/1b6b82fd7f30a598.png)

![e09af18697b0fd7f.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/e09af18697b0fd7f.png)

You are almost there! The final step is to include the "**Alternative Location** " tool in the agent's instructions. Add a line, **\- Use ${TOOL: Alternative Location} if the user's request contains a location that does not exist** , to the agent's instructions and then click on **save**.

![3134d9eadca34e21.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/3134d9eadca34e21.png)

We're all set. Let's open the toggle simulator again and ask the same questions (i.e. What's the best way to reach Wakanda?)

![6cdee598391fc82a.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/6cdee598391fc82a.png)

Congratulations! Your agent is now recommending places using the provided information from a text file.

That's it, we're done with building our own agent builder AI agent, if you want to explore more in terms of customizing your agent for better experience, please check out the Additional Activities below.

##  5\. Additional Activities - Make your AI agent live 

In the preceding steps, you have developed an AI agent and grounded it with relevant reference data. In the following section, you will address the crucial question of how to embed this agent within your website, enabling real-time interaction with your visitors.

There are many ways to expose your agent. You can either export it or directly publish it. You can explore [the documentation](https://cloud.google.com/dialogflow/cx/docs/concept/integration/dialogflow-messenger) to find out about the possible options.

In the top right corner of your Dialogflow tab, click on **Overflow menu** and then **Publish agent**

![a1b109fa9d7cb51d.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/a1b109fa9d7cb51d.png)

Keep all the configuration as **Default** , and click on **Enable unauthenticated API**.

**Note:** Enabling the unauthenticated API is for the demo purposes only and this configuration is not recommended to use for production workload. If you are interested in publishing securely, check out [this documentation](https://cloud.google.com/dialogflow/cx/docs/concept/integration/dialogflow-messenger#authenticated_setup).

![ef0f24db780a185e.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/ef0f24db780a185e.png)

Upon clicking, you should see a small CSS code snippet:

![c40d12f6207bf5b4.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/c40d12f6207bf5b4.png)

Just **copy the code snippet**. You will be integrating this code snippet into a website later on.

To create a website, you will be using the Cloud Editor environment. Here are the steps to open Cloud Editor:

  1. Open up Google Cloud Console on another tab.
  2. Click on the Activate **Cloud Shell** button on the top right corner
  3. Click on **Open Editor** button.



If there is a prompt to Authorize Cloud Shell, click on **Authorize** to continue.

![d23192eca480f00c.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/d23192eca480f00c.png)

In the following section, you will be using [Gemini Code Assist](https://blog.google/technology/developers/gemini-code-assist-free/) to create a sample python flask web application to integrate with your Agent snippet.

Once Cloud Shell Editor is opened, click on **Gemini Code Assist** and **login to your Google Cloud** Project. If it asks you to enable the API, click on **Enable.**

![93112cce3e8d963b.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/93112cce3e8d963b.png)

Once done, let's ask Gemini Code Assist to create a flask app and integrate the AI agent code snippet to it.

Here is the sample prompt, you can use

`Here` `is` `my` `Travel` `buddy` `Vertex` `AI` `agent` `builder` `agent` `publish` `code` `snippet,`

`<REPLACE IT WITH YOUR AI AGENT PUBLISH CODE SNIPPET>`

`can` `you` `create` `a` `sample` `flask` `app` `to` `use` `it`

``

**Note:** Here we've asked for a python flask app. If you prefer any other programming language or framework, please feel free to use it. Gemini Code Assist has the capability to generate different programming languages. Check out [Supported languages, IDEs, and interfaces](https://cloud.google.com/gemini/docs/codeassist/supported-languages) for more details.

You will see that the provided code snippet is already integrated with the AI agent. To test if the provided code is valid and working as intended, you can follow the instructions given by Gemini Code Assist on how to run this code section of the output response.

Sample Output Response code snippet -

`from` `flask` `import` `Flask,` `render_template_string`

`app` `=` `Flask(__name__)`

`#` `HTML` `template` `string` `with` `the` `provided` `Dialogflow` `Messenger` `code`

`html_template` `=` `"""`

`<!DOCTYPE` `html>`

`<html` `lang="en">`

`<head>`

`<meta` `charset="UTF-8">`

`<meta` `name="viewport"` `content="width=device-width,` `initial-scale=1.0">`

`<title>Travel` `Buddy` `Chatbot</title>`

`<link` `rel="stylesheet"` `href="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/themes/df-messenger-default.css">`

`<script` `src="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/df-messenger.js"></script>`

`<style>`

`df-messenger` `{`

`z-index:` `999;`

`position:` `fixed;`

`--df-messenger-font-color:` `#000;`

`--df-messenger-font-family:` `Google` `Sans;`

`--df-messenger-chat-background:` `#f3f6fc;`

`--df-messenger-message-user-background:` `#d3e3fd;`

`--df-messenger-message-bot-background:` `#fff;`

`bottom:` `16px;`

`right:` `16px;`

`}`

`body` `{`

`font-family:` `sans-serif;`

`margin:` `20px;`

`}`

`</style>`

`</head>`

`<body>`

`<h1>Welcome` `to` `Travel` `Buddy!</h1>`

`<p>Start` `chatting` `with` `our` `AI` `Travel` `buddy,` `in` `the` `bottom` `right` `corner.</p>`

`<df-messenger`

`project-id="<SAMPLE>"`

`agent-id="<SAMPLE>"`

`language-code="en"`

`max-query-length="-1">`

`<df-messenger-chat-bubble`

`chat-title="Travel` `Buddy">`

`</df-messenger-chat-bubble>`

`</df-messenger>`

`</body>`

`</html>`

`"""`

`@app.route("/")`

`def` `index():`

`"""Renders` `the` `HTML` `template` `with` `the` `Dialogflow` `Messenger."""`

`return` `render_template_string(html_template)`

`if` `__name__` `==` `"__main__":`

`app.run(debug=True)`

``

![3dd3246c5fceb1d4.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/3dd3246c5fceb1d4.png)

As per given instruction

  1. Copy the provided sample flask app code snippet,
  2. Create a new file named **app.py** and save the file.



![4e58cfcf95f65d38.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/4e58cfcf95f65d38.png)

In the next step, it is asking to install the flask to run this snippet, that is not required for now as cloud shell already has all the commonly used utilities installed by default.

![b657b535710fd8f3.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/b657b535710fd8f3.png)

Save the file (Ctrl + S or CMD + S) and then click on the **Open Terminal** , where you will run the provided code.

In the terminal, run the below command

`python app.py`

``

**Note:** Make sure you're in the right folder, where your **app.py** file is present

The python flask app will be running on port **5000**. To see the preview of this web application, click on the **Web Preview** icon in the cloud shell. Then you can click on **Change Port, input 5000,** and click **Change and Preview** to save it.

![59ed7b08133b82bf.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/59ed7b08133b82bf.png)

A sample website will come up and there will be an AI agent already available. Just click on the AI agent and start chatting with it.

![35a4b5abdd299efe.png](/static/devsite/codelabs/building-ai-agents-vertexai/img/35a4b5abdd299efe.png)

Feel free to test it with different prompts. You may also ask Gemini Code Assist to beautify your website, or add more grounding data to the AI agent and make it more resourceful.

Once you are ready, as a next step, you can try hosting this AI agent on Google Cloud so that it can be accessed by anyone, anywhere. As for the reminder of this codelab, you will be deploying this sample flask application in Cloud Run as a container.

**Note:** It is not only limited to cloud run (If you don't know what is cloud run, even you can ask this), you can ask gemini code assist to assist you deploy this in Google Cloud or anywhere with the best practices, it can help you with that part as well.

Head back to the **Cloud Shell Terminal** and press **Ctrl + C** to kill the process. Click on the **Open Editor** again and ask Gemini Code Assist to help us with containerizing the application and deploy it in **cloud run**.

`Can` `you` `help` `me` `deploy` `this` `sample` `flask` `app` `to` `cloud` `run` `service`

``

It provides some instructions and command to follow to host our app in cloud run service, let's follow the instructions

Here is the sample output response

**Steps to Deploy to Cloud Run**

  1. **Prerequisites:**


  * **Google Cloud Account:** You need a Google Cloud account with billing enabled.
  * **gcloud CLI:** Install and initialize the Google Cloud SDK (gcloud CLI) on your local machine. You'll use this to interact with Google Cloud from your terminal.
  * **Docker:** Install Docker on your local machine. Cloud Run uses Docker to containerize your application.
  * **Project Setup:** Ensure you have a Google Cloud project selected in your gcloud CLI. You can check with `gcloud config list project` and set it with `gcloud config set project YOUR_PROJECT_ID`



**Note:** As we're performing this entire activity in cloud shell, there is not need of setting up projects

  2. **Create** ﻿**`requirements.txt`**﻿**:**


  * This file lists all the Python packages your app needs. In your project directory (where `main.py` is), create a file named `requirements.txt` and add the following linee


  3. **Create** ﻿**`Dockerfile`**﻿**:**


  * A `Dockerfile` defines how to build a Docker image for your application. Create a file named `Dockerfile` (no extension) in your project directory and add the following content:



`#` `Use` `an` `official` `Python` `runtime` `as` `a` `parent` `imageFROM` `python:3.9-slim-buster`

`#` `Set` `the` `working` `directory` `to` `/appWORKDIR` `/app`

`#` `Copy` `the` `current` `directory` `contents` `into` `the` `container` `at` `/app`

`COPY` `.` `/app`

`#` `Install` `any` `needed` `packages` `specified` `in` `requirements.txt`

`RUN` `pip` `install` `--no-cache-dir` `-r` `requirements.txt`

`#` `Make` `port` `5000` `available` `to` `the` `world` `outside` `this` `container`

`EXPOSE` `5000`

`#` `Define` `environment` `variable`

`ENV` `NAME` `World`

`#` `Run` `app.py` `when` `the` `container` `launches`

`CMD` `["python",` `".py"]`



  4. **Build the Docker Image:**


  * Open your terminal, navigate to your project directory, and run:



gcloud builds submit –tag gcr.io/bgr-workshop-23rd/travel-buddy

  5. **Deploy to Cloud Run:**


  * After the image is built and uploaded, deploy it to Cloud Run with the following command:



`gcloud` `run` `deploy` `travel-buddy` `--image` `gcr.io/bgr-workshop-23rd/travel-buddy` `--region` `us-central1`



Once you're done with these steps, you'll see your application with integrated AI agent will be live for your end users.

Congratulations and happy learning.

##  6\. Clean Up 

To avoid incurring charges to your Google Cloud account for the resources used in this codelab, follow these steps:

  1. In the Google Cloud console, go to the [Manage resources](https://console.cloud.google.com/iam-admin/projects?_ga=2.137741431.690084714.1674832835-1977883585.1670853686) page.
  2. In the project list, select the project that you want to delete, and then click **Delete**.
  3. In the dialog, type the project ID, and then click **Shut down** to delete the project.
  4. Alternatively you can go to [Cloud Run](https://console.cloud.google.com/run) on the console, select the service you just deployed and delete.



Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

[[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Missing the information I need","missingTheInformationINeed","thumb-down"],["Too complicated / too many steps","tooComplicatedTooManySteps","thumb-down"],["Out of date","outOfDate","thumb-down"],["Samples / code issue","samplesCodeIssue","thumb-down"],["Other","otherDown","thumb-down"]],[],[],[]] 
Skip to main content 

[ ![Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v0a8f38b07c3863b7ced1d678d2584c8bd483c306fc4b8f547093e71dea088feb/cloud/images/cloud-logo.svg) ](/)

  * 


`/`

  * English
  * Deutsch
  * Español
  * Español – América Latina
  * Français
  * Indonesia
  * Italiano
  * Português
  * Português – Brasil
  * 中文 – 简体
  * 中文 – 繁體
  * 日本語
  * 한국어

[ Console ](//console.cloud.google.com/) Sign in

  * [ Vertex AI ](https://cloud.google.com/vertex-ai/docs)



[Contact Us](https://cloud.google.com/contact) [Start free](//console.cloud.google.com/freetrial)

  * [ Home ](https://cloud.google.com/)
  * [ Documentation ](https://cloud.google.com/docs)
  * [ AI and ML ](https://cloud.google.com/docs/ai-ml)
  * [ Vertex AI ](https://cloud.google.com/vertex-ai/docs)



Send feedback 

#  Vertex AI custom training overview

Stay organized with collections  Save and categorize content based on your preferences. 

Vertex AI provides a managed training service that helps you operationalize large scale model training. You can use Vertex AI to run training applications based on any machine learning (ML) framework on Google Cloud infrastructure. For the following popular ML frameworks, Vertex AI also has integrated support that simplifies the preparation process for model training and serving:

  * [PyTorch](/vertex-ai/docs/start/pytorch)
  * [TensorFlow](/vertex-ai/docs/start/tensorflow)
  * [scikit-learn](https://scikit-learn.org/stable/)
  * [XGBoost](https://xgboost.readthedocs.io/en/stable/)



This page explains the benefits of custom training on Vertex AI, the workflow involved, and the various training options that are available.

### Vertex AI operationalizes training at scale

There are several challenges to operationalizing model training. These challenges include the time and cost needed to train models, the depth of skills required to manage the compute infrastructure, and the need to provide enterprise-level security. Vertex AI addresses these challenges while providing a host of other benefits.

#### Fully managed compute infrastructure

![Managed infrastructure](/static/vertex-ai/docs/training/images/icons/managed.svg) |  Model training on Vertex AI is a fully managed service that requires no administration of physical infrastructure. You can train ML models without the need to provision or manage servers. You only pay for the compute resources that you consume. Vertex AI also handles job logging, queuing, and monitoring. 

#### High-performance

|  ![High-performance](/static/vertex-ai/docs/training/images/icons/performance.svg) |  Vertex AI training jobs are optimized for ML model training, which can provide faster performance than directly running your training application on a Google Kubernetes Engine (GKE)) cluster. You can also identify and debug performance bottlenecks in your training job by using Cloud Profiler. 

#### Distributed training

|  ![Distributed training](/static/vertex-ai/docs/training/images/icons/distributed.svg) |  [Reduction Server](https://cloud.google.com/blog/topics/developers-practitioners/optimize-training-performance-reduction-server-vertex-ai) is an all-reduce algorithm in Vertex AI that can increase throughput and reduce latency of multi-node distributed training on NVIDIA graphics processing units (GPUs). This optimization helps reduce the time and cost of completing large training jobs. 

#### Hyperparameter optimization

|  ![Hyperparameter tuning](/static/vertex-ai/docs/training/images/icons/hptuning.svg) |  [Hyperparameter tuning jobs](/vertex-ai/docs/training/hyperparameter-tuning-overview) run multiple trials of your training application using different hyperparameter values. You specify a range of values to test, and Vertex AI discovers the optimal values for your model within that range. 

#### Enterprise security

|  ![Enterprise security](/static/vertex-ai/docs/training/images/icons/security.svg) |  Vertex AI provides the following enterprise security features:

  * [VPC peering](/vertex-ai/docs/general/vpc-peering) to limit network access.
  * [VPC Service Controls](/vertex-ai/docs/general/vpc-service-controls) to mitigate the risks of data exfiltration.
  * [Customer-managed encryption keys](/vertex-ai/docs/general/cmek) to help you meet specific compliance or regulatory requirements related to data protection.
  * [Identity and Access Management](/vertex-ai/docs/general/access-control) for fine-grained control over service account access.
  * Data isolation with single-tenant project boundaries. 



#### ML operations (MLOps) integrations

|  ![MLOps](/static/vertex-ai/docs/training/images/icons/mlops.svg) |  Vertex AI provides a suite of [integrated MLOps tools](/vertex-ai/docs/start/introduction-mlops) and features that you can use for the following purposes:

  * Orchestrate end-to-end ML workflows.
  * Perform feature engineering.
  * Run experiments.
  * Manage and iterate your models.
  * Track ML metadata.
  * Monitor and evaluate model quality. 



## Workflow for custom training

The following diagram shows a high-level overview of the custom training workflow on Vertex AI. The sections that follow describe each step in detail. ![Workflow for custom training](/static/vertex-ai/docs/training/images/custom-training-workflow.png)

### Load and prepare training data

For the best performance and support, use one of the following Google Cloud services as your data source:

  * [Cloud Storage](/vertex-ai/docs/training/cloud-storage-file-system)
  * [BigQuery](/bigquery/docs/introduction)
  * [NFS shares on Google Cloud](/vertex-ai/docs/training/train-nfs-share)

For a comparison of these services, see [Data preparation overview](/vertex-ai/docs/training/data-preparation-overview). You can also specify a [Vertex AI managed dataset](/vertex-ai/docs/training/using-managed-datasets) as the data source when using a training pipeline to train your model. Training a custom model and an AutoML model using the same dataset lets you compare the performance of the two models.

### Prepare your training application

To prepare your training application for use on Vertex AI, do the following:

  * Implement training code best practices for Vertex AI.
  * Determine a type of container image to use.
  * Package your training application into a supported format based on the selected container image type.



#### Implement training code best practices

Your training application should implement the [training code best practices for Vertex AI](/vertex-ai/docs/training/code-requirements#requirements_for_all_custom_training_code). These best practices relate to the ability of your training application to do the following:

  * Access Google Cloud services.
  * Load input data.
  * Enable autologging for experiment tracking.
  * Export model artifacts.
  * Use the environment variables of Vertex AI.
  * Ensure resilience to VM restarts.



#### Select a container type

Vertex AI runs your training application in a [Docker container image](https://www.docker.com/resources/what-container/). A Docker container image is a self-contained software package that includes code and all dependencies, which can run in almost any computing environment. You can either specify the URI of a [prebuilt container image](/vertex-ai/docs/training/pre-built-containers) to use, or create and upload a [custom container image](/vertex-ai/docs/training/containers-overview) that has your training application and dependencies pre-installed. The following table shows the differences between prebuilt and custom container images: | Specifications  | Prebuilt container images  | Custom container images   
---|---|---  
**ML framework** | Each container image is specific to an ML framework.  | Use any ML framework or use none.   
**ML framework version** | Each container image is specific to an ML framework version.  | Use any ML framework version, including minor versions and nightly builds.   
**Application dependencies** | Common dependencies for the ML framework are pre-installed. You can specify additional dependencies to install in your training application.  | Pre-install the dependencies that your training application needs.   
**Application delivery format** | 

  * Python source distribution.
  * Single Python file.

| Pre-install the training application in the custom container image.   
**Effort to set up** | Low  | High   
**Recommended for** | Python training applications based on an ML framework and framework version that has a prebuilt container image available.  | 

  * Greater customization and control.
  * Non-Python training applications.
  * Private or custom dependencies.
  * Training applications that use an ML framework or framework version that has no prebuilt container image available.

  
  
#### Package your training application

After you've determined the type of container image to use, package your training application into one of the following formats based on the container image type:

  * **Single Python file for use in a prebuilt container**

Write your training application as a single Python file and use the [Vertex AI SDK for Python](/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk) to create a `CustomJob` or `CustomTrainingJob` class. The Python file is packaged into a Python source distribution and installed to a prebuilt container image. Delivering your training application as a single Python file is suitable for prototyping. For production training applications, you'll likely have your training application arranged into more than one file.

  * **Python source distribution for use in a prebuilt container**

[Package your training application](/vertex-ai/docs/training/create-python-pre-built-container) into one or more Python source distributions and upload them to a Cloud Storage bucket. Vertex AI installs the source distributions to a prebuilt container image when you create a training job.

  * **Custom container image**

[Create your own Docker container image](/vertex-ai/docs/training/create-custom-container) that has your training application and dependencies pre-installed, and upload it to Artifact Registry. If your training application is written in Python, you can [perform these steps by using one Google Cloud CLI command](/vertex-ai/docs/training/create-custom-job#create_custom_job-gcloud).




### Configure training job

A Vertex AI training job performs the following tasks:

  * Provisions one (single node training) or more (distributed training) virtual machines (VMs).
  * Runs your containerized training application on the provisioned VMs.
  * Deletes the VMs after the training job completes.



Vertex AI offers [three types of training jobs](/vertex-ai/docs/training/custom-training-methods) for running your training application:

  * **[Custom job](/vertex-ai/docs/training/create-custom-job)**

A custom job ([`CustomJob`](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob)) runs your training application. If you're using a prebuilt container image, model artifacts are output to the specified Cloud Storage bucket. For custom container images, your training application can also output model artifacts to other locations.

  * **[Hyperparameter tuning job](/vertex-ai/docs/training/hyperparameter-tuning-overview)**

A hyperparameter tuning job ([`HyperparameterTuningJob`](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.HyperparameterTuningJob)) runs multiple trials of your training application using different hyperparameter values until it produces model artifacts with the optimal performing hyperparameter values. You specify the range of hyperparameter values to test and the metrics to optimize for.

  * **[Training pipeline](/vertex-ai/docs/training/create-training-pipeline)**

A training pipeline ([`CustomTrainingJob`](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob)) runs a custom job or hyperparameter tuning job and optionally exports the model artifacts to Vertex AI to create a model resource. You can specify a Vertex AI managed dataset as your data source.




When creating a training job, specify the compute resources to use for running your training application and configure your container settings.

#### Compute configurations

[Specify the compute resources](/vertex-ai/docs/training/configure-compute) to use for a training job. Vertex AI supports single-node training, where the training job runs on one VM, and [distributed training](/vertex-ai/docs/training/distributed-training), where the training job runs on multiple VMs.

The compute resources that you can specify for your training job are as follows:

  * **VM machine type**

Different machine types offer different CPUs, memory size, and bandwidth.

  * **Graphics processing units (GPUs)**

You can add one or more GPUs to A2 or N1 type VMs. If your training application is designed to use GPUs, adding GPUs can significantly improve performance.

  * **Tensor Processing Units (TPUs)**

TPUs are designed specifically for accelerating machine learning workloads. When using a TPU VM for training, you can specify only one worker pool. That worker pool can have only one replica.

  * **Boot disks**

You can use SSDs (default) or HDDs for your boot disk. If your training application reads and writes to disk, using SSDs can improve performance. You can also specify the size of your boot disk based on the amount of temporary data that your training application writes to disk. Boot disks can have between 100 GiB (default) and 64,000 GiB. All VMs in a worker pool must use the same type and size of boot disk.




#### Container configurations

The [container configurations](/vertex-ai/docs/training/configure-container-settings) that you need to make depend on whether you're using a prebuilt or custom container image.

  * **Prebuilt container configurations:**

    * Specify the URI of the prebuilt container image that you want to use.
    * If your training application is packaged as a Python source distribution, specify the Cloud Storage URI where the package is located.
    * Specify the entry point module of your training application.
    * Optional: Specify a list of command-line arguments to pass to the entry point module of your training application.
  * **Custom container configurations:**

    * Specify the URI of your custom container image, which can be a URI from Artifact Registry or Docker Hub.
    * **Optional** : Override the `ENTRYPOINT` or `CMD` instructions in your container image.



### Create a training job

After your data and training application are prepared, run your training application by creating one of the following training jobs:

  * [Create a custom job](/vertex-ai/docs/training/create-custom-job).
  * [Create a hyperparameter tuning job](/vertex-ai/docs/training/using-hyperparameter-tuning).
  * [Create a training pipeline](/vertex-ai/docs/training/create-training-pipeline).



To create the training job, you can use the Google Cloud console, Google Cloud CLI, Vertex AI SDK for Python, or the Vertex AI API.

### (Optional) Import model artifacts into Vertex AI

Your training application likely outputs one or more model artifacts to a specified location, usually a Cloud Storage bucket. Before you can get inferences in Vertex AI from your model artifacts, first [import the model artifacts into Vertex AI Model Registry](/vertex-ai/docs/training/exporting-model-artifacts).

Like container images for training, Vertex AI gives you the choice of using [prebuilt](/vertex-ai/docs/predictions/pre-built-containers) or [custom](/vertex-ai/docs/predictions/custom-container-requirements) container images for inferences. If a prebuilt container image for inferences is available for your ML framework and framework version, we recommend using a prebuilt container image.

## What's next

  * [Get inferences](/vertex-ai/docs/predictions/get-predictions) from your model.
  * [Evaluate your model](/vertex-ai/docs/evaluation/introduction).
  * Try the [Hello custom training](/vertex-ai/docs/tutorials/image-classification-custom) tutorial for step-by-step instructions on training a TensorFlow Keras image classification model on Vertex AI. 



Send feedback 

Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-10-10 UTC.

Need to tell us more?  [[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Hard to understand","hardToUnderstand","thumb-down"],["Incorrect information or sample code","incorrectInformationOrSampleCode","thumb-down"],["Missing the information/samples I need","missingTheInformationSamplesINeed","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-10-10 UTC."],[],[]] 
Skip to main content 

[ ![Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v0a8f38b07c3863b7ced1d678d2584c8bd483c306fc4b8f547093e71dea088feb/cloud/images/cloud-logo.svg) ](/)

  * 


`/`

  * English
  * Deutsch
  * Español
  * Español – América Latina
  * Français
  * Indonesia
  * Italiano
  * Português
  * Português – Brasil
  * 中文 – 简体
  * 中文 – 繁體
  * 日本語
  * 한국어

[ Console ](//console.cloud.google.com/) Sign in

  * [ Vertex AI Vision ](https://cloud.google.com/vision-ai/docs)



[Contact Us](https://cloud.google.com/contact) [Start free](//console.cloud.google.com/freetrial)

  * [ Home ](https://cloud.google.com/)
  * [ Documentation ](https://cloud.google.com/docs)
  * [ AI and ML ](https://cloud.google.com/docs/ai-ml)
  * [ Vertex AI Vision ](https://cloud.google.com/vision-ai/docs)



# Vertex AI Vision documentation

[Read product documentation](https://cloud.google.com/vision-ai/docs/overview)

Easily build and deploy Vertex AI Vision applications using a single platform. 

![Vertex AI Vision architecture diagram](/static/vision-ai/docs/images/vertex-ai-vision-architecture-diagram.png)

[Get started for free](https://console.cloud.google.com/freetrial)

#### Start your proof of concept with $300 in free credit

  * Get access to Gemini 2.0 Flash Thinking 
  * Free monthly usage of popular products, including AI APIs and BigQuery 
  * No automatic charges, no commitment 



[ View free product offers ](/free/docs/free-cloud-features#free-tier)

#### Keep exploring with 20+ always-free products

Access 20+ free products for common use cases, including AI APIs, VMs, data warehouses, and more. 

format_list_numbered 

### Guides

  * [ Vertex AI Vision overview ](/vision-ai/docs/overview)

  * [ Set up a project and a development environment ](/vision-ai/docs/cloud-environment)

  * Quickstart 

[ Build an app in the console ](/vision-ai/docs/build-app-console-quickstart)

  * How to 

Learn to: [Create streams and ingest data](/vision-ai/docs/create-manage-streams), [Build an application](/vision-ai/docs/build-app), or [Search warehouse data in the console](/vision-ai/docs/search)

  * Tutorials 

Build an end-to-end: [Face blur app](/vision-ai/docs/face-blur-tutorial), [Occupancy count app with VM streaming](/vision-ai/docs/occupancy-count-tutorial), or [Occupancy analytics app with BigQuery ML forecasting](/vision-ai/docs/occupancy-bq-tutorial)




find_in_page 

### Reference

  * Technical 

APIs: [REST](/vision-ai/docs/reference/rest) or [RPC](/vision-ai/docs/reference/rpc)

  * Technical 

[ SDK: C++ SDK reference ](/vision-ai/docs/reference/cpp)

  * Conceptual 

Before you build: [Responsible AI practices](https://ai.google/responsibilities/responsible-ai-practices/?category=general) or [Inclusive ML guide - AutoML](/inclusive-ml)




info 

### Resources

  * [ Pricing ](/vision-ai/pricing)

  * [ Quotas and limits ](/vision-ai/quotas)

  * [ Release notes ](/vision-ai/docs/release-notes)

  * [ Service level agreement (SLA) ](/vertex-ai-vision/sla)




##  Related videos 

Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-10-02 UTC.

[[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Hard to understand","hardToUnderstand","thumb-down"],["Incorrect information or sample code","incorrectInformationOrSampleCode","thumb-down"],["Missing the information/samples I need","missingTheInformationSamplesINeed","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-10-02 UTC."],[],[]] 
[**Try Gemini 2.5,** our most intelligent model now available in Vertex AI](https://console.cloud.google.com/freetrial/?redirectPath=/vertex-ai/studio/multimodal)

# Vertex AI Studio

## Test, tune, and deploy enterprise-ready generative AI

Streamline your foundation model workflows with Vertex AI Studio. Rapidly prototype, refine, and seamlessly deploy models to your applications.

**New customers get up to $300 in free credits** to try Vertex AI and other Google Cloud products. 

Try it free[](https://console.cloud.google.com/vertex-ai/generative/multimodal/create/text)

Contact sales [](https://cloud.google.com/contact/)

### Product highlights

  * [Adapt models to your use case with prompt design ](/generative-ai-studio?hl=en#features)
  * [Easily tune foundation models with your own data](/generative-ai-studio?hl=en#common-uses)
  * [Rapidly prototype and test generative AI models](/generative-ai-studio?hl=en#features)



* * *

  * [![Vertex AI logo](https://www.gstatic.com/bricks/image/1727a73b4338e5650adbed6ff57c7f30cc9163ac9b2c710f798286c2bce3a9a1.svg)Introduction to Vertex AI Studio27:50](https://www.youtube.com/watch?v=KWarqNq195M)




Features

### Gemini, Google’s most capable multimodal models

Vertex AI offers access to the latest [Gemini models](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models) from Google. Gemini is capable of understanding virtually any input, combining different types of information, and generating almost any output. Prompt and test Gemini in [Vertex AI Studio](https://console.cloud.google.com/freetrial/?redirectPath=/vertex-ai/studio/multimodal), using text, images, video, or code. Using Gemini’s advanced reasoning and state-of-the-art generation capabilities, developers can try sample prompts for extracting text from images, converting image text to JSON, and even generate answers about uploaded images to build next-gen AI applications.

[Multimodal AI in actionWatch the video ](https://www.youtube.com/watch?v=pEmCgIGpIoo&)

### Access to foundation models and APIs

Choose the right model for your use case with 200+ proprietary models, open models, and 3rd party models on Vertex AI's [Model Garden](https://cloud.google.com/model-garden). With access to Google's foundation models as [APIs](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), you can easily deploy these models to applications.

In addition to Gemini, you also have access to [Gemma](https://ai.google.dev/gemma), a family of lightweight, state-of-the-art open models built from the same research and technology used to create the Gemini models.

### Experiment and test models with prompt design

Adapt models to your use case with [prompt design](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/introduction-prompt-design). Iterate on the prompt through a familiar chat interface and choose from multiple ways to adjust responses. For example, you can change the response "temperature" to elicit a more creative response. 

[Generative AI prompt samplesView examples](https://cloud.google.com/vertex-ai/generative-ai/docs/prompt-gallery)

### Easily tune models with your own data 

Improve the quality of model responses for your use case by [tuning foundation models](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-models) with your own data with Vertex AI Studio. 

Access state-of-the-art tuning options like [adapter tuning](https://services.google.com/fh/files/misc/adaptation_of_foundation_models_whitepaper_google_cloud.pdf) and Reinforcement Learning from Human Feedback (RLHF) or style and subject tuning for image generation. 

  


### Connect models to real-world data and real-time actions

Vertex AI Extensions provides a set of fully-managed tools for building and managing extensions that connect models to proprietary data sources or 3rd party services. Now developers can create generative AI applications that deliver real-time information, incorporate company data, and take action on the user's behalf. 

### Integration with end-to-end ML tools

Vertex AI's [managed endpoints](https://cloud.google.com/vertex-ai/docs/pipelines/model-endpoint-component) make it easy to build generative capabilities into an application, with only a few lines of code and no ML background required. Developers can forget about the complexities of provisioning storage and compute resources, or of optimizing the model for inference. 

Once deployed, foundation models can be scaled, managed, and governed in production using Vertex AI’s end-to-end [MLOps](https://cloud.google.com/vertex-ai/docs/start/introduction-mlops) capabilities and fully managed AI infrastructure. 

  


### Enterprise-grade data governance and security 

With Vertex AI, your data is [completely protected, secure, and private](https://cloud.google.com/vertex-ai/docs/generative-ai/data-governance) when using it to customize a model, and you have full control over where and how or if their data is used. None of the customer’s data, model weights, or input prompts are used to tune the original foundation models. When enterprises tune a model with their own data, the original model remains unchanged, and the new model never leaves your company’s environment. 

View all features

How It Works

### 

Vertex AI Studio is a Google Cloud console tool for rapidly prototyping and testing generative AI models. Test sample prompts, design your own prompts, and customize foundation models to handle tasks to meet your application's needs.

Get started in Vertex AI Studio with our no cost introductory training. In this course, learn what Vertex AI Studio is, walk through product demos, features, options, and how to use it.

Start free training [](https://www.cloudskillsboost.google/course_templates/552?utm_source=cgc-site&utm_medium=et&utm_campaign=FY24-Q2-global-website-skillsboost&utm_content=developers&utm_term=-)

[![Introduction to Vertex AI Studio ](https://www.gstatic.com/bricks/image/c4JosbpXjD-veJlpp4H1R0Ffy6GEbPk1DJbCSslVprZzXceC25pbaffMlAFXV1SGIfYQWsC3Sm4.png)](https://www.youtube.com/watch?v=KWarqNq195M&t)

Introduction to Vertex AI Studio 

Common Uses

### Build with Gemini

## 

Use Vertex AI Studio to access Gemini's multimodal models

Prompt and test in Vertex AI Studio with Gemini, using natural language, text, code, or an image. Test, tune, and deploy enterprise-ready models to build next-gen AI applications.

Try Vertex AI Studio [](https://console.cloud.google.com/vertex-ai/studio/multimodal)

[![Image of web page for Vertex AI Studio](https://www.gstatic.com/bricks/image/37c3ec59-0752-4f37-92ae-244b5f4a8fc7.png)](%27#%27)

  * [Get started with _generative AI_](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview#get-started)
  * [ Choose _models and infrastructure_ for your generative AI application](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)
  * [Checkout the generative AI on _Vertex AI cookbook_](https://cloud.google.com/vertex-ai/generative-ai/docs/cookbook)



![build](https://fonts.gstatic.com/s/i/short-term/release/googlesymbols/build/wght100fill1/20px.svg)

#### Tutorials, quickstarts, & labs

## 

Use Vertex AI Studio to access Gemini's multimodal models

Prompt and test in Vertex AI Studio with Gemini, using natural language, text, code, or an image. Test, tune, and deploy enterprise-ready models to build next-gen AI applications.

Try Vertex AI Studio [](https://console.cloud.google.com/vertex-ai/studio/multimodal)

[![Image of web page for Vertex AI Studio](https://www.gstatic.com/bricks/image/37c3ec59-0752-4f37-92ae-244b5f4a8fc7.png)](%27#%27)

  * [Get started with _generative AI_](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview#get-started)
  * [ Choose _models and infrastructure_ for your generative AI application](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)
  * [Checkout the generative AI on _Vertex AI cookbook_](https://cloud.google.com/vertex-ai/generative-ai/docs/cookbook)



### Design and test model prompts 

## 

Prompt design and prompt engineering

Dive into an introduction on basic concepts for designing prompts. Learn to write well structured prompts can be an essential part of ensuring accurate, high quality responses from a language model. You can use prompts to generate text, embeddings, code, images, videos, music, and more.

Get an intro to prompt designing[](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design)

  * [Use AI-powered _prompting tool_](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/ai-powered-prompt-writing)
  * [ Browse the _prompt gallery_](https://cloud.google.com/vertex-ai/generative-ai/docs/prompt-gallery)
  * [ Overview of prompting strategies ](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-design-strategies)



![build](https://fonts.gstatic.com/s/i/short-term/release/googlesymbols/build/wght100fill1/20px.svg)

#### Tutorials, quickstarts, & labs

## 

Prompt design and prompt engineering

Dive into an introduction on basic concepts for designing prompts. Learn to write well structured prompts can be an essential part of ensuring accurate, high quality responses from a language model. You can use prompts to generate text, embeddings, code, images, videos, music, and more.

Get an intro to prompt designing[](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design)

  * [Use AI-powered _prompting tool_](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/ai-powered-prompt-writing)
  * [ Browse the _prompt gallery_](https://cloud.google.com/vertex-ai/generative-ai/docs/prompt-gallery)
  * [ Overview of prompting strategies ](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-design-strategies)



### Tune foundation models from your data 

## 

Benefits of model tuning 

Fine-tune large language models with your own data to achieve superior performance on specific tasks. This customization process, known as model tuning, leads to more accurate and relevant results, increased model robustness, reduced latency and cost, thanks to shorter prompts. Model tuning delivers higher quality output tailored to your use case.

Introduction to tuning [](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-models)

  * [Tune _Gemini_ models ](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-use-supervised-tuning)
  * [Tune _text_](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune_gemini/text_tune)
  * [ Tune _images_](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune_gemini/image_tune)



![build](https://fonts.gstatic.com/s/i/short-term/release/googlesymbols/build/wght100fill1/20px.svg)

#### Tutorials, quickstarts, & labs

## 

Benefits of model tuning 

Fine-tune large language models with your own data to achieve superior performance on specific tasks. This customization process, known as model tuning, leads to more accurate and relevant results, increased model robustness, reduced latency and cost, thanks to shorter prompts. Model tuning delivers higher quality output tailored to your use case.

Introduction to tuning [](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-models)

  * [Tune _Gemini_ models ](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-use-supervised-tuning)
  * [Tune _text_](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune_gemini/text_tune)
  * [ Tune _images_](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune_gemini/image_tune)



### Evaluate and optimize model performance

## 

Gen AI evaluation service workflow

The Gen AI evaluation service in Vertex AI lets you evaluate any generative model or application and benchmark the evaluation results against your own judgment, using your own evaluation criteria. Evaluating Gen AI is integrated within Vertex AI to help you launch and reuse evaluations as needed.

  


Get an overview[](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-quickstart)

  * [View and interpret _evaluation results_](https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation)
  * [ Prepare your _evaluation dataset_](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-dataset)
  * [ Run an _evaluation_](https://cloud.google.com/vertex-ai/generative-ai/docs/models/run-evaluation)



![build](https://fonts.gstatic.com/s/i/short-term/release/googlesymbols/build/wght100fill1/20px.svg)

#### Tutorials, quickstarts, & labs

## 

Gen AI evaluation service workflow

The Gen AI evaluation service in Vertex AI lets you evaluate any generative model or application and benchmark the evaluation results against your own judgment, using your own evaluation criteria. Evaluating Gen AI is integrated within Vertex AI to help you launch and reuse evaluations as needed.

  


Get an overview[](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-quickstart)

  * [View and interpret _evaluation results_](https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation)
  * [ Prepare your _evaluation dataset_](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-dataset)
  * [ Run an _evaluation_](https://cloud.google.com/vertex-ai/generative-ai/docs/models/run-evaluation)



Generate a solution

What problem are you trying to solve?

Generate solution

 _shuffle_ Surprise me

What you'll get:

_check_small_ Step-by-step guide

 _check_small_ Reference architecture

 _check_small_ Available pre-built solutions

 _spark_ Use various generative models

 _spark_ Generate custom images

 _spark_ Train a custom model

This service was built with [Vertex AI](/vertex-ai). You must be 18 or older to use it. Do not enter sensitive, confidential, or personal info.

Pricing

Vertex AI Studio| Pricing for generative AI varies by foundation models and APIs.   
---|---  
Service| Pricing  
Vertex AI| Learn more about generative AI on [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models).   
  
Vertex AI Studio

Pricing for generative AI varies by foundation models and APIs. 

Vertex AI

Pricing

Learn more about generative AI on [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models). 

### 

Pricing calculator

Estimate your costs on Google Cloud

Check out our pricing calculator [](https://cloud.google.com/products/calculator)

### 

Custom quote

Connect with our sales team to learn more about pricing

Contact sales[](https://cloud.google.com/contact/)

### 

Start your AI journey today 

### 

New customers get up to $300 in free credits to try Vertex AI and other Google Cloud products. 

Try it free [](https://console.cloud.google.com/freetrial/?redirectPath=/vertex-ai/studio/multimodal)

### 

Have a large project?

Contact sales[](https://cloud.google.com/contact)

![](https://www.gstatic.com/cgc/product-v3/proof-of-concept-blue.svg)

### 

Add AI to applications

Watch video[](https://youtu.be/yaDrWa1f-RI)

![](https://www.gstatic.com/cgc/product-v3/proof-of-concept-yellow.svg)

### 

Take ML models to production

Read blog[](https://cloud.google.com/blog/products/ai-machine-learning/go-from-a-notebook-to-a-production-ml-model)

![](https://www.gstatic.com/cgc/product-v3/proof-of-concept-green.svg)

### 

MLOps on Vertex AI

Read documentation[](https://cloud.google.com/vertex-ai/docs/start/introduction-mlops)
Skip to main content 

[ ![Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v0a8f38b07c3863b7ced1d678d2584c8bd483c306fc4b8f547093e71dea088feb/cloud/images/cloud-logo.svg) ](/)

  * 


`/`

  * English
  * Deutsch
  * Español
  * Español – América Latina
  * Français
  * Indonesia
  * Italiano
  * Português
  * Português – Brasil
  * 中文 – 简体
  * 中文 – 繁體
  * 日本語
  * 한국어

[ Console ](//console.cloud.google.com/) Sign in

  * [ Generative AI on Vertex AI ](https://cloud.google.com/vertex-ai/generative-ai/docs)



[Contact Us](https://cloud.google.com/contact) [Start free](//console.cloud.google.com/freetrial)

  * [ Home ](https://cloud.google.com/)
  * [ Generative AI on Vertex AI ](https://cloud.google.com/vertex-ai/generative-ai/docs)
  * [ Documentation ](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview)
  * [ Vertex AI Cookbook ](https://cloud.google.com/vertex-ai/generative-ai/docs/cookbook)



#  Generate text from multimodal prompt

Stay organized with collections  Save and categorize content based on your preferences. 

This sample demonstrates how to generate text from a multimodal prompt using the Gemini model. The prompt consists of three images and two text prompts. The model generates a text response that describes the images and the text prompts.

## Code sample

### Java

Before trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using client libraries](/vertex-ai/docs/start/client-libraries). For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1). 

To authenticate to Vertex AI, set up Application Default Credentials. For more information, see [Set up authentication for a local development environment](/docs/authentication/set-up-adc-local-dev-environment). 
    
    
    import com.google.genai.Client;
    import com.google.genai.types.Content;
    import com.google.genai.types.GenerateContentResponse;
    import com.google.genai.types.HttpOptions;
    import com.google.genai.types.Part;
    import java.io.IOException;
    import java.nio.file.Files;
    import java.nio.file.Paths;
    
    public class TextGenerationWithMultiLocalImage {
    
      public static void main(String[] args) throws IOException {
        // TODO(developer): Replace these variables before running the sample.
        String modelId = "gemini-2.5-flash";
        String localImageFilePath1 = "your/local/img1.jpg";
        String localImageFilePath2 = "your/local/img2.jpg";
        generateContent(modelId, localImageFilePath1, localImageFilePath2);
      }
    
      // Generates text using multiple local images
      public static String generateContent(
          String modelId, String localImageFilePath1, String localImageFilePath2) throws IOException {
        // Initialize client that will be used to send requests. This client only needs to be created
        // once, and can be reused for multiple requests.
        try (Client client =
            Client.builder()
                .location("global")
                .vertexAI(true)
                .httpOptions(HttpOptions.builder().apiVersion("v1").build())
                .build()) {
    
          // Read content from local files.
          byte[] localFileImg1Bytes = Files.readAllBytes(Paths.get(localImageFilePath1));
          byte[] localFileImg2Bytes = Files.readAllBytes(Paths.get(localImageFilePath2));
    
          GenerateContentResponse response =
              client.models.generateContent(
                  modelId,
                  Content.fromParts(
                      Part.fromBytes(localFileImg1Bytes, "image/jpeg"),
                      Part.fromBytes(localFileImg2Bytes, "image/jpeg"),
                      Part.fromText("Generate a list of all the objects contained in both images")),
                  null);
    
          System.out.print(response.text());
          // Example response:
          // Based on both images, here are the objects contained in both:
          //
          // 1.  **Coffee cups (or mugs)**: Both images feature one or more cups containing a beverage.
          // 2.  **Coffee (or a similar beverage)**: Both images contain a liquid beverage in the cups,
          // appearing to be coffee or a coffee-like drink.
          // 3.  **Table (or a flat surface)**: Both compositions are set on a flat surface, likely a
          // table or countertop.
          return response.text();
        }
      }
    }

### Node.js

Before trying this sample, follow the Node.js setup instructions in the [Vertex AI quickstart using client libraries](/vertex-ai/docs/start/client-libraries). For more information, see the [Vertex AI Node.js API reference documentation](/nodejs/docs/reference/aiplatform/latest). 

To authenticate to Vertex AI, set up Application Default Credentials. For more information, see [Set up authentication for a local development environment](/docs/authentication/set-up-adc-local-dev-environment). 
    
    
    const {GoogleGenAI} = require('@google/genai');
    const fs = require('fs');
    
    const GOOGLE_CLOUD_PROJECT = process.env.GOOGLE_CLOUD_PROJECT;
    const GOOGLE_CLOUD_LOCATION = process.env.GOOGLE_CLOUD_LOCATION || 'global';
    
    function loadImageAsBase64(path) {
      const bytes = fs.readFileSync(path);
      return bytes.toString('base64');
    }
    
    async function generateContent(
      projectId = GOOGLE_CLOUD_PROJECT,
      location = GOOGLE_CLOUD_LOCATION,
      imagePath1,
      imagePath2
    ) {
      const client = new GoogleGenAI({
        vertexai: true,
        project: projectId,
        location: location,
      });
    
      // TODO(Developer): Update the below file paths to your images
      const image1 = loadImageAsBase64(imagePath1);
      const image2 = loadImageAsBase64(imagePath2);
    
      const response = await client.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: [
          {
            role: 'user',
            parts: [
              {
                text: 'Generate a list of all the objects contained in both images.',
              },
              {
                inlineData: {
                  data: image1,
                  mimeType: 'image/jpeg',
                },
              },
              {
                inlineData: {
                  data: image2,
                  mimeType: 'image/jpeg',
                },
              },
            ],
          },
        ],
      });
    
      console.log(response.text);
    
      // Example response:
      //  Okay, here's a jingle combining the elements of both sets of images, focusing on ...
      //  ...
    
      return response.text;
    }
    

### Python

Before trying this sample, follow the Python setup instructions in the [Vertex AI quickstart using client libraries](/vertex-ai/docs/start/client-libraries). For more information, see the [Vertex AI Python API reference documentation](/python/docs/reference/aiplatform/latest). 

To authenticate to Vertex AI, set up Application Default Credentials. For more information, see [Set up authentication for a local development environment](/docs/authentication/set-up-adc-local-dev-environment). 
    
    
    from google import genai
    from google.genai.types import HttpOptions, Part
    
    client = genai.Client(http_options=HttpOptions(api_version="v1"))
    # TODO(Developer): Update the below file paths to your images
    # image_path_1 = "path/to/your/image1.jpg"
    # image_path_2 = "path/to/your/image2.jpg"
    with open(image_path_1, "rb") as f:
        image_1_bytes = f.read()
    with open(image_path_2, "rb") as f:
        image_2_bytes = f.read()
    
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=[
            "Generate a list of all the objects contained in both images.",
            Part.from_bytes(data=image_1_bytes, mime_type="image/jpeg"),
            Part.from_bytes(data=image_2_bytes, mime_type="image/jpeg"),
        ],
    )
    print(response.text)
    # Example response:
    # Okay, here's a jingle combining the elements of both sets of images, focusing on ...
    # ...

## What's next

To search and filter code samples for other Google Cloud products, see the [Google Cloud sample browser](/docs/samples?product=googlegenaisdk). 

Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

[[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Hard to understand","hardToUnderstand","thumb-down"],["Incorrect information or sample code","incorrectInformationOrSampleCode","thumb-down"],["Missing the information/samples I need","missingTheInformationSamplesINeed","thumb-down"],["Other","otherDown","thumb-down"]],[],[],[]] 
Skip to main content 

[ ![Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v0a8f38b07c3863b7ced1d678d2584c8bd483c306fc4b8f547093e71dea088feb/cloud/images/cloud-logo.svg) ](/)

  * 


`/`

  * English
  * Deutsch
  * Español
  * Español – América Latina
  * Français
  * Indonesia
  * Italiano
  * Português
  * Português – Brasil
  * 中文 – 简体
  * 中文 – 繁體
  * 日本語
  * 한국어

[ Console ](//console.cloud.google.com/) Sign in

  * [ Vertex AI Workbench ](https://cloud.google.com/vertex-ai/docs/workbench/instances)



[Contact Us](https://cloud.google.com/contact) [Start free](//console.cloud.google.com/freetrial)

  * [ Home ](https://cloud.google.com/)
  * [ Documentation ](https://cloud.google.com/docs)
  * [ AI and ML ](https://cloud.google.com/docs/ai-ml)
  * [ Vertex AI Workbench ](https://cloud.google.com/vertex-ai/docs/workbench/instances)
  * [ Guides ](https://cloud.google.com/vertex-ai/docs)



Send feedback 

Stay organized with collections  Save and categorize content based on your preferences. 

# Introduction to Vertex AI Workbench

Vertex AI Workbench instances are Jupyter notebook-based development environments for the entire data science workflow. You can interact with Vertex AI and other Google Cloud services from within a Vertex AI Workbench instance's Jupyter notebook.

Vertex AI Workbench integrations and features can make it easier to access your data, process data faster, schedule notebook runs, and more.

Vertex AI Workbench instances are prepackaged with [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html) and have a preinstalled suite of deep learning packages, including support for the TensorFlow and PyTorch frameworks. You can configure either CPU-only or GPU-enabled instances.

Vertex AI Workbench instances support the ability to sync with a [GitHub](https://github.com/) repository.

Vertex AI Workbench instances are protected by Google Cloud authentication and authorization.

## Access to data

You can access your data without leaving the JupyterLab user interface.

In JupyterLab's navigation menu on a Vertex AI Workbench instance, you can use the Cloud Storage integration to browse data and other files that you have access to. See [Access Cloud Storage buckets and files from within JupyterLab](/vertex-ai/docs/workbench/instances/cloud-storage).

You can also use the BigQuery integration to browse tables that you have access to, write queries, preview results, and load data into your notebook. See [Query data in BigQuery tables from within JupyterLab](/vertex-ai/docs/workbench/instances/bigquery).

## Execute notebook runs

Use the executor to run a notebook file as a one-time execution or on a schedule. Choose the specific environment and hardware that you want your execution to run on. Your notebook's code will run on Vertex AI custom training, which can make it easier to do distributed training, optimize hyperparameters, or schedule continuous training jobs.

You can use parameters in your execution to make specific changes to each run. For example, you might specify a different dataset to use, change the learning rate on your model, or change the version of the model.

You can also set a notebook to run on a recurring schedule. Even while your instance is shut down, Vertex AI Workbench will run your notebook file and save the results for you to look at and share with others. See [Schedule a notebook run](/vertex-ai/docs/workbench/instances/schedule-notebook-run-quickstart).

## Share insights

Executed notebook runs are stored in a Cloud Storage bucket, so you can share your insights with others by granting access to the results. See the previous section on executing notebook runs.

## Secure your instance

The following sections describe supported capabilities that can help you secure your Vertex AI Workbench instance.

### VPC

You can deploy your Vertex AI Workbench instance with the default Google-managed network, which uses a default VPC network and subnet. Instead of the default network, you can specify a VPC network to use with your instance.

To use Vertex AI Workbench within a service perimeter, see [Use a Vertex AI Workbench instance within a service perimeter](/vertex-ai/docs/workbench/instances/service-perimeter).

### Customer-managed encryption keys (CMEK)

By default, Google Cloud automatically [encrypts data when it is at rest](/security/encryption/default-encryption) using encryption keys managed by Google. If you have specific compliance or regulatory requirements related to the keys that protect your data, you can use customer-managed encryption keys (CMEK) with your Vertex AI Workbench instances. For more information, see [Customer-managed encryption keys](/vertex-ai/docs/workbench/instances/cmek).

### Confidential Computing

You can encrypt your data-in-use by using Confidential Computing. To use Confidential Computing, you enable the Confidential VM service when you create a Vertex AI Workbench instance. To get started, see [Create an instance with Confidential Computing](/vertex-ai/docs/workbench/instances/create-confidential-computing).

## Automated shutdown for idle instances

To help manage costs, Vertex AI Workbench instances shut down after being idle for a specific time period by default. You can change the amount of time or turn this feature off. For more information, see [Idle shutdown](/vertex-ai/docs/workbench/instances/idle-shutdown).

## Add conda environments

Vertex AI Workbench instances use [kernels](https://jupyterlab.readthedocs.io/en/stable/user/documents_kernels.html) based on conda environments. You can add a conda environment to your Vertex AI Workbench instance, and the environment appears as a kernel in your instance's JupyterLab interface.

Adding conda environments lets you use kernels that aren't available in the default Vertex AI Workbench instance. For example, you can add conda environments for R and Apache Beam. Or you can add conda environments for specific earlier versions of the available frameworks, such as TensorFlow, PyTorch, or Python.

For more information, see [Add a conda environment](/vertex-ai/docs/workbench/instances/add-environment).

## Custom containers

You can create a Vertex AI Workbench instance based on a custom container. Start with a Google-provided base container image, and modify it for your needs. Then create an instance based on your custom container.

For more information, see [Create an instance using a custom container](/vertex-ai/docs/workbench/instances/create-custom-container).

## Dataproc integration

You can process data quickly by running a notebook on a Dataproc cluster. After your cluster is set up, you can run a notebook file on it without leaving the JupyterLab user interface. For more information, see [Create a Dataproc-enabled instance](/vertex-ai/docs/workbench/instances/create-dataproc-enabled).

## Reserve VM resources

Use [Compute Engine reservations](/compute/docs/instances/reservations-overview) to gain a high level of assurance that your Vertex AI Workbench instances have enough virtual machine (VM) resources to run.

Reservations are a Compute Engine feature. They help make sure that you have the resources available to create VMs with the same hardware (memory and vCPUs) and optional resources (GPUs and Local SSD disks) whenever you need them.

For more information, see [Use reservations](/vertex-ai/docs/workbench/instances/reservations).

## Create instances with third party credentials

You can create and manage Vertex AI Workbench instances with third party credentials provided by Workforce Identity Federation. Workforce Identity Federation uses your external identity provider (IdP) to grant a group of users access to Vertex AI Workbench instances through a proxy.

Access to a Vertex AI Workbench instance is granted by assigning a [workforce pool principal](/iam/docs/workforce-identity-federation#representing-workforce-users) to the Vertex AI Workbench instance's service account.

For more information, see [Create an instance with third party credentials](/vertex-ai/docs/workbench/instances/create-third-party-instance).

## Tags for Vertex AI Workbench instances

The underlying VM of a Vertex AI Workbench instance is a Compute Engine VM. You can add and manage resource tags to your Vertex AI Workbench instance through its Compute Engine VM.

When you create a Vertex AI Workbench instance, Vertex AI Workbench attaches the Compute Engine resource tag `vertex-workbench-instances:prod=READ_ONLY`. This resource tag is only used for internal purposes.

To learn more about managing tags for Compute Engine instances, see [Manage tags for resources](/compute/docs/tag-resources).

## Limitations

Consider the following limitations of Vertex AI Workbench instances when planning your project:

  * Third party JupyterLab extensions aren't supported.

  * When you use [Access Context Manager](/access-context-manager/docs/create-basic-access-level#corporate-network-example) and [Chrome Enterprise Premium](/chrome-enterprise-premium/docs/access-levels) to protect Vertex AI Workbench instances with context-aware access controls, access is evaluated each time the user authenticates to the instance. For example, access is evaluated the first time the user accesses JupyterLab and whenever they access it thereafter if their web browser's cookie has expired.

  * Using a custom container that isn't derived from the Google-provided base container (`gcr.io/deeplearning-platform-release/workbench-container:latest`) increases the risks of compatibility issues with our services and isn't supported. Instead, modify the base container to create a custom container that meets your needs, and then [create an instance using the custom container](/vertex-ai/docs/workbench/instances/create-custom-container).

  * Vertex AI Workbench instances expect images from the `cloud-notebooks-managed` project. The list of image names is available at the creation page in the Google Cloud console. Although the use of custom virtual machine (VM) images or [Deep Learning VM](/deep-learning-vm/docs/introduction) images with Vertex AI Workbench instances can be possible, Vertex AI Workbench doesn't provide any support for unexpected behaviors or malfunctions when using those images.

  * The use of a user-managed notebooks image or managed notebooks image to create a Vertex AI Workbench instance isn't supported.

  * You can't edit the underlying VM of a Vertex AI Workbench instance by using the Google Cloud console or the Compute Engine API. To edit a Vertex AI Workbench instance's underlying VM, use the [`projects.locations.instances.patch`](/vertex-ai/docs/workbench/reference/rest/v2/projects.locations.instances/patch) method in the Notebooks API or the [`gcloud workbench instances update`](/sdk/gcloud/reference/workbench/instances/update) command in the Google Cloud SDK.

  * In instances that use VPC Service Controls, use of the [executor](/vertex-ai/docs/workbench/instances/schedule-notebook-run-quickstart) isn't supported.

  * To use accelerators with Vertex AI Workbench instances, the accelerator type that you want must be available in your instance's zone. To learn about accelerator availability by zone, see [GPU regions and zones availability](/compute/docs/gpus/gpu-regions-zones).




## What's next

  * [Create a Vertex AI Workbench instance](/vertex-ai/docs/workbench/instances/create).

  * [Compare Vertex AI's notebook solutions](/vertex-ai/docs/workbench/notebook-solution).




Send feedback 

Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-10-02 UTC.

Need to tell us more?  [[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Hard to understand","hardToUnderstand","thumb-down"],["Incorrect information or sample code","incorrectInformationOrSampleCode","thumb-down"],["Missing the information/samples I need","missingTheInformationSamplesINeed","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-10-02 UTC."],[],[]] 
[Sitemap](/sitemap/sitemap.xml)

[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6ea4e8ef139b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)

Sign up

[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40williamwarley%2Fmastering-gcp-vertex-ai-with-javascript-a-comprehensive-guide-for-beginners-and-experts-6ea4e8ef139b&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)

[Medium Logo](/?source=post_page---top_nav_layout_nav-----------------------------------------)

[Write](/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)

[Search](/search?source=post_page---top_nav_layout_nav-----------------------------------------)

Sign up

[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40williamwarley%2Fmastering-gcp-vertex-ai-with-javascript-a-comprehensive-guide-for-beginners-and-experts-6ea4e8ef139b&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)

![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)

# Mastering GCP Vertex AI with JavaScript: A Comprehensive Guide for Beginners and Experts

[![Warley's CatOps](https://miro.medium.com/v2/resize:fill:64:64/1*gL9MH6lhDcuMm21JQWvsEA.jpeg)](/@williamwarley?source=post_page---byline--6ea4e8ef139b---------------------------------------)

[Warley's CatOps](/@williamwarley?source=post_page---byline--6ea4e8ef139b---------------------------------------)

36 min read

·

Sep 16, 2024

[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6ea4e8ef139b&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40williamwarley%2Fmastering-gcp-vertex-ai-with-javascript-a-comprehensive-guide-for-beginners-and-experts-6ea4e8ef139b&user=Warley%27s+CatOps&userId=f7f903618188&source=---header_actions--6ea4e8ef139b---------------------clap_footer------------------)

\--

1

[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6ea4e8ef139b&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40williamwarley%2Fmastering-gcp-vertex-ai-with-javascript-a-comprehensive-guide-for-beginners-and-experts-6ea4e8ef139b&source=---header_actions--6ea4e8ef139b---------------------bookmark_footer------------------)

Listen

Share

Press enter or click to view image in full size

## Introduction to GCP Vertex AI

**What is GCP Vertex AI?  
** Google Cloud Vertex AI is a managed machine learning (ML) platform that allows developers and data scientists to build, deploy, and scale machine learning models. Unlike traditional ML solutions that require different tools for each stage of the ML workflow (data preprocessing, model training, model deployment), Vertex AI integrates everything into one seamless environment. It supports both AutoML (where you don’t need much expertise to train models) and custom training (where you can bring your own models and code).

**Why Use Vertex AI with JavaScript?  
** While Python has traditionally dominated the machine learning ecosystem, JavaScript (especially with the rise of Node.js) is becoming a popular choice for full-stack developers. By using JavaScript to interact with Vertex AI, you can:  
_Leverage existing skills:_ If you’re already familiar with JavaScript, you don’t need to learn Python or other ML-specific languages.  
_Build end-to-end applications:_ JavaScript enables you to integrate machine learning models directly into web or mobile applications.  
_Use REST APIs and SDKs:_ Google provides APIs and SDKs that allow developers to manage and interact with Vertex AI models using JavaScript.  
_Ease of integration:_ Combine Vertex AI with JavaScript’s vast ecosystem of libraries for creating robust applications, especially with frameworks like React, Angular, and Vue.

**Vertex AI Key Features  
** Some of the standout features of Vertex AI include:  
_AutoML:_ This feature allows you to automatically train high-quality models without deep knowledge of machine learning. You simply provide the data, and Vertex AI handles the rest.  
_Custom Training:_ For more advanced users, Vertex AI allows you to train custom models using frameworks like TensorFlow, PyTorch, or Scikit-learn.  
_Model Deployment:_ After training a model, Vertex AI makes it easy to deploy the model to an endpoint for real-time predictions.  
_Scalability:_ With Google Cloud infrastructure, Vertex AI ensures your models can scale to meet production demands.  
_Pipelines:_ Vertex AI provides orchestration tools that help automate the machine learning workflow, from data preparation to deployment and _monitoring.  
Unified AI Platform: _Whether it’s data labeling, training, tuning, or serving predictions, Vertex AI brings all these functionalities under one roof.  
  
**Can Vertex AI Be Used for Production-Grade Applications?  
** Yes, Vertex AI is designed for both experimentation and production use cases. Some examples of production-grade applications include:  
_Recommendation Systems:_ Use Vertex AI to train and deploy models that provide personalized recommendations.  
_Fraud Detection:_ Build ML models to detect anomalies and fraudulent activities in real-time.  
_Natural Language Processing (NLP):_ With Vertex AI, you can create models for tasks like sentiment analysis, text summarization, or chatbots.  
_Image Classification and Object Detection:_ Train models to classify images or detect objects using AutoML or custom ML pipelines.

Vertex AI’s flexibility makes it suitable for industries ranging from healthcare to retail and finance.

## Setting Up GCP Vertex AI with JavaScript

In this chapter, we’ll walk through the steps to set up Google Cloud Platform (GCP) Vertex AI for use with JavaScript, covering everything from creating a GCP project to installing the necessary Node.js packages and authentication.

### GCP Project Setup

To get started with Vertex AI, you’ll need a Google Cloud project. If you don’t already have one, follow these steps:  
**Create a GCP Account  
**If you don’t have a Google Cloud account, create one[ here](https://cloud.google.com/). Google offers free credits for new users, which can be used to explore Vertex AI.

**Create a New Project  
** Go to the[ Google Cloud Console](https://console.cloud.google.com/).  
From the dropdown at the top, select _New Project.  
_ Provide a name for the project and an organization (if required).  
Click _Create._

**Enable Vertex AI API  
** Navigate to the _APIs & Services_ section in the Cloud Console.  
Search for “Vertex AI API” and click _Enable._

### Configuring Service Accounts

Service accounts allow your JavaScript application to interact with Google Cloud services, including Vertex AI, securely.  
**Create a Service Account  
** In the Cloud Console, go to IAM & Admin > Service Accounts.  
Click Create Service Account and give it a name and description.  
Click Create and assign the necessary roles, such as:  
Vertex AI User: This grants access to Vertex AI operations.  
Storage Admin: If you’re storing data or models in Cloud Storage.  
Click Done to finish creating the service account.

**Generate a Service Account Key  
** In the Service Accounts section, select the account you just created.  
Go to the Keys tab, and click _Add Key > Create New Key._  
Select JSON as the key type, and download the file. This JSON file contains credentials that you’ll use in your JavaScript app.

### Installing Required Node.js Packages

To interact with Vertex AI from JavaScript, we need to install several Node.js packages, including `[@google](http://twitter.com/google)-cloud/aiplatform` (for Vertex AI) and others like `[@google](http://twitter.com/google)-cloud/storage` for handling datasets and models.

**Initialize Your Node.js Project  
**If you don’t already have a Node.js project, create one:

To interact with Vertex AI from JavaScript, we need to install several Node.js packages, including `[@google](http://twitter.com/google)-cloud/aiplatform` (for Vertex AI) and others like `[@google](http://twitter.com/google)-cloud/storage` for handling datasets and models.

**Initialize Your Node.js Project**  
 _If you don’t already have a Node.js project, create one:_
    
    
     mkdir vertex-ai-js  
    cd vertex-ai-js  
    npm init -y

**Install the Google Cloud Client Libraries**  
 _You’ll need the following packages to interact with Vertex AI and other GCP services:_
    
    
     npm install @google-cloud/aiplatform @google-cloud/storage

`[@google](http://twitter.com/google)-cloud/aiplatform`: This is the Vertex AI client library for Node.js.  
`[@google](http://twitter.com/google)-cloud/storage`: Useful for managing datasets and models stored in Google Cloud Storage.

### Authenticating to Google Cloud

To allow your application to communicate with Vertex AI, you need to authenticate it using the service account key generated earlier.

**Set Up Authentication in Your JavaScript Application  
** Place the downloaded JSON key file in your project directory (e.g., `vertex-ai-js/`).  
In your JavaScript code, you can set the environment variable to point to this file or authenticate directly within your code.

**Using Environment Variables for Authentication  
**Set the environment variable `GOOGLE_APPLICATION_CREDENTIALS` to point to your JSON file:

**Using Environment Variables for Authentication**  
 _Set the environment variable `GOOGLE_APPLICATION_CREDENTIALS` to point to your JSON file:_
    
    
     export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-key.json"

**Authenticating in JavaScript Code**  
 _Alternatively, you can set up authentication directly within your code:_
    
    
     const { AIPlatformClient } = require('@google-cloud/aiplatform');  
      
    const client = new AIPlatformClient({  
      keyFilename: './path/to/your/service-account-key.json',  
    });#### 2.5 Testing Your Setup

Before diving into complex operations like training models or making predictions, it’s a good idea to test if your setup is working.

_Here’s a small script to list your existing Vertex AI models (if any):_
    
    
     const { ModelServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function listModels() {  
      const client = new ModelServiceClient();  
      
      const projectId = 'your-project-id';  
      const location = 'us-central1';  // Adjust to your region  
      const parent = `projects/${projectId}/locations/${location}`;  
      
      const [models] = await client.listModels({ parent });  
      
      models.forEach(model => {  
        console.log(`Model name: ${model.displayName}`);  
        console.log(`Model id: ${model.name}`);  
      });  
    }  
      
    listModels().catch(console.error);

Replace `your-project-id` with your actual Google Cloud project ID.  
You can run this script using Node.js:
    
    
    node listModels.js

If your setup is correct, this script should return a list of models in your Vertex AI environment (or none if you haven’t created any yet).  
With this setup, you’re now ready to start using GCP Vertex AI with JavaScript.

## Exploring Vertex AI Components

In this chapter, we will explore the core components of Google Cloud Vertex AI that you’ll interact with when using JavaScript, including training models, managing datasets, and using the prediction service. We will cover the essential tools and concepts required to get started with Vertex AI.

### Training Models

Vertex AI provides two primary ways to train models:  
_AutoML_ : Google’s AutoML service allows you to train machine learning models without having to write custom ML code. This is particularly useful for tasks like image classification, object detection, and natural language processing (NLP).  
_Custom Training:_ For more advanced users, Vertex AI allows you to upload and train custom models using frameworks such as TensorFlow, PyTorch, or Scikit-learn.

**How to Train Models with Vertex AI using JavaScript  
** To train a model using AutoML with JavaScript, follow these steps:

**Prepare a Dataset  
**Before training, you need a labeled dataset stored in Google Cloud Storage. For example, an image classification dataset can be a set of images, each associated with a label.

**Create a Dataset in Vertex AI  
** Use JavaScript to create a new dataset in Vertex AI:
    
    
    const { DatasetServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function createDataset() {  
      const client = new DatasetServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  // Adjust to your region  
      const parent = `projects/${projectId}/locations/${location}`;  
      
      const dataset = {  
        displayName: 'your-dataset-name',  
        metadataSchemaUri: 'gs://google-cloud-aiplatform/schema/dataset/metadata/image_1.0.0.yaml',  // for image dataset  
      };  
      
      const [operation] = await client.createDataset({  
        parent,  
        dataset,  
      });  
      const [response] = await operation.promise();  
      console.log(`Dataset created: ${response.name}`);  
    }  
      
    createDataset().catch(console.error);

Adjust the metadata schema URI based on the type of data you’re using (e.g., text, tabular, image).

**Training a Model using AutoML**  
After creating and uploading the dataset, you can use JavaScript to initiate a training job:
    
    
    const { PipelineServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function createTrainingPipeline() {  
      const client = new PipelineServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  // Adjust to your region  
      const datasetId = 'your-dataset-id';  // The dataset created above  
      const parent = `projects/${projectId}/locations/${location}`;  
      
      const trainingPipeline = {  
        displayName: 'image-classification-model',  
        inputDataConfig: {  
          datasetId: datasetId,  
        },  
        modelToUpload: {  
          displayName: 'image-classifier',  
        },  
        trainingTaskInputs: {  
          modelType: 'CLOUD',  
          baseModelId: '',  
        },  
      };  
      
      const [operation] = await client.createTrainingPipeline({  
        parent,  
        trainingPipeline,  
      });  
      const [response] = await operation.promise();  
      console.log(`Training pipeline created: ${response.name}`);  
    }  
      
    createTrainingPipeline().catch(console.error);

This snippet initiates an AutoML training job for an image classification model.

### Deploying Models

Once a model is trained, it needs to be deployed to an endpoint where it can serve predictions. Vertex AI makes deploying models easy, with built-in endpoints for real-time predictions or batch processing.

_Here’s how to deploy a model using JavaScript:_
    
    
     const { EndpointServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function deployModel() {  
      const client = new EndpointServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  // Adjust to your region  
      const endpointId = 'your-endpoint-id';  
      const modelId = 'your-model-id';  // The trained model  
      
      const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
      
      const [operation] = await client.deployModel({  
        endpoint,  
        deployedModel: {  
          model: `projects/${projectId}/locations/${location}/models/${modelId}`,  
          displayName: 'my-deployed-model',  
        },  
        trafficSplit: { 0: 100 },  // Direct 100% traffic to this model  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Model deployed: ${response.deployedModelId}`);  
    }  
      
    deployModel().catch(console.error);

You need to provide the `modelId` and `endpointId` (the endpoint where the model will be deployed).

### Managing Datasets

Datasets are a crucial part of the machine learning process, and Vertex AI provides various tools for managing datasets, from creation to versioning.

_JavaScript Code Example for Listing Datasets_
    
    
     const { DatasetServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function listDatasets() {  
      const client = new DatasetServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  // Adjust to your region  
      
      const [datasets] = await client.listDatasets({  
        parent: `projects/${projectId}/locations/${location}`,  
      });  
      
      datasets.forEach(dataset => {  
        console.log(`Dataset ID: ${dataset.name}`);  
        console.log(`Dataset Display Name: ${dataset.displayName}`);  
      });  
    }  
      
    listDatasets().catch(console.error);

This code will list all the datasets associated with your project in a particular region.

### Prediction Service Overview

Vertex AI allows for two types of predictions:  
_Real-time Predictions_ : Deployed models can be queried for immediate predictions.  
_Batch Predictions:_ For larger datasets, you can run batch prediction jobs.

**Real-Time Predictions with JavaScript  
** Once a model is deployed, you can make predictions as follows:
    
    
    const { PredictionServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function predict() {  
      const client = new PredictionServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  // Adjust to your region  
      const endpointId = 'your-endpoint-id';  
      const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
      
      const instance = { /* Your input data */ };  
      const instances = [instance];  
      
      const [response] = await client.predict({  
        endpoint,  
        instances,  
      });  
      
      console.log(`Prediction results: ${JSON.stringify(response.predictions)}`);  
    }  
      
    predict().catch(console.error);

The input data format will depend on the type of model you have deployed (e.g., image, text, tabular data).  
This chapter covered the essential components of Vertex AI and how to interact with them using JavaScript.

## Training a Machine Learning Model Using JavaScript

In this chapter, we’ll explore how to train machine learning models on Google Cloud Vertex AI using JavaScript. We’ll go through the process of preparing data, choosing between AutoML and custom training, and provide JavaScript code examples that you can use as templates.

### Preparing Data for Training

Before training any machine learning model, the first step is to prepare and upload the data. The data needs to be stored in Google Cloud Storage, and it must be properly formatted for the type of model you want to train (e.g., tabular data, images, or text).

**Steps to Prepare Data:  
Format Your Data  
**Depending on the task, data formats can vary:  
_For image classification:_ The dataset should consist of images organized in folders by their class.  
_For text classification:_ Store your text data in a CSV file where one column contains the text and another column contains the label.  
_For tabular data:_ Store your structured data (e.g., CSV) with clearly defined columns for features and labels.

**Upload Data to Google Cloud Storage  
**To train a model, you need to upload your dataset to Google Cloud Storage:  
  
Go to the _Google Cloud Console > Cloud Storage > Create Bucket.  
_Upload your dataset into this bucket.

**_Code Example: Uploading Data to Cloud Storage  
_** You can automate uploading files to Google Cloud Storage using the `[@google](http://twitter.com/google)-cloud/storage` library.
    
    
    const { Storage } = require('@google-cloud/storage');  
    const storage = new Storage();  
      
    async function uploadFile(bucketName, filePath) {  
      await storage.bucket(bucketName).upload(filePath, {  
        gzip: true,  
        metadata: {  
          cacheControl: 'no-cache',  
        },  
      });  
      
      console.log(`${filePath} uploaded to ${bucketName}`);  
    }  
      
    // Replace with your bucket name and file path  
    uploadFile('your-bucket-name', 'path/to/local/file').catch(console.error);

Once your data is uploaded, you’re ready to create a dataset in Vertex AI.

### Using AutoML for Quick Training

AutoML simplifies the process of training models by allowing you to create high-quality models with minimal expertise. Here’s how to train a model using AutoML with JavaScript.

**Steps to Train a Model with AutoML:  
Create a Dataset in Vertex AI  
**Use the dataset you uploaded in Cloud Storage to create a dataset in Vertex AI.
    
    
    const { DatasetServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function createDataset() {  
      const client = new DatasetServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
        
      const dataset = {  
        displayName: 'my-dataset',  
        metadataSchemaUri: 'gs://google-cloud-aiplatform/schema/dataset/metadata/image_1.0.0.yaml',  
        gcsSource: {  
          uris: ['gs://your-bucket-name/your-data-path/']  
        },  
      };  
      
      const parent = `projects/${projectId}/locations/${location}`;  
      const [operation] = await client.createDataset({  
        parent,  
        dataset,  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Dataset created: ${response.name}`);  
    }  
      
    createDataset().catch(console.error);

**Create a Training Pipeline**  
After your dataset is created, you can create a training pipeline using AutoML.
    
    
    const { PipelineServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function createTrainingPipeline() {  
      const client = new PipelineServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
        
      const trainingPipeline = {  
        displayName: 'my-image-classification-pipeline',  
        inputDataConfig: {  
          datasetId: 'your-dataset-id',  
        },  
        modelToUpload: {  
          displayName: 'my-image-classification-model',  
        },  
        trainingTaskInputs: {  
          modelType: 'CLOUD',  
        },  
      };  
      
      const parent = `projects/${projectId}/locations/${location}`;  
      const [operation] = await client.createTrainingPipeline({  
        parent,  
        trainingPipeline,  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Training pipeline created: ${response.name}`);  
    }  
      
    createTrainingPipeline().catch(console.error);

**Monitor Training Progress  
**Once the training job starts, you can monitor its status through the Vertex AI console or by querying the API.

### Custom Model Training with Vertex AI

If you require more control over the training process, you can train custom models using frameworks like TensorFlow or PyTorch. Custom model training allows you to bring your own training code and run it on Google’s infrastructure.

**Steps to Train Custom Models:  
**_Create a Training Container_   
You’ll need a Docker container that includes your custom training code. The container should be pushed to Google Container Registry (GCR).

_Submit a Custom Training Job  
_ After the container is uploaded to GCR, you can create a custom training job. Here’s how to submit a job with JavaScript:
    
    
    const { JobServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function submitCustomTrainingJob() {  
      const client = new JobServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      
      const customJob = {  
        displayName: 'my-custom-job',  
        jobSpec: {  
          workerPoolSpecs: [  
            {  
              containerSpec: {  
                imageUri: 'gcr.io/your-project-id/your-training-container',  
                command: ['python3', 'train.py'],  // Command to start training  
              },  
              machineSpec: {  
                machineType: 'n1-standard-4',  
              },  
            },  
          ],  
        },  
      };  
      
      const parent = `projects/${projectId}/locations/${location}`;  
      const [operation] = await client.createCustomJob({  
        parent,  
        customJob,  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Custom training job submitted: ${response.name}`);  
    }  
      
    submitCustomTrainingJob().catch(console.error);

This script submits a custom training job that runs in the specified container on Google Cloud.

### JavaScript Code Example for Model Training

Here’s a complete flow for training a model using AutoML, from uploading data to Cloud Storage to initiating a training pipeline.
    
    
    const { Storage } = require('@google-cloud/storage');  
    const { DatasetServiceClient, PipelineServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    // Upload Data to Google Cloud Storage  
    async function uploadFile(bucketName, filePath) {  
      const storage = new Storage();  
      await storage.bucket(bucketName).upload(filePath, {  
        gzip: true,  
        metadata: { cacheControl: 'no-cache' },  
      });  
      console.log(`${filePath} uploaded to ${bucketName}`);  
    }  
      
    // Create Dataset  
    async function createDataset() {  
      const client = new DatasetServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      
      const dataset = {  
        displayName: 'my-dataset',  
        metadataSchemaUri: 'gs://google-cloud-aiplatform/schema/dataset/metadata/image_1.0.0.yaml',  
        gcsSource: {  
          uris: ['gs://your-bucket-name/your-data-path/']  
        },  
      };  
      
      const parent = `projects/${projectId}/locations/${location}`;  
      const [operation] = await client.createDataset({  
        parent,  
        dataset,  
      });  
      const [response] = await operation.promise();  
      console.log(`Dataset created: ${response.name}`);  
    }  
      
    // Create Training Pipeline  
    async function createTrainingPipeline() {  
      const client = new PipelineServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      
      const trainingPipeline = {  
        displayName: 'my-image-classification-pipeline',  
        inputDataConfig: {  
          datasetId: 'your-dataset-id',  
        },  
        modelToUpload: {  
          displayName: 'my-image-classification-model',  
        },  
        trainingTaskInputs: {  
          modelType: 'CLOUD',  
        },  
      };  
      
      const parent = `projects/${projectId}/locations/${location}`;  
      const [operation] = await client.createTrainingPipeline({  
        parent,  
        trainingPipeline,  
      });  
      const [response] = await operation.promise();  
      console.log(`Training pipeline created: ${response.name}`);  
    }  
      
    (async () => {  
      await uploadFile('your-bucket-name', 'path/to/local/file');  
      await createDataset();  
      await createTrainingPipeline();  
    })();

This end-to-end script allows you to upload data, create a dataset, and initiate a training pipeline, all using JavaScript.  
This concludes the chapter on training machine learning models using Vertex AI and JavaScript.

## Deploying Models on Vertex AI

In this chapter, we will explore how to deploy machine learning models using Google Cloud Vertex AI with JavaScript. Model deployment is a crucial step in turning your trained machine learning models into real-time or batch-serving services that users or applications can interact with. We will also cover monitoring deployed models and provide code examples to help guide you through the deployment process.

### Creating and Managing Endpoints

An _endpoint_ is where your deployed model will serve predictions. Once you have trained a model, it needs to be deployed to an endpoint so that it can process requests for predictions in real-time.

**Steps to Create an Endpoint:  
**_Initialize Vertex AI Endpoint Service Client  
_ The `EndpointServiceClient` from the `[@google](http://twitter.com/google)-cloud/aiplatform` library allows you to create and manage endpoints in Vertex AI.  
_Create an Endpoint for Your Model  
_ To create an endpoint, you need to define some metadata like the display name. Here’s how to create an endpoint using JavaScript:
    
    
    const { EndpointServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function createEndpoint() {  
      const client = new EndpointServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1'; // Adjust to your region  
      
      const parent = `projects/${projectId}/locations/${location}`;  
      const endpoint = {  
        displayName: 'my-model-endpoint',  
      };  
      
      const [operation] = await client.createEndpoint({  
        parent,  
        endpoint,  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Endpoint created: ${response.name}`);  
    }  
      
    createEndpoint().catch(console.error);

This script creates an endpoint where models can be deployed for real-time predictions.

### Deploying a Model Using JavaScript

Once an endpoint is created, you can deploy your trained model to this endpoint. A deployed model is a containerized version of your trained model that can handle real-time requests.

**Steps to Deploy a Model:  
**_Initialize the Deployment Service  
_After creating an endpoint, you can deploy the model to it using the same `EndpointServiceClient`.  
_Deploy a Model to the Endpoint  
_In this step, we provide the model ID (from the trained model) and link it to the endpoint.
    
    
    const { EndpointServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function deployModel() {  
      const client = new EndpointServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  // Adjust to your region  
      const endpointId = 'your-endpoint-id';  // The endpoint created earlier  
      const modelId = 'your-model-id';  // The trained model's ID  
      
      const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
      
      const [operation] = await client.deployModel({  
        endpoint,  
        deployedModel: {  
          model: `projects/${projectId}/locations/${location}/models/${modelId}`,  
          displayName: 'my-deployed-model',  
        },  
        trafficSplit: { 0: 100 },  // Send 100% of traffic to this model  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Model deployed: ${response.deployedModelId}`);  
    }  
      
    deployModel().catch(console.error);

The `trafficSplit` parameter allows you to divide traffic among multiple models. In this case, all traffic is routed to the new model.

### Monitoring Deployed Models

Once the model is deployed, it’s important to monitor its performance to ensure it’s working correctly and efficiently. Vertex AI provides built-in monitoring tools that track:  
_Latency:_ The time it takes for the model to respond to a prediction request.  
_Model performance:_ Metrics like prediction accuracy or other business-specific KPIs.  
_Traffic_ : How many requests the model is receiving.

**Monitoring via the Vertex AI Console  
** You can monitor your deployed models via the Google Cloud Console by navigating to _Vertex AI > Endpoints > Monitoring_. This interface provides real-time statistics on latency, traffic, and errors.

**Automated Monitoring in JavaScript  
** While you can use the console for real-time monitoring, it’s possible to automate some monitoring tasks using JavaScript, such as logging metrics or setting up alerts.
    
    
    const { EndpointServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function getEndpoint() {  
      const client = new EndpointServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      const endpointId = 'your-endpoint-id';  
      
      const endpointName = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
      const [endpoint] = await client.getEndpoint({ name: endpointName });  
      
      console.log(`Endpoint name: ${endpoint.displayName}`);  
      console.log(`Deployed model ID: ${endpoint.deployedModels[0].id}`);  
      console.log(`Traffic split: ${JSON.stringify(endpoint.trafficSplit)}`);  
    }  
      
    getEndpoint().catch(console.error);

This code fetches and prints out the current status of the endpoint, including deployed models and traffic splits.

### **JavaScript Code Example for Model Deployment**

Here’s an end-to-end example that includes creating an endpoint and deploying a model to it, all using JavaScript:
    
    
    const { EndpointServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function createAndDeployModel() {  
      const client = new EndpointServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
        
      // Step 1: Create an Endpoint  
      const parent = `projects/${projectId}/locations/${location}`;  
      const endpoint = { displayName: 'my-model-endpoint' };  
        
      const [createEndpointOperation] = await client.createEndpoint({  
        parent,  
        endpoint,  
      });  
        
      const [createEndpointResponse] = await createEndpointOperation.promise();  
      const endpointId = createEndpointResponse.name.split('/').pop();  
      console.log(`Endpoint created: ${createEndpointResponse.name}`);  
        
      // Step 2: Deploy the Model to the Endpoint  
      const modelId = 'your-model-id';  // Replace with your trained model's ID  
      const endpointName = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
        
      const [deployModelOperation] = await client.deployModel({  
        endpoint: endpointName,  
        deployedModel: {  
          model: `projects/${projectId}/locations/${location}/models/${modelId}`,  
          displayName: 'my-deployed-model',  
        },  
        trafficSplit: { 0: 100 },  
      });  
        
      const [deployModelResponse] = await deployModelOperation.promise();  
      console.log(`Model deployed: ${deployModelResponse.deployedModelId}`);  
    }  
      
    createAndDeployModel().catch(console.error);

**This script walks through the entire process:**  
Creates an endpoint where the model will be deployed.  
Deploys a trained model to that endpoint.

### Real-time vs Batch Predictions

Once a model is deployed, you can choose between:  
**Real-time Predictions:** Ideal for applications that need immediate predictions, such as chatbots, recommendation systems, or fraud detection.  
**Batch Predictions:** Suitable for larger datasets where real-time response isn’t required, like processing thousands of images or performing data transformations.

We’ll cover making predictions in the next chapter.  
This concludes the chapter on deploying models using Google Cloud Vertex AI and JavaScript.

## Making Predictions Using Deployed Models

In this chapter, we will explore how to make predictions using deployed models on Google Cloud Vertex AI. Vertex AI supports both real-time and batch predictions, and we’ll walk through how to use JavaScript to interact with the deployed models for both prediction types.

### Prediction Workflow Overview

Once a model is deployed to an endpoint, you can start sending requests to it to receive predictions. Here’s the general workflow for making predictions:  
_Prepare Input Data:_ Format the input data in a way that matches what the model expects (e.g., image, text, or tabular data).  
_Send a Prediction Request:_ Use the Vertex AI API to send a prediction request to the model’s endpoint.  
_Handle the Response:_ The API will return predictions, which can then be used in your application.  
You can use either real-time predictions (immediate response) or batch predictions (process large amounts of data).

### Real-Time Predictions

Real-time predictions are useful for applications where you need immediate responses, such as chatbots, recommendation systems, or fraud detection systems. To make real-time predictions, you send requests to the endpoint where the model is deployed.

**Steps for Making Real-Time Predictions:  
**_Prepare the Input Data:  
_The input data format will depend on the type of model deployed (e.g., image, text, tabular). Make sure the data is structured correctly to match the model’s input requirements.  
_Send a Real-Time Prediction Request:  
_ Here’s a JavaScript example for sending a real-time prediction request to a deployed model using the Vertex AI API:
    
    
    const { PredictionServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function predict() {  
      const client = new PredictionServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  // Adjust to your region  
      const endpointId = 'your-endpoint-id';  // The endpoint where the model is deployed  
      
      const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
        
      // Define the input instances for your model (this will vary based on the model type)  
      const instance = {  
        // Example for a tabular model  
        // Replace with your own input data structure  
        values: [1.0, 2.0, 3.0, 4.0]  // Example input features  
      };  
      const instances = [instance];  // You can send multiple instances in one request  
      
      // Send prediction request  
      const [response] = await client.predict({  
        endpoint,  
        instances,  
      });  
      
      // Handle the response  
      console.log(`Prediction results: ${JSON.stringify(response.predictions)}`);  
    }  
      
    predict().catch(console.error);

**Explanation:  
**_Endpoint:_ The location of your deployed model.  
_Instances:_ The data you want to send for prediction. For example, in a tabular model, this could be feature values, and in an image model, it could be base64-encoded images.  
_Response:_ The model’s predictions, returned as an array of values.

**_Example Use Cases for Real-Time Predictions:_**_  
Chatbots:_ Use a natural language processing (NLP) model to generate responses to user queries.  
_Recommendation Systems:_ Serve product or content recommendations in real-time.  
_Fraud Detection:_ Detect suspicious transactions on a live system using a classification model.

### Batch Predictions

Batch predictions are useful when you have large datasets that need to be processed, but real-time results aren’t necessary. With batch predictions, you submit a job to Vertex AI and it processes the data in the background, returning the results once the job is complete.

**Steps for Making Batch Predictions:  
**_Prepare the Input Data:  
_For batch predictions, the input data is typically stored in Google Cloud Storage in formats like CSV or JSONL.

_Create a Batch Prediction Job:  
_ Here’s how to create a batch prediction job using JavaScript:
    
    
    const { JobServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function createBatchPredictionJob() {  
      const client = new JobServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  // Adjust to your region  
      const modelId = 'your-model-id';  // The model to use for batch prediction  
      
      const inputConfig = {  
        gcsSource: { uris: ['gs://your-bucket/input-data.csv'] },  // Replace with your input data location  
      };  
        
      const outputConfig = {  
        gcsDestination: { outputUriPrefix: 'gs://your-bucket/output-results/' },  // Replace with your output bucket  
      };  
      
      const job = {  
        displayName: 'my-batch-prediction-job',  
        model: `projects/${projectId}/locations/${location}/models/${modelId}`,  
        inputConfig,  
        outputConfig,  
        dedicatedResources: {  
          machineSpec: {  
            machineType: 'n1-standard-4',  
          },  
          minReplicaCount: 1,  
          maxReplicaCount: 2,  
        },  
      };  
      
      const parent = `projects/${projectId}/locations/${location}`;  
      const [operation] = await client.createBatchPredictionJob({  
        parent,  
        batchPredictionJob: job,  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Batch prediction job created: ${response.name}`);  
    }  
      
    createBatchPredictionJob().catch(console.error);

**_Explanation:  
_**_InputConfig:_ Specifies the location of the input data (e.g., in Google Cloud Storage).  
_OutputConfig:_ Specifies where to store the output results (e.g., in a Google Cloud Storage bucket).  
_Job Configuration:_ You can define the resources for running the batch job, including the number and type of machine instances.

**Monitor Batch Prediction Job:  
**You can monitor the batch prediction job through the Vertex AI console or programmatically check the status of the job using the `JobServiceClient` API.

**_Example Use Cases for Batch Predictions:  
_**_Image Processing:_ Process a large dataset of images for classification or object detection.  
_Data Analytics:_ Run predictions on a large set of customer data for segmentation or risk analysis.  
_Document Processing:_ Use machine learning to extract information from thousands of documents in a batch.

### Handling Predictions in Applications

Once you receive the prediction results (either real-time or batch), you can integrate them into your application’s business logic. For example:  
_Web Apps:_ Show personalized recommendations based on real-time predictions.  
_Mobile Apps:_ Use predictions to offer location-based services or product suggestions.  
_Data Pipelines:_ Incorporate batch predictions into a larger data pipeline for reporting or analytics.

### JavaScript Code Example for Predictions

Here’s a summary of the code you can use for both real-time and batch predictions:

**_Real-Time Prediction Example:_**
    
    
     const { PredictionServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function predict() {  
      const client = new PredictionServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  // Adjust to your region  
      const endpointId = 'your-endpoint-id';  // The endpoint where the model is deployed  
      
      const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
        
      const instance = { values: [1.0, 2.0, 3.0, 4.0] };  // Example input features  
      const instances = [instance];  
      
      const [response] = await client.predict({  
        endpoint,  
        instances,  
      });  
      
      console.log(`Prediction results: ${JSON.stringify(response.predictions)}`);  
    }  
      
    predict().catch(console.error);

**_Batch Prediction Example:_**
    
    
     const { JobServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function createBatchPredictionJob() {  
      const client = new JobServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      const modelId = 'your-model-id';  
      
      const inputConfig = {  
        gcsSource: { uris: ['gs://your-bucket/input-data.csv'] },  
      };  
      
      const outputConfig = {  
        gcsDestination: { outputUriPrefix: 'gs://your-bucket/output-results/' },  
      };  
      
      const job = {  
        displayName: 'my-batch-prediction-job',  
        model: `projects/${projectId}/locations/${location}/models/${modelId}`,  
        inputConfig,  
        outputConfig,  
        dedicatedResources: {  
          machineSpec: {  
            machineType: 'n1-standard-4',  
          },  
          minReplicaCount: 1,  
          maxReplicaCount: 2,  
        },  
      };  
      
      const parent = `projects/${projectId}/locations/${location}`;  
      const [operation] = await client.createBatchPredictionJob({  
        parent,  
        batchPredictionJob: job,  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Batch prediction job created: ${response.name}`);  
    }  
      
    createBatchPredictionJob().catch(console.error);

This concludes the chapter on _Making Predictions Using Deployed Models._

## Monitoring and Managing AI Models in Vertex AI

In this chapter, we will focus on how to monitor and manage deployed machine learning models using Vertex AI. Monitoring is crucial for understanding the performance of your models in production, identifying issues, and ensuring that your models are up-to-date and accurate. We will also explore version control, model pipelines, and provide some practical JavaScript code examples for managing models.

### How to Monitor Model Performance

Once a model is deployed, it’s essential to track its performance over time to ensure it behaves as expected. Vertex AI provides several tools for monitoring, including metrics for latency, error rates, traffic, and predictions.

**Metrics to Monitor:  
**_Latency:_ How long the model takes to respond to a prediction request.  
_Prediction Accuracy:_ You may have your own way to track prediction accuracy (e.g., comparing predictions with actual outcomes).  
_Traffic Volume:_ The number of requests being served by the model.  
_Error Rates:_ How often the model fails or produces invalid predictions.

**Monitoring Using Google Cloud Console:  
** Navigate to _Google Cloud Console > Vertex AI > Endpoints_ to view the deployed model’s endpoint.  
Click on the _Monitoring_ tab to see real-time metrics, including latency, traffic, and error rates.  
You can also set up _alerts_ to notify you if a certain threshold is crossed (e.g., if latency becomes too high or error rates increase).

**Monitoring Programmatically with JavaScript:  
** While most of the monitoring is done via the console, you can also retrieve some monitoring information programmatically using JavaScript.

_Here’s how you can get the current status of an endpoint, including deployed model details and traffic information:_
    
    
     const { EndpointServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function getEndpointStatus() {  
      const client = new EndpointServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  // Adjust to your region  
      const endpointId = 'your-endpoint-id';  
      
      const endpointName = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
      const [endpoint] = await client.getEndpoint({ name: endpointName });  
      
      console.log(`Endpoint: ${endpoint.displayName}`);  
      console.log(`Deployed Models: ${endpoint.deployedModels.length}`);  
      endpoint.deployedModels.forEach((model) => {  
        console.log(`Model Display Name: ${model.displayName}`);  
        console.log(`Traffic Split: ${model.trafficSplit}`);  
      });  
    }  
      
    getEndpointStatus().catch(console.error);

This script fetches the current status of an endpoint and prints out key details like deployed models and traffic split.

### Using Vertex AI’s Built-in Monitoring Tools

Vertex AI provides integrated monitoring tools to help you observe and track model performance:  
_AI Platform Dashboards:_ Visualize and track real-time model performance and metrics like latency, throughput, and error rates.  
_Google Cloud Monitoring:_ Provides alerts, notifications, and detailed logging that can be configured for the Vertex AI models.  
_Error Tracking:_ Helps you identify and log erroneous predictions and take action accordingly.

### Managing Model Versions

As you continue improving and retraining your models, you will likely have multiple versions of a model. Vertex AI allows you to manage multiple versions, enabling you to:  
_Deploy multiple versions:_ Route a percentage of traffic to different versions to test performance.  
_Rollback to previous versions:_ If a new model version underperforms, you can easily revert to an earlier version.  
_Versioning best practices:_ Label and track each model version carefully so that changes can be tracked over time.

**JavaScript Example for Managing Model Versions:  
**_List Model Versions:  
_ You can list all versions of a model using the following script:
    
    
    const { ModelServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function listModelVersions() {  
      const client = new ModelServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      const modelId = 'your-model-id';  // Model you want to check versions for  
      
      const modelName = `projects/${projectId}/locations/${location}/models/${modelId}`;  
      const [versions] = await client.listModelVersions({ name: modelName });  
      
      versions.forEach((version) => {  
        console.log(`Model Version: ${version.versionId}`);  
        console.log(`Version Display Name: ${version.displayName}`);  
      });  
    }  
      
    listModelVersions().catch(console.error);

_Deploy a Specific Model Version:_  
If you want to deploy a specific version of a model, you can modify the deployment code by specifying the `versionId` in the model path:
    
    
    const { EndpointServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function deploySpecificVersion() {  
      const client = new EndpointServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';    
      const endpointId = 'your-endpoint-id';  
      const modelId = 'your-model-id';  
      const versionId = 'your-version-id';  // Specify the version to deploy  
      
      const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
      
      const [operation] = await client.deployModel({  
        endpoint,  
        deployedModel: {  
          model: `projects/${projectId}/locations/${location}/models/${modelId}@${versionId}`,  
          displayName: 'my-model-version-deployment',  
        },  
        trafficSplit: { 0: 100 },  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Deployed model version: ${response.deployedModelId}`);  
    }  
      
    deploySpecificVersion().catch(console.error);

This script deploys a specific version of the model, which can be helpful for A/B testing or when rolling back to a previous version.

**Managing Model Pipelines  
** A _pipeline_ in Vertex AI allows you to automate and orchestrate the machine learning workflow, including data ingestion, preprocessing, model training, and model evaluation. Vertex AI pipelines help you automate these tasks and improve productivity by enabling reusable workflows.

**Steps for Creating a Pipeline:  
**_Define the Steps in the Pipeline:_ This can include data preprocessing, training, evaluation, and deployment.  
_Use Google Cloud Pipelines API:_ Automate the pipeline creation and execution process.  
_Monitor and Manage Pipelines:_ You can track the pipeline’s progress and debug any failures via the Google Cloud Console or programmatically.

_Here’s how you can use Vertex AI pipelines with JavaScript:_
    
    
     const { PipelineServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function createPipeline() {  
      const client = new PipelineServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      
      const parent = `projects/${projectId}/locations/${location}`;  
      const pipelineJob = {  
        displayName: 'my-ml-pipeline',  
        trainingPipeline: {  
          displayName: 'training-step',  
          inputDataConfig: {  
            datasetId: 'your-dataset-id',  
          },  
          modelToUpload: {  
            displayName: 'my-trained-model',  
          },  
        },  
      };  
      
      const [operation] = await client.createPipelineJob({  
        parent,  
        pipelineJob,  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Pipeline created: ${response.name}`);  
    }  
      
    createPipeline().catch(console.error);

This script creates a simple ML pipeline that automates the model training step, but it can be expanded to include more complex workflows.

### JavaScript Snippets for Managing Models

Here are additional JavaScript snippets that can help you manage models on Vertex AI:

_Update a Deployed Model:_
    
    
     const { EndpointServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function updateDeployedModel() {  
      const client = new EndpointServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      const endpointId = 'your-endpoint-id';  
      
      const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
        
      const [operation] = await client.undeployModel({  
        endpoint,  
        deployedModelId: 'your-deployed-model-id',  
        trafficSplit: { 0: 100 },  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Model undeployed: ${response}`);  
    }  
      
    updateDeployedModel().catch(console.error);

_Delete a Model:_
    
    
     const { ModelServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function deleteModel() {  
      const client = new ModelServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      const modelId = 'your-model-id';  
      
      const modelName = `projects/${projectId}/locations/${location}/models/${modelId}`;  
      const [operation] = await client.deleteModel({ name: modelName });  
      const [response] = await operation.promise();  
      console.log(`Model deleted: ${response}`);  
    }  
      
    deleteModel().catch(console.error);

This chapter covered essential aspects of _Monitoring and Managing AI Models in Vertex AI_ , including performance tracking, version management, and pipeline orchestration.

## Best Practices and Tips for Working with Vertex AI

In this chapter, we’ll cover essential best practices and tips for working efficiently with Google Cloud Vertex AI. These tips will help you optimize your workflow, reduce costs, maintain security, and manage version control for models and datasets effectively.

**Optimizing Costs  
** Machine learning operations on Vertex AI, especially model training and deployment, can become costly if not managed properly. Here are some strategies to optimize your usage and minimize costs:

**Choose the Right Machine Type  
** _Training Jobs:_ For smaller datasets or less complex models, using standard machine types (like `n1-standard-4`) is more cost-effective. Use high-performance GPUs (e.g., Tesla T4, P100) only when necessary for complex models like deep learning.  
_Prediction Jobs:_ For real-time predictions, use _autoscaling_ to dynamically allocate resources based on traffic. Set appropriate minimum and maximum replicas to avoid over-provisioning.
    
    
    // Example of deploying a model with autoscaling:  
    const { EndpointServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function deployModelWithAutoscaling() {  
      const client = new EndpointServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      const endpointId = 'your-endpoint-id';  
      const modelId = 'your-model-id';  
      
      const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
      
      const [operation] = await client.deployModel({  
        endpoint,  
        deployedModel: {  
          model: `projects/${projectId}/locations/${location}/models/${modelId}`,  
          displayName: 'my-deployed-model',  
        },  
        automaticResources: {  
          minReplicaCount: 1,  // Start with a minimum replica  
          maxReplicaCount: 3,  // Automatically scale up to 3 replicas  
        },  
        trafficSplit: { 0: 100 },  // Send all traffic to this model  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Model deployed: ${response.deployedModelId}`);  
    }  
      
    deployModelWithAutoscaling().catch(console.error);

**Use Preemptible VMs for Training**  
Preemptible virtual machines are much cheaper than standard VMs, but they can be terminated by Google Cloud at any time. If your training jobs can handle interruptions, use preemptible VMs to save costs.

_How to Use Preemptible VMs:_  
You can specify preemptible VMs when configuring your training jobs.
    
    
    const { JobServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    async function createPreemptibleTrainingJob() {  
      const client = new JobServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      
      const customJob = {  
        displayName: 'my-preemptible-job',  
        jobSpec: {  
          workerPoolSpecs: [  
            {  
              machineSpec: {  
                machineType: 'n1-standard-4',  
                acceleratorType: 'NVIDIA_TESLA_T4',  
                acceleratorCount: 1,  
              },  
              replicaCount: 1,  
              preemptible: true,  // Enable preemptible instances  
              containerSpec: {  
                imageUri: 'gcr.io/your-project-id/your-container-image',  
                command: ['python3', 'train.py'],  
              },  
            },  
          ],  
        },  
      };  
      
      const parent = `projects/${projectId}/locations/${location}`;  
      const [operation] = await client.createCustomJob({  
        parent,  
        customJob,  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Custom preemptible training job created: ${response.name}`);  
    }  
      
    createPreemptibleTrainingJob().catch(console.error);

**Optimize Dataset Size  
** Before training your model, clean your dataset and remove unnecessary features or rows that don’t add value. This reduces storage costs in Google Cloud Storage and speeds up training times, which can reduce the overall cost.

**Schedule Batch Predictions During Off-Peak Hours  
** If possible, schedule batch prediction jobs during off-peak hours to take advantage of lower cloud usage rates and ensure resources are available.

### Security Best Practices

Security is a key consideration when working with machine learning models and data. Vertex AI provides several built-in tools to ensure that your data, models, and endpoints are secure.

**Use IAM for Role-Based Access Control  
** _Principle of Least Privilege:_ Always grant the minimum necessary permissions to users and service accounts. Use predefined roles such as `Vertex AI Admin`, `Vertex AI User`, and `Vertex AI Viewer` to limit access.  
_Service Account Separation:_ Use different service accounts for development, staging, and production environments.

_You can manage IAM roles for Vertex AI through the Google Cloud Console or via API:_
    
    
     const { IAM } = require('@google-cloud/iam');  
      
    async function grantVertexAIRole() {  
      const iam = new IAM();  
      const projectId = 'your-project-id';  
      const role = 'roles/aiplatform.admin';  // Vertex AI Admin Role  
      const member = 'user:example@example.com';  // Replace with user email  
      
      const policy = {  
        bindings: [  
          {  
            role: role,  
            members: [member],  
          },  
        ],  
      };  
      
      await iam.projects.roles.setIamPolicy({  
        resource: `projects/${projectId}`,  
        policy,  
      });  
      
      console.log(`Role assigned successfully.`);  
    }  
      
    grantVertexAIRole().catch(console.error);

**Use VPC Service Controls  
** VPC Service Controls provide additional security by creating a virtual boundary around your Vertex AI resources. This prevents unauthorized access from outside your defined boundary.

**Ensure Data Encryption  
** _Data at Rest:_ Google Cloud automatically encrypts all data at rest using AES-256 encryption.  
_Data in Transit:_ Ensure that you’re using HTTPS to communicate with Vertex AI endpoints, and use SSL/TLS for added security.  
_Custom Encryption:_ If needed, you can provide your own encryption keys for additional security.

### Version Control for Models and Datasets

Managing different versions of datasets and models is crucial, especially when working in production environments where models are updated frequently.

**Label and Track Model Versions  
** Always assign meaningful labels to your models and datasets, such as version numbers, training data versions, or feature sets. This will help you track the progress and changes in each iteration.

**_Example:  
_** Model `v1.0`: Trained on Dataset A with Feature Set X.  
Model `v2.0`: Trained on Dataset B with Feature Set X + Y.

**Use Cloud Source Repositories for Model Code  
** Just like version control for source code, you can store your machine learning code in a version control system like _Google Cloud Source Repositories_ or _GitHub_. This allows for easier rollback and collaboration.
    
    
    # Example of pushing your training code to Google Cloud Source Repository  
    git remote add google https://source.developers.google.com/p/your-project-id/r/your-repo  
    git push google master

**Automate Version Control in Pipelines  
** Set up your pipelines to automatically track and manage model versions by saving model metadata after each training run. You can store this metadata in Google Cloud Storage or in a database like Firestore for easier querying and management.

### Debugging Tips for JavaScript with Vertex AI

Debugging your machine learning pipeline or model deployment can be tricky. Here are some best practices for debugging issues in your Vertex AI applications.

**Use Google Cloud Logging  
** Google Cloud Logging captures detailed logs for all the services you use. You can add custom logging within your Vertex AI models or Node.js applications to track errors, performance metrics, and warnings.
    
    
    const { Logging } = require('@google-cloud/logging');  
      
    async function writeLog(logMessage) {  
      const logging = new Logging();  
      const log = logging.log('vertex-ai-log');  // Define a log name  
      const metadata = { resource: { type: 'global' } };  
      const entry = log.entry(metadata, { message: logMessage });  
      
      await log.write(entry);  
      console.log(`Logged: ${logMessage}`);  
    }  
      
    writeLog('Vertex AI prediction started').catch(console.error);

**Use Debug Mode in Vertex AI Training Jobs  
** Vertex AI allows you to run training jobs in debug mode, which provides additional logs and outputs to help diagnose issues.

**Check Quotas and Limits  
** If your training or prediction jobs are failing, check the Google Cloud quotas for your project. You might be hitting resource limits (e.g., CPU, memory, GPU quotas). You can request quota increases through the Google Cloud Console.

**Test Locally Before Deployment  
** Before deploying your model to Vertex AI, test your model and pipeline locally using Docker or a local environment to catch any issues before they occur in production.

### General Workflow Tips

**Here are a few additional tips to streamline your workflow with Vertex AI:**  
_Use Pipelines for Automation:_ Pipelines can automate the entire ML workflow — from data ingestion to model training, deployment, and prediction — reducing the need for manual intervention.  
_Regularly Retrain Models:_ Ensure that you have a process in place to retrain your models with new data periodically. This will help improve prediction accuracy and adapt to changing data patterns.  
_Experiment with Hyperparameter Tuning:_ Use Vertex AI’s Hyperparameter Tuning to optimize model performance by testing different configurations automatically.

This chapter covered the _Best Practices and Tips for Working with Vertex AI_ , focusing on optimizing costs, maintaining security, version control, and debugging.

## Advanced Use Cases of Vertex AI with JavaScript

In this final chapter, we will explore some advanced use cases of Vertex AI when working with JavaScript. We’ll look at how Vertex AI can be integrated with other Google Cloud services, how to build full-stack applications powered by machine learning, and provide a real-world case study of AI-powered applications using Vertex AI.

### Integrating Vertex AI with Other Google Cloud Services

Vertex AI is a part of the broader Google Cloud ecosystem, and integrating it with other services can unlock even more powerful applications. Here are some key services that can be combined with Vertex AI:

**BigQuery  
** BigQuery is Google Cloud’s highly scalable data warehouse, and it can be used to handle large datasets that you want to use for training machine learning models. You can directly export data from BigQuery to Vertex AI for model training and predictions.

**_Example Use Case: Training a Model Using BigQuery Data  
_** Query data from BigQuery to create your training dataset.  
Load the results into Vertex AI for model training.
    
    
    const { BigQuery } = require('@google-cloud/bigquery');  
      
    async function loadBigQueryData() {  
      const bigquery = new BigQuery();  
      const query = `SELECT * FROM \`your-project.your-dataset.your-table\``;  
      
      const [rows] = await bigquery.query(query);  
      console.log('Data from BigQuery:', rows);  
    }  
      
    loadBigQueryData().catch(console.error);

Once the data is retrieved, it can be uploaded to Cloud Storage and used as part of a Vertex AI model pipeline.

**Cloud Functions  
** Cloud Functions are serverless functions that can be triggered by events, such as a new model being trained or new data arriving. You can use Cloud Functions to automate parts of your Vertex AI workflow, such as triggering model retraining or making predictions when new data is available.

**_Example Use Case: Automated Model Retraining  
_** When new data is uploaded to Google Cloud Storage, a Cloud Function is triggered that retrains the model using Vertex AI.
    
    
    const { PipelineServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    exports.retrainModel = async (event, context) => {  
      const client = new PipelineServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      
      const parent = `projects/${projectId}/locations/${location}`;  
      const pipelineJob = {  
        displayName: 'auto-retraining-pipeline',  
        trainingPipeline: {  
          displayName: 'auto-retrain-job',  
          inputDataConfig: {  
            datasetId: 'your-dataset-id',  
          },  
          modelToUpload: {  
            displayName: 'your-new-model',  
          },  
        },  
      };  
      
      const [operation] = await client.createPipelineJob({  
        parent,  
        pipelineJob,  
      });  
      
      const [response] = await operation.promise();  
      console.log(`Model retraining pipeline started: ${response.name}`);  
    };

**Pub/Sub**  
Pub/Sub is a messaging service that can be used to communicate between different components of a machine learning system. For example, you can publish messages when a model is deployed, and then other services (such as logging or notification services) can subscribe to those messages and take action.

**_Example Use Case: Notifications for Model Deployment_**  
Publish a message to Pub/Sub when a new model is deployed, and trigger notifications or logging systems to record the event.
    
    
    const { PubSub } = require('@google-cloud/pubsub');  
      
    async function publishMessage() {  
      const pubsub = new PubSub();  
      const topicName = 'model-deployment-topic';  
      const dataBuffer = Buffer.from(JSON.stringify({ modelId: 'your-model-id', status: 'deployed' }));  
      
      await pubsub.topic(topicName).publish(dataBuffer);  
      console.log('Message published.');  
    }  
      
    publishMessage().catch(console.error);

**Cloud Storage**  
Cloud Storage serves as a repository for datasets, models, and prediction results. You can automate the process of storing models or exporting batch predictions to Cloud Storage for further processing.

**_Example Use Case: Store Batch Prediction Results_**  
After performing a batch prediction, store the results in Cloud Storage for further analysis or visualization.
    
    
    const { Storage } = require('@google-cloud/storage');  
    const storage = new Storage();  
      
    async function uploadPredictionResults(bucketName, filePath) {  
      await storage.bucket(bucketName).upload(filePath, {  
        gzip: true,  
        metadata: {  
          cacheControl: 'no-cache',  
        },  
      });  
      
      console.log(`${filePath} uploaded to ${bucketName}`);  
    }  
      
    uploadPredictionResults('your-bucket-name', 'path/to/prediction/results.csv').catch(console.error);

### Building a Full Stack Application with Vertex AI

Vertex AI can be integrated into full-stack applications to provide intelligent features like recommendations, classification, and predictions. Here’s an outline of how you can build a full-stack app using Vertex AI with JavaScript as the backend:

**_Example Use Case: Building an E-commerce Recommendation System_**

 _Frontend_ : Build a React or Vue.js app for an e-commerce platform where users browse products.  
_Backend:_ Use Node.js with Express.js to handle user requests and interact with the Vertex AI API for generating personalized recommendations.  
_Model:_ Train a recommendation model using customer behavior data, such as purchase history, stored in BigQuery.  
_Real-Time Predictions:_ When a user visits the site, send a request to the deployed model on Vertex AI to get product recommendations.

**_Backend Example (Node.js Express App for Predictions):_**
    
    
     const express = require('express');  
    const { PredictionServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    const app = express();  
    const client = new PredictionServiceClient();  
    const projectId = 'your-project-id';  
    const location = 'us-central1';  
    const endpointId = 'your-endpoint-id';  // Deployed model endpoint  
      
    app.get('/recommendations', async (req, res) => {  
      const userId = req.query.userId;  // Example user identifier  
      const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
      
      const instance = { values: [userId] };  // Example input based on user ID  
      const instances = [instance];  
      
      try {  
        const [response] = await client.predict({  
          endpoint,  
          instances,  
        });  
      
        res.json({ recommendations: response.predictions });  
      } catch (error) {  
        console.error('Error making prediction:', error);  
        res.status(500).send('Error generating recommendations');  
      }  
    });  
      
    app.listen(3000, () => {  
      console.log('Server running on port 3000');  
    });

In this example, when a user requests product recommendations, the server sends a prediction request to Vertex AI, and the model returns personalized recommendations based on the user’s data.

### Case Study: AI-Powered Applications Using Vertex AI

**Example: AI-Powered Document Classification System  
** _Problem:_ A law firm needs to classify thousands of legal documents into various categories (e.g., contracts, case law, correspondence) and extract key information from them.

**Solution Using Vertex AI:**_  
Data Collection:_ The firm uploads all its documents (PDFs and text files) to Google Cloud Storage.  
_Model Training:_ Using Vertex AI, the firm trains a custom document classification model. The model is trained using labeled documents stored in BigQuery and Google Cloud Storage.  
_Deployment:_ The trained model is deployed to Vertex AI, and a Cloud Function is set up to trigger whenever new documents are uploaded.  
_Automation:_ Whenever a new document is uploaded, the Cloud Function sends the document to the Vertex AI model for classification. The results (document type, extracted information) are saved to a Firestore database.  
_Dashboard:_ The firm uses a React frontend to display a dashboard showing the classification results in real-time, allowing users to quickly find and organize documents.

**Technical Implementation:**_  
Cloud Storage:_ Stores the documents.  
_Vertex AI:_ Trains and deploys the document classification model.  
_Cloud Functions:_ Automates the classification process when new documents are uploaded.  
_Firestore:_ Stores the classification results.  
_React Frontend:_ Provides a user interface for document search and filtering.

_Code Snippet: Cloud Function for Document Classification:_
    
    
     const { PredictionServiceClient } = require('@google-cloud/aiplatform').v1;  
      
    exports.classifyDocument = async (event, context) => {  
      const file = event.name;  // File uploaded to Cloud Storage  
      const client = new PredictionServiceClient();  
      const projectId = 'your-project-id';  
      const location = 'us-central1';  
      const endpointId = 'your-endpoint-id';  
      
      const instance = { document: file };  // Document input for classification  
      const instances = [instance];  
      const endpoint = `projects/${projectId}/locations/${location}/endpoints/${endpointId}`;  
      
      const [response] = await client.predict({  
        endpoint,  
        instances,  
      });  
      
      console.log('Classification results:', response.predictions);  
    };

**Other Advanced Use Cases  
** _Sentiment Analysis for Customer Support:_ Analyze customer service conversations to determine satisfaction levels and provide real-time feedback to support agents.  
_Predictive Maintenance for Manufacturing:_ Use machine learning models to predict equipment failures based on sensor data, and schedule maintenance proactively.  
_Fraud Detection in Financial Transactions:_ Build and deploy models to detect unusual behavior and transactions in real-time.  
This concludes the chapter on _Advanced Use Cases of Vertex AI with JavaScript_. We’ve covered real-world examples, integrations with other Google Cloud services, and how to build a full-stack application using Vertex AI.

## Summary

This guide explored how to effectively use _Google Cloud Platform’s Vertex AI_ with _JavaScript_ for building, deploying, and managing machine learning models. Whether you’re a beginner or a seasoned developer, this guide covered all essential steps, from setting up Vertex AI to implementing advanced use cases.

### Key Chapters and Takeaways:

_Introduction to GCP Vertex AI  
_We introduced Vertex AI, a powerful machine learning platform that integrates the entire ML workflow, supporting both AutoML for beginners and custom model training for professionals. JavaScript, while traditionally underused in ML, can now be leveraged through Vertex AI APIs for efficient model management.

_Setting Up GCP Vertex AI with JavaScript  
_We explained how to create a GCP project, configure service accounts, install the required Node.js packages, and authenticate your JavaScript application with Google Cloud. This section provided a foundational setup to interact with Vertex AI.

_Exploring Vertex AI Components  
_This chapter broke down essential Vertex AI components, including model training (AutoML and custom models), dataset management, and deploying models. We provided JavaScript code to interact with Vertex AI components, covering both real-time and batch workflows.

_Training a Machine Learning Model Using JavaScript  
_We covered how to prepare datasets, use AutoML for quick training, and run custom training jobs using JavaScript. Example scripts demonstrated how to automate data uploads, create datasets, and initiate model training pipelines.

_Deploying Models on Vertex AI  
_We explored how to deploy trained models to Vertex AI endpoints for real-time or batch predictions. JavaScript code examples guided through creating endpoints, deploying models, and automating the deployment process.

_Making Predictions Using Deployed Models  
_This section covered how to send real-time or batch prediction requests to deployed models using Vertex AI. JavaScript examples showed how to handle model predictions and integrate them into applications.

_Monitoring and Managing AI Models in Vertex AI  
_We emphasized the importance of monitoring deployed models using Google Cloud’s built-in tools, including logging, error tracking, and setting up automated alerts. We also explored how to manage model versions and automate pipelines.

_Best Practices and Tips for Working with Vertex AI  
_We shared best practices for cost optimization (using preemptible VMs, autoscaling, etc.), ensuring security through IAM roles and encryption, and effectively managing model versions and datasets for reproducibility and scale.

_Advanced Use Cases of Vertex AI with JavaScript  
_We explored advanced use cases where Vertex AI can be integrated with other Google Cloud services like BigQuery, Cloud Functions, and Pub/Sub to build powerful AI-driven applications. Real-world examples included building e-commerce recommendation systems, document classification, and AI-powered dashboards.

**Final Thoughts:  
** By combining _JavaScript_ with _Google Cloud Vertex AI_ , developers can leverage their existing skills to integrate machine learning into modern web applications and full-stack systems. Whether you’re automating predictions, scaling models with serverless functions, or building intelligent dashboards, Vertex AI provides all the necessary tools for success.

Press enter or click to view image in full size

[Vertex AI](/tag/vertex-ai?source=post_page-----6ea4e8ef139b---------------------------------------)

[Gcp](/tag/gcp?source=post_page-----6ea4e8ef139b---------------------------------------)

[Nodejs](/tag/nodejs?source=post_page-----6ea4e8ef139b---------------------------------------)

[JavaScript](/tag/javascript?source=post_page-----6ea4e8ef139b---------------------------------------)

[Vertex](/tag/vertex?source=post_page-----6ea4e8ef139b---------------------------------------)

[![Warley's CatOps](https://miro.medium.com/v2/resize:fill:96:96/1*gL9MH6lhDcuMm21JQWvsEA.jpeg)](/@williamwarley?source=post_page---post_author_info--6ea4e8ef139b---------------------------------------)

[![Warley's CatOps](https://miro.medium.com/v2/resize:fill:128:128/1*gL9MH6lhDcuMm21JQWvsEA.jpeg)](/@williamwarley?source=post_page---post_author_info--6ea4e8ef139b---------------------------------------)

## [Written by Warley's CatOps](/@williamwarley?source=post_page---post_author_info--6ea4e8ef139b---------------------------------------)

[485 followers](/@williamwarley/followers?source=post_page---post_author_info--6ea4e8ef139b---------------------------------------)

·[11 following](/@williamwarley/following?source=post_page---post_author_info--6ea4e8ef139b---------------------------------------)

Furly Tech Enthusiast with passion to teach people. Guides for each technology you need. Let's learn with meow!1

## Responses (1)

[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--6ea4e8ef139b---------------------------------------)

See all responses

[Help](https://help.medium.com/hc/en-us?source=post_page-----6ea4e8ef139b---------------------------------------)

[Status](https://status.medium.com/?source=post_page-----6ea4e8ef139b---------------------------------------)

[About](/about?autoplay=1&source=post_page-----6ea4e8ef139b---------------------------------------)

[Careers](/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----6ea4e8ef139b---------------------------------------)

[Press](mailto:pressinquiries@medium.com)

[Blog](https://blog.medium.com/?source=post_page-----6ea4e8ef139b---------------------------------------)

[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6ea4e8ef139b---------------------------------------)

[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----6ea4e8ef139b---------------------------------------)

[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6ea4e8ef139b---------------------------------------)

[Text to speech](https://speechify.com/medium?source=post_page-----6ea4e8ef139b---------------------------------------)
Skip to main content 

[ ![Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v0a8f38b07c3863b7ced1d678d2584c8bd483c306fc4b8f547093e71dea088feb/cloud/images/cloud-logo.svg) ](/)

  * 


`/`

  * English
  * Deutsch
  * Español
  * Español – América Latina
  * Français
  * Indonesia
  * Italiano
  * Português
  * Português – Brasil
  * 中文 – 简体
  * 中文 – 繁體
  * 日本語
  * 한국어

[ Console ](//console.cloud.google.com/) Sign in

  * [ Generative AI on Vertex AI ](https://cloud.google.com/vertex-ai/generative-ai/docs)



[Contact Us](https://cloud.google.com/contact) [Start free](//console.cloud.google.com/freetrial)

  * [ Home ](https://cloud.google.com/)
  * [ Generative AI on Vertex AI ](https://cloud.google.com/vertex-ai/generative-ai/docs)
  * [ Documentation ](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview)



Send feedback 

#  Mistral AI models

Stay organized with collections  Save and categorize content based on your preferences. 

Mistral AI models on Vertex AI offer fully managed and serverless models as APIs. To use a Mistral AI model on Vertex AI, send a request directly to the Vertex AI API endpoint. Because Mistral AI models use a managed API, there's no need to provision or manage infrastructure.

You can stream your responses to reduce the end-user latency perception. A streamed response uses server-sent events (SSE) to incrementally stream the response.

You pay for Mistral AI models as you use them (pay as you go). For pay-as-you-go pricing, see Mistral AI model pricing on the Vertex AI [pricing](/vertex-ai/generative-ai/pricing#partner-models)

page.

## Available Mistral AI models

The following models are available from Mistral AI to use in Vertex AI. To access a Mistral AI model, go to its Model Garden model card.

### Mistral Medium 3

Mistral Medium 3 is a versatile model designed for a wide range of tasks, including programming, mathematical reasoning, understanding long documents, summarization, and dialogue. It excels at complex tasks requiring advanced reasoning abilities, visual understanding or a high level of specialization (e.g. creative writing, agentic workflows, code generation).

It boasts multi-modal capabilities, enabling it to process visual inputs, and supports dozens of languages, including over 80 coding languages. Additionally, it features function calling and agentic workflows.

Mistral Medium 3 is optimized for single-node inference, particularly for long-context applications. Its size allows it to achieve high throughput on a single node.

[Go to the Mistral Medium 3 model card](https://console.cloud.google.com/vertex-ai/publishers/mistralai/model-garden/mistral-medium-3)

### Mistral OCR (25.05)

Mistral OCR (25.05) is an Optical Character Recognition API for document understanding. Mistral OCR (25.05) excels in understanding complex document elements, including interleaved imagery, mathematical expressions, tables, and advanced layouts such as LaTeX formatting. The model enables deeper understanding of rich documents such as scientific papers with charts, graphs, equations and figures.

Mistral OCR (25.05) is an ideal model to use in combination with a RAG system that takes multimodal documents (such as slides or complex PDFs) as input.

You can couple Mistral OCR (25.05) with other Mistral models to reformat the results. This combination ensures that the extracted content is not only accurate but also presented in a structured and coherent manner, making it suitable for various downstream applications and analyses.

[Go to the Mistral OCR (25.05) model card](https://console.cloud.google.com/vertex-ai/publishers/mistralai/model-garden/mistral-ocr-2505)

### Mistral Small 3.1 (25.03)

Mistral Small 3.1 (25.03) features multimodal capabilities and a context of up to 128,000. The model can process and understand visual inputs and long documents, further expanding its range of applications compared to the previous Mistral AI Small model. Mistral Small 3.1 (25.03) is a versatile model designed for various tasks such as programming, mathematical reasoning, document understanding, and dialogue. Mistral Small 3.1 (25.03) is designed for low-latency applications to deliver best-in-class efficiency compared to models of the same quality.

Mistral Small 3.1 (25.03) has undergone a full post-training process to align the model with human preferences and needs, making it usable out-of-the-box for applications that require chat or precise instruction following.

[Go to the Mistral Small 3.1 (25.03) model card](https://console.cloud.google.com/vertex-ai/publishers/mistralai/model-garden/mistral-small-2503)

### Mistral Large (24.11)

Mistral Large (24.11) is the latest version of Mistral AI's Large model now with improved reasoning and function calling capabilities.

  * **Agent-centric** : best-in-class agentic capabilities with built-in function calling and JSON outputs.
  * **Multi-lingual by design** : dozens of languages supported, including English, French, German, Spanish, Italian, Chinese, Japanese, Korean, Portuguese, Dutch, and Polish
  * **Proficient in coding** : trained on 80+ coding languages such as Python, Java, C, C++, JavaScript, and Bash. Also trained on more specific languages such as Swift and Fortran
  * **Advanced reasoning** : state-of-the-art mathematical and reasoning capabilities.



[Go to the Mistral Large (24.11) model card](https://console.cloud.google.com/vertex-ai/publishers/mistralai/model-garden/mistral-large-2411)

### Codestral (25.01)

Codestral (25.01) is designed for code generation tasks. It helps developers write and interact with code through a shared instruction and completion API endpoint. As it masters code along with its ability to converse in a variety of languages, you can use Codestral (25.01) to design advanced AI applications for software developers.

  * Codestral (25.01) is fluent in 80+ programming languages including Python, Java, C, C++, JavaScript, and Bash. It also performs well on more specific languages like Swift and Fortran.
  * Codestral (25.01) helps to improve developers' productivity and reduces errors: Codestral (25.01) can complete coding functions, write tests, and complete any partial code using a fill-in-the-middle mechanism.
  * Codestral (25.01) provides a new standard on the performance and latency space with only 24B parameters and a 128,000 context window.



Codestral (25.01) is optimized for the following use cases:

  * Generates code and provides code completion, suggestions, and translation.
  * Adds code between user-defined start and end points, which makes it ideal for tasks that require a specific piece of code to be generated.
  * Summarizes and explains your code.
  * Reviews the quality of your code by helping to refactor your code, fixes bugs, and generates test cases.



[Go to the Codestral (25.01) model card](https://console.cloud.google.com/vertex-ai/publishers/mistralai/model-garden/codestral-2501)

## Use Mistral AI models

You can use curl commands to send requests to the Vertex AI endpoint using the following model names:

  * For Mistral Medium 3, use `mistral-medium-3`
  * For Mistral OCR (25.05), use `mistral-ocr-2505`
  * For Mistral Small 3.1 (25.03), use `mistral-small-2503`
  * For Mistral Large (24.11), use `mistral-large-2411`
  * For Mistral Nemo, use `mistral-nemo`
  * For Codestral (25.01), use `codestral-2501`



For more information about using the Mistral AI SDK, see the [ Mistral AI Vertex AI documentation](https://docs.mistral.ai/deployment/cloud/vertex/).

### Before you begin

To use Mistral AI models with Vertex AI, you must perform the following steps. The Vertex AI API (`aiplatform.googleapis.com`) must be enabled to use Vertex AI. If you already have an existing project with the Vertex AI API enabled, you can use that project instead of creating a new project.

  1. Sign in to your Google Cloud account. If you're new to Google Cloud, [ create an account](https://console.cloud.google.com/freetrial) to evaluate how our products perform in real-world scenarios. New customers also get $300 in free credits to run, test, and deploy workloads. 
  2. In the Google Cloud console, on the project selector page, select or create a Google Cloud project.

**Roles required to select or create a project**

     * **Select a project** : Selecting a project doesn't require a specific IAM role—you can select any project that you've been granted a role on. 
     * **Create a project** : To create a project, you need the Project Creator (`roles/resourcemanager.projectCreator`), which contains the `resourcemanager.projects.create` permission. [Learn how to grant roles](/iam/docs/granting-changing-revoking-access). 

[Go to project selector](https://console.cloud.google.com/projectselector2/home/dashboard)

  3. [Verify that billing is enabled for your Google Cloud project](/billing/docs/how-to/verify-billing-enabled#confirm_billing_is_enabled_on_a_project). 

  4. Enable the Vertex AI API. 

**Roles required to enable APIs**

To enable APIs, you need the Service Usage Admin IAM role (`roles/serviceusage.serviceUsageAdmin`), which contains the `serviceusage.services.enable` permission. [Learn how to grant roles](/iam/docs/granting-changing-revoking-access). 

[Enable the API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)

  5. In the Google Cloud console, on the project selector page, select or create a Google Cloud project.

**Roles required to select or create a project**

     * **Select a project** : Selecting a project doesn't require a specific IAM role—you can select any project that you've been granted a role on. 
     * **Create a project** : To create a project, you need the Project Creator (`roles/resourcemanager.projectCreator`), which contains the `resourcemanager.projects.create` permission. [Learn how to grant roles](/iam/docs/granting-changing-revoking-access). 

[Go to project selector](https://console.cloud.google.com/projectselector2/home/dashboard)

  6. [Verify that billing is enabled for your Google Cloud project](/billing/docs/how-to/verify-billing-enabled#confirm_billing_is_enabled_on_a_project). 

  7. Enable the Vertex AI API. 

**Roles required to enable APIs**

To enable APIs, you need the Service Usage Admin IAM role (`roles/serviceusage.serviceUsageAdmin`), which contains the `serviceusage.services.enable` permission. [Learn how to grant roles](/iam/docs/granting-changing-revoking-access). 

[Enable the API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)

  8. Go to one of the following Model Garden model cards, then click **Enable** : 
     * [Go to the Mistral Medium 3 model card](https://console.cloud.google.com/vertex-ai/publishers/mistralai/model-garden/mistral-medium-3)
     * [Go to the Mistral OCR (25.05) model card](https://console.cloud.google.com/vertex-ai/publishers/mistralai/model-garden/mistral-ocr-2505)
     * [Go to the Mistral Small 3.1 (25.03) model card](https://console.cloud.google.com/vertex-ai/publishers/mistralai/model-garden/mistral-small-2503)
     * [Go to the Mistral Large (24.11) model card](https://console.cloud.google.com/vertex-ai/publishers/mistralai/model-garden/mistral-large-2411)
     * [Go to the Mistral Nemo model card](https://console.cloud.google.com/vertex-ai/publishers/mistralai/model-garden/mistral-nemo)
     * [Go to the Codestral (25.01) model card](https://console.cloud.google.com/vertex-ai/publishers/mistralai/model-garden/codestral-2501)



#### Make a streaming call to a Mistral AI model

The following sample makes a streaming call to a Mistral AI model.

### REST

After you [set up your environment](/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal#gemini-setup-environment-drest), you can use REST to test a text prompt. The following sample sends a request to the publisher model endpoint. 

Before using any of the request data, make the following replacements: 

  * LOCATION: A region that supports Mistral AI models.
  * MODEL: The model name you want to use. In the request body, exclude the `@` model version number.
  * ROLE: The role associated with a message. You can specify a `user` or an `assistant`. The first message must use the `user` role. The models operate with alternating `user` and `assistant` turns. If the final message uses the `assistant` role, then the response content continues immediately from the content in that message. You can use this to constrain part of the model's response.
  * STREAM: A boolean that specifies whether the response is streamed or not. Stream your response to reduce the end-use latency perception. Set to `true` to stream the response and `false` to return the response all at once.
  * CONTENT: The content, such as text, of the `user` or `assistant` message.
  * MAX_OUTPUT_TOKENS: Maximum number of tokens that can be generated in the response. A token is approximately 3.5 characters. 100 tokens correspond to roughly 60-80 words. 

Specify a lower value for shorter responses and a higher value for potentially longer responses.




HTTP method and URL: 
    
    
    POST https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/mistralai/models/MODEL:streamRawPredict

Request JSON body: 
    
    
    {
    "model": MODEL,
      "messages": [
       {
        "role": "ROLE",
        "content": "CONTENT"
       }],
      "max_tokens": MAX_TOKENS,
      "stream": true
    }
    

To send your request, choose one of these options:

#### curl

Save the request body in a file named `request.json`, and execute the following command: 
    
    
    curl -X POST \  
         -H "Authorization: Bearer $(gcloud auth print-access-token)" \  
         -H "Content-Type: application/json; charset=utf-8" \  
         -d @request.json \  
         "https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/mistralai/models/MODEL:streamRawPredict"

#### PowerShell

Save the request body in a file named `request.json`, and execute the following command: 
    
    
    $cred = gcloud auth print-access-token  
    $headers = @{ "Authorization" = "Bearer $cred" }  
      
    Invoke-WebRequest `  
        -Method POST `  
        -Headers $headers `  
        -ContentType: "application/json; charset=utf-8" `  
        -InFile request.json `  
        -Uri "https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/mistralai/models/MODEL:streamRawPredict" | Select-Object -Expand Content

You should receive a JSON response similar to the following.

#### Response
    
    
    data: {
        "id": "0e9c8e69e5924f729b39bc60bac9e0be",
        "object": "chat.completion.chunk",
        "created": 1720807292,
        "model": "MODEL",
        "choices": [
            {
                "index": 0,
                "delta": {
                  "content": "OUTPUT"
                },
                "finish_reason": null,
                "logprobs": null
            }
        ]
    }
    
    data: {
        "id": "0e9c8e69e5924f729b39bc60bac9e0be",
        "object": "chat.completion.chunk",
        "created": 1720807292,
        "model": "MODEL",
        "choices": [
            {
                "index": 0,
                "delta": {
                  "content": "OUTPUT"
                },
                "finish_reason": null,
                "logprobs": null
            }
        ]
    }
    ...
    

#### Make a unary call to a Mistral AI model

The following sample makes a unary call to a Mistral AI model.

### REST

After you [set up your environment](/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal#gemini-setup-environment-drest), you can use REST to test a text prompt. The following sample sends a request to the publisher model endpoint. 

Before using any of the request data, make the following replacements: 

  * LOCATION: A region that supports Mistral AI models.
  * MODEL: The model name you want to use. In the request body, exclude the `@` model version number.
  * ROLE: The role associated with a message. You can specify a `user` or an `assistant`. The first message must use the `user` role. The models operate with alternating `user` and `assistant` turns. If the final message uses the `assistant` role, then the response content continues immediately from the content in that message. You can use this to constrain part of the model's response.
  * STREAM: A boolean that specifies whether the response is streamed or not. Stream your response to reduce the end-use latency perception. Set to `true` to stream the response and `false` to return the response all at once.
  * CONTENT: The content, such as text, of the `user` or `assistant` message.
  * MAX_OUTPUT_TOKENS: Maximum number of tokens that can be generated in the response. A token is approximately 3.5 characters. 100 tokens correspond to roughly 60-80 words. 

Specify a lower value for shorter responses and a higher value for potentially longer responses.




HTTP method and URL: 
    
    
    POST https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/mistralai/models/MODEL:rawPredict

Request JSON body: 
    
    
    {
    "model": MODEL,
      "messages": [
       {
        "role": "ROLE",
        "content": "CONTENT"
       }],
      "max_tokens": MAX_TOKENS,
      "stream": false
    }
    

To send your request, choose one of these options:

#### curl

Save the request body in a file named `request.json`, and execute the following command: 
    
    
    curl -X POST \  
         -H "Authorization: Bearer $(gcloud auth print-access-token)" \  
         -H "Content-Type: application/json; charset=utf-8" \  
         -d @request.json \  
         "https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/mistralai/models/MODEL:rawPredict"

#### PowerShell

Save the request body in a file named `request.json`, and execute the following command: 
    
    
    $cred = gcloud auth print-access-token  
    $headers = @{ "Authorization" = "Bearer $cred" }  
      
    Invoke-WebRequest `  
        -Method POST `  
        -Headers $headers `  
        -ContentType: "application/json; charset=utf-8" `  
        -InFile request.json `  
        -Uri "https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/mistralai/models/MODEL:rawPredict" | Select-Object -Expand Content

You should receive a JSON response similar to the following.

#### Response
    
    
    {
        "id": "e71d13ffb77344a08e34e0a22ea84458",
        "object": "chat.completion",
        "created": 1720806624,
        "model": "MODEL",
        "choices": [
            {
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "OUTPUT",
                    "tool_calls": null
                },
                "finish_reason": "stop",
                "logprobs": null
            }
        ],
        "usage": {
            "prompt_tokens": 17,
            "total_tokens": 295,
            "completion_tokens": 278
        }
    }
    

## Mistral AI model region availability and quotas

For Mistral AI models, a quota applies for each region where the model is available. The quota is specified in queries per minute (QPM) and tokens per minute (TPM). TPM includes both input and output tokens.

Model | Region | Quotas | Context length  
---|---|---|---  
Mistral Medium 3  
`us-central1` | 

  * QPM: 90
  * TPM: 315,000

|  128,000   
`europe-west4` | 

  * QPM: 90
  * TPM: 315,000

|  128,000   
Mistral OCR (25.05)  
`us-central1` | 

  * QPM: 30
  * Pages per request: 30 (1 page = 1 million input tokens and 1 million output tokens)

|  30 pages   
`europe-west4` | 

  * QPM: 30
  * Pages per request: 30 (1 page = 1 million input tokens and 1 million output tokens)

|  30 pages   
Mistral Small 3.1 (25.03)  
`us-central1` | 

  * QPM: 60
  * TPM: 200,000

|  128,000   
`europe-west4` | 

  * QPM: 60
  * TPM: 200,000

|  128,000   
Mistral Large (24.11)  
`us-central1` | 

  * QPM: 60
  * TPM: 400,000

|  128,000   
`europe-west4` | 

  * QPM: 60
  * TPM: 400,000

|  128,000   
Mistral Nemo  
`us-central1` | 

  * QPM: 60
  * TPM: 400,000

|  128,000   
`europe-west4` | 

  * QPM: 60
  * TPM: 400,000

|  128,000   
Codestral (25.01)  
`us-central1` | 

  * QPM: 60
  * TPM: 400,000

|  32,000   
`europe-west4` | 

  * QPM: 60
  * TPM: 400,000

|  32,000   
  
If you want to increase any of your quotas for Generative AI on Vertex AI, you can use the Google Cloud console to request a quota increase. To learn more about quotas, see [Work with quotas](/docs/quota).

Send feedback 

Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-10-10 UTC.

Need to tell us more?  [[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Hard to understand","hardToUnderstand","thumb-down"],["Incorrect information or sample code","incorrectInformationOrSampleCode","thumb-down"],["Missing the information/samples I need","missingTheInformationSamplesINeed","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-10-10 UTC."],[],[]] 
Skip to main content 

[ ![Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v0a8f38b07c3863b7ced1d678d2584c8bd483c306fc4b8f547093e71dea088feb/cloud/images/cloud-logo.svg) ](/)

  * 


`/`

  * English
  * Deutsch
  * Español
  * Español – América Latina
  * Français
  * Indonesia
  * Italiano
  * Português
  * Português – Brasil
  * 中文 – 简体
  * 中文 – 繁體
  * 日本語
  * 한국어

[ Console ](//console.cloud.google.com/) Sign in

  * [ Generative AI on Vertex AI ](https://cloud.google.com/vertex-ai/generative-ai/docs)



[Contact Us](https://cloud.google.com/contact) [Start free](//console.cloud.google.com/freetrial)

  * [ Home ](https://cloud.google.com/)
  * [ Generative AI on Vertex AI ](https://cloud.google.com/vertex-ai/generative-ai/docs)
  * [ Documentation ](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview)



Send feedback 

#  Google models

Stay organized with collections  Save and categorize content based on your preferences. 

## Featured Gemini models

2.5 Pro diamond

Our most advanced reasoning Gemini model, made to solve complex problems 

  * Best for multimodal understanding
  * Capable of processing complex prompts and providing well-rounded responses
  * Best for coding, particularly for web development

[](/vertex-ai/generative-ai/docs/models/gemini/2-5-pro)

2.5 Flash spark

Our best model in terms of price-performance, offering well-rounded capabilities 

  * Support for Live API included for some endpoints
  * See the model's thinking process as part of the response
  * Balances price and performance

[](/vertex-ai/generative-ai/docs/models/gemini/2-5-flash)

2.5 Flash-Lite performance_auto

Our most cost effective model that supports high throughput tasks 

  * The fastest model in the 2.5 line of models
  * Features a 1 million token context window and multimodal input, like 2.5 Flash
  * Outperforms 2.0 Flash on most evaluation benchmarks

[](/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-lite)

## Generally available Gemini models

diamond [Gemini 2.5 Pro](/vertex-ai/generative-ai/docs/models/gemini/2-5-pro) Our most advanced reasoning model to date spark [Gemini 2.5 Flash](/vertex-ai/generative-ai/docs/models/gemini/2-5-flash) Our best model in terms of price-performance, offering well-rounded capabilities photo_spark [Gemini 2.5 Flash Image](/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-image) Our standard model upgraded for rapid creative workflows with image generation and conversational, multi-turn editing capabilities  performance_auto [Gemini 2.5 Flash-Lite](/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-lite) Our most cost effective model that supports high throughput tasks spark [Gemini 2.0 Flash](/vertex-ai/generative-ai/docs/models/gemini/2-0-flash) Our newest multimodal model, with next generation features and improved capabilities performance_auto [Gemini 2.0 Flash-Lite](/vertex-ai/generative-ai/docs/models/gemini/2-0-flash-lite) A Gemini 2.0 Flash model optimized for cost efficiency and low latency

## Preview Gemini models

mic_detect_auto [ Gemini 2.5 Flash Live API](/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-live-api) Our standard model upgraded for real-time, conversational experiences with streaming capabilities 

## Gemma models

![](https://ai.google.dev/gemma/images/gemma_sq.png) [Gemma 3n](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemma3n) The latest open models, designed for efficient execution on low-resource devices, capable of multimodal input, handling text, image, video, and audio input, and generating text outputs, and trained with data in over 140 spoken languages ![](https://ai.google.dev/gemma/images/gemma_sq.png) [Gemma 3](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemma3) The third of generation of our open models, featuring the ability to solve a wide variety of tasks with text and image input, support for over 140 languages, and long 128K context window ![](https://ai.google.dev/gemma/images/gemma_sq.png) [Gemma 2](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemma2) The second of generation of our open models featuring text generation, summarization, and extraction ![](https://ai.google.dev/gemma/images/gemma_sq.png) [Gemma](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335) A small-sized, lightweight open model supporting text generation, summarization, and extraction ![](https://ai.google.dev/gemma/images/gemma_sq.png) [ShieldGemma 2](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/shieldgemma2) Instruction tuned models for evaluating the safety of text and images against a set of defined safety policies ![](https://ai.google.dev/gemma/images/gemma_sq.png) [PaliGemma](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/paligemma) Our open vision-language model that combines SigLIP and Gemma ![](https://ai.google.dev/gemma/images/gemma_sq.png) [CodeGemma](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/codegemma) Powerful, lightweight open model that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following ![](https://ai.google.dev/gemma/images/gemma_sq.png) [TxGemma](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/txgemma) Generates predictions, classifications or text based on therapeutic related data and can be used to efficiently build AI models for therapeutic-related tasks with less data and less compute ![](https://ai.google.dev/gemma/images/gemma_sq.png) [MedGemma](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/medgemma) Collection of Gemma 3 variants that are trained for performance on medical text and image comprehension ![](https://ai.google.dev/gemma/images/gemma_sq.png) [MedSigLIP](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/medsiglip) SigLIP variant that is trained to encode medical images and text into a common embedding space ![](https://ai.google.dev/gemma/images/gemma_sq.png) [T5Gemma](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/T5Gemma) A family of lightweight yet powerful encoder-decoder research models from Google

## Embeddings models

width_normal [Embeddings for Text](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-embedding-001) Converts text data into vector representations for semantic search, classification, clustering, and similar tasks width_normal [Multimodal Embeddings](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/multimodalembedding) Generates vectors based on images, which can be used for downstream tasks like image classification, image search, and more

## Generally available Imagen models

photo_spark [Imagen 4 for Generation](/vertex-ai/generative-ai/docs/models/imagen/4-0-generate-001) Use text prompts to generate novel images with higher quality than our previous image generation models photo_spark [Imagen 4 for Fast Generation](/vertex-ai/generative-ai/docs/models/imagen/4-0-fast-generate-001) Use text prompts to generate novel images with higher quality and lower latency than our previous image generation models photo_spark [Imagen 4 for Ultra Generation](/vertex-ai/generative-ai/docs/models/imagen/4-0-ultra-generate-001) Use text prompts to generate novel images with higher quality and better prompt adherence than our previous image generation models photo_spark [Imagen 3 for Generation](/vertex-ai/generative-ai/docs/models/imagen/3-0-generate-002) Use text prompts to generate novel images image_edit_auto [Imagen 3 for Editing and Customization](/vertex-ai/generative-ai/docs/models/imagen/3-0-capability-001) Use text prompts to edit existing input images, or parts of an image with a mask or generate new images based upon the context provided by input reference images photo_spark [Imagen 3 for Fast Generation](/vertex-ai/generative-ai/docs/models/imagen/3-0-fast-generate-001) Use text prompts to generate novel images with lower latency than our other image generation models subtitles [Imagen for Captioning & VQA](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/imagetext) Use text prompts to generative novel images, edit existing ones, edit parts of an image with a mask and more

## Preview Imagen models

photo_spark [Virtual Try-On](/vertex-ai/generative-ai/docs/models/imagen/virtual-try-on-preview-08-04) Generate images of people wearing clothing products.  image_edit_auto [Imagen product recontext on Vertex AI](/vertex-ai/generative-ai/docs/models/imagen/imagen-product-recontext-preview-06-30) Use text prompts to edit product images into different scenes or backgrounds. 

## Veo models

movie [Veo 2](/vertex-ai/generative-ai/docs/models/veo/2-0-generate-001) Use text prompts and images to generate novel videos movie [Veo 3](/vertex-ai/generative-ai/docs/models/veo/3-0-generate-001) Use text prompts and images to generate novel videos with higher quality than our previous video generation model movie [Veo 3 Fast](/vertex-ai/generative-ai/docs/models/veo/3-0-fast-generate-001) Use text prompts and images to generate novel videos with higher quality and lower latency than our previous video generation model

## Preview Veo models

movie [Veo 3 preview](/vertex-ai/generative-ai/docs/models/veo/3-0-generate-preview) Use text prompts and images to generate novel videos with higher quality than our previous video generation model movie [Veo 3 Fast preview](/vertex-ai/generative-ai/docs/models/veo/3-0-generate-preview) Use text prompts and images to generate novel videos with higher quality and lower latency than our previous video generation model

## Experimental Veo models

movie [Veo 2 Experimental](/vertex-ai/generative-ai/docs/models/veo/2-0-generate-exp) An experimental model, with features under test.

## MedLM models

medical_information [MedLM-medium](/static/vertex-ai/generative-ai/docs/medlm/MedLM-model-card.pdf) HIPAA-compliant suite of medically tuned models designed to help healthcare practitioners with medical question and answer tasks, and summarization tasks for healthcare and medical documents clinical_notes [MedLM-large-large](/static/vertex-ai/generative-ai/docs/medlm/MedLM-model-card.pdf) HIPAA-compliant suite of medically tuned models designed to help healthcare practitioners with medical question and answer tasks, and summarization tasks for healthcare and medical documents

## Language support

### Gemini

All the Gemini models can understand and respond in the following languages: 

Afrikaans (`af`), Albanian (`sq`), Amharic (`am`), Arabic (`ar`), Armenian (`hy`), Assamese (`as`), Azerbaijani (`az`), Basque (`eu`), Belarusian (`be`), Bengali (`bn`), Bosnian (`bs`), Bulgarian (`bg`), Catalan (`ca`), Cebuano (`ceb`), Chinese (Simplified and Traditional) (`zh`), Corsican (`co`), Croatian (`hr`), Czech (`cs`), Danish (`da`), Dhivehi (`dv`), Dutch (`nl`), English (`en`), Esperanto (`eo`), Estonian (`et`), Filipino (Tagalog) (`fil`), Finnish (`fi`), French (`fr`), Frisian (`fy`), Galician (`gl`), Georgian (`ka`), German (`de`), Greek (`el`), Gujarati (`gu`), Haitian Creole (`ht`), Hausa (`ha`), Hawaiian (`haw`), Hebrew (`iw`), Hindi (`hi`), Hmong (`hmn`), Hungarian (`hu`), Icelandic (`is`), Igbo (`ig`), Indonesian (`id`), Irish (`ga`), Italian (`it`), Japanese (`ja`), Javanese (`jv`), Kannada (`kn`), Kazakh (`kk`), Khmer (`km`), Korean (`ko`), Krio (`kri`), Kurdish (`ku`), Kyrgyz (`ky`), Lao (`lo`), Latin (`la`), Latvian (`lv`), Lithuanian (`lt`), Luxembourgish (`lb`), Macedonian (`mk`), Malagasy (`mg`), Malay (`ms`), Malayalam (`ml`), Maltese (`mt`), Maori (`mi`), Marathi (`mr`), Meiteilon (Manipuri) (`mni-Mtei`), Mongolian (`mn`), Myanmar (Burmese) (`my`), Nepali (`ne`), Norwegian (`no`), Nyanja (Chichewa) (`ny`), Odia (Oriya) (`or`), Pashto (`ps`), Persian (`fa`), Polish (`pl`), Portuguese (`pt`), Punjabi (`pa`), Romanian (`ro`), Russian (`ru`), Samoan (`sm`), Scots Gaelic (`gd`), Serbian (`sr`), Sesotho (`st`), Shona (`sn`), Sindhi (`sd`), Sinhala (Sinhalese) (`si`), Slovak (`sk`), Slovenian (`sl`), Somali (`so`), Spanish (`es`), Sundanese (`su`), Swahili (`sw`), Swedish (`sv`), Tajik (`tg`), Tamil (`ta`), Telugu (`te`), Thai (`th`), Turkish (`tr`), Ukrainian (`uk`), Urdu (`ur`), Uyghur (`ug`), Uzbek (`uz`), Vietnamese (`vi`), Welsh (`cy`), Xhosa (`xh`), Yiddish (`yi`), Yoruba (`yo`), and Zulu (`zu`). 

### Gemma

Gemma and Gemma 2 support only the English (`en`) language. Gemma 3 and Gemma 3n provide multilingual support in over 140 languages. 

### Embeddings

Multilingual text embedding models support the following languages:

Afrikaans (`af`), Albanian (`sq`), Amharic (`am`), Arabic (`ar`), Armenian (`hy`), Azerbaijani (`az`), Basque (`eu`), Belarusian (`be`), Bengali (`bn`), Bulgarian (`bg`), Catalan (`ca`), Cebuano (`ceb`), Chinese (Simplified and Traditional) (`zh`), Corsican (`co`), Czech (`cs`), Danish (`da`), Dutch (`nl`), English (`en`), Esperanto (`eo`), Estonian (`et`), Filipino (Tagalog) (`fil`), Finnish (`fi`), French (`fr`), Frisian (`fy`), Galician (`gl`), Georgian (`ka`), German (`de`), Greek (`el`), Gujarati (`gu`), Haitian Creole (`ht`), Hausa (`ha`), Hawaiian (`haw`), Hebrew (`iw`), Hindi (`hi`), Hmong (`hmn`), Hungarian (`hu`), Icelandic (`is`), Igbo (`ig`), Indonesian (`id`), Irish (`ga`), Italian (`it`), Japanese (`ja`), Javanese (`jv`), Kannada (`kn`), Kazakh (`kk`), Khmer (`km`), Korean (`ko`), Kurdish (`ku`), Kyrgyz (`ky`), Lao (`lo`), Latin (`la`), Latvian (`lv`), Lithuanian (`lt`), Luxembourgish (`lb`), Macedonian (`mk`), Malagasy (`mg`), Malay (`ms`), Malayalam (`ml`), Maltese (`mt`), Maori (`mi`), Marathi (`mr`), Mongolian (`mn`), Myanmar (Burmese) (`my`), Nepali (`ne`), Nyanja (Chichewa) (`ny`), Norwegian (`no`), Pashto (`ps`), Persian (`fa`), Polish (`pl`), Portuguese (`pt`), Punjabi (`pa`), Romanian (`ro`), Russian (`ru`), Samoan (`sm`), Scots Gaelic (`gd`), Serbian (`sr`), Sesotho (`st`), Shona (`sn`), Sindhi (`sd`), Sinhala (Sinhalese) (`si`), Slovak (`sk`), Slovenian (`sl`), Somali (`so`), Spanish (`es`), Sundanese (`su`), Swahili (`sw`), Swedish (`sv`), Tajik (`tg`), Tamil (`ta`), Telugu (`te`), Thai (`th`), Turkish (`tr`), Ukrainian (`uk`), Urdu (`ur`), Uzbek (`uz`), Vietnamese (`vi`), Welsh (`cy`), Xhosa (`xh`), Yiddish (`yi`), Yoruba (`yo`), and Zulu (`zu`). 

### Imagen 3

Imagen 3 supports the following languages:

English (`en`), Chinese (Simplified and Traditional) (`zh`), Hindi (`hi`), Japanese (`ja`), Korean (`ko`), Portuguese (`pt`), and Spanish (`es`). 

### MedLM

The MedLM model supports the English (`en`) language. 

## Explore all models in Model Garden

Model Garden is a platform that helps you discover, test, customize, and deploy Google proprietary and select OSS models and assets. To explore the generative AI models and APIs that are available on Vertex AI, go to Model Garden in the Google Cloud console.

[Go to Model Garden](https://console.cloud.google.com/vertex-ai/model-garden)

To learn more about Model Garden, including available models and capabilities, see [Explore AI models in Model Garden](/vertex-ai/generative-ai/docs/model-garden/explore-models).

## Model versions

To see all model versions, including legacy and retired models, see [Model versions and lifecycle](/vertex-ai/generative-ai/docs/learn/model-versions).

## What's next

  * Try a quickstart tutorial using [Vertex AI Studio](/vertex-ai/generative-ai/docs/start/quickstarts/quickstart) or the [Vertex AI API](/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal).
  * Explore pretrained models in [Model Garden](/vertex-ai/generative-ai/docs/model-garden/explore-models).
  * Learn how to control access to specific models in Model Garden by using a [Model Garden organization policy](/vertex-ai/generative-ai/docs/control-model-access).
  * Learn about [pricing](/vertex-ai/generative-ai/pricing).



Send feedback 

Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-10-10 UTC.

Need to tell us more?  [[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Hard to understand","hardToUnderstand","thumb-down"],["Incorrect information or sample code","incorrectInformationOrSampleCode","thumb-down"],["Missing the information/samples I need","missingTheInformationSamplesINeed","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-10-10 UTC."],[],[]] 
[Sitemap](/sitemap/sitemap.xml)

[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc604964888f0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)

Sign up

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fsasmaster.medium.com%2Fmy-experience-with-googles-vertex-ai-c604964888f0&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)

[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)

[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)

[Search](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)

Sign up

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fsasmaster.medium.com%2Fmy-experience-with-googles-vertex-ai-c604964888f0&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)

![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)

# **My Experience with Google’s Vertex AI**

[![Michael Ivanov](https://miro.medium.com/v2/resize:fill:64:64/0*7tXoKy1wHP5TTa1L.png)](/?source=post_page---byline--c604964888f0---------------------------------------)

[Michael Ivanov](/?source=post_page---byline--c604964888f0---------------------------------------)

9 min read

·

Dec 18, 2023

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc604964888f0&operation=register&redirect=https%3A%2F%2Fsasmaster.medium.com%2Fmy-experience-with-googles-vertex-ai-c604964888f0&user=Michael+Ivanov&userId=6c3ff732a683&source=---header_actions--c604964888f0---------------------clap_footer------------------)

\--

2

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc604964888f0&operation=register&redirect=https%3A%2F%2Fsasmaster.medium.com%2Fmy-experience-with-googles-vertex-ai-c604964888f0&source=---header_actions--c604964888f0---------------------bookmark_footer------------------)

Listen

Share

 _Disclaimer: I am not associated in any way with the companies mentioned in this post. In fact, this is the first time in seven years that I am testing cloud providers in relation to my own product. All opinions expressed here are my own, based on the practical experience accumulated during those tests in relation to the products developed by Code Artworks Ltd._

I’m pressed for time and often find myself wishing I could eliminate the need for sleep, though that’s physically impossible. I am experimenting with various approaches, see if they work according to my needs then move on to design a PoC. In this mode I have got no time for a deep dive. My expertise in GCP or any other cloud services so far has been configuration of user account, setup of a cloud instance and related HW resources, installation of software and running of remotely deployed services in development environment. I’m confident that many early-stage startups, similar to me, don’t have the resources to hire cloud specialists (commonly referred to as ‘devops’), especially in the pre-seed stage of a company. This article shares my personal experience in setting up and using Google’s generative AI service called [Vertex AI](https://cloud.google.com/vertex-ai?hl=en). It’s important to note that the market is rapidly evolving, and any flaws, bugs, or deficiencies I detail further down may have been improved or fixed by the time you read this article.

So, we have been working on a new unannounced product which makes use of generative AI models. Initially we began playing around with OpenAI’s GPT chat API just to learn if it answered our application needs. It met our technical expectations. However, at present, OpenAI lacks the B2B infrastructure necessary for deploying their models in commercial-grade workloads. If your application is intended to be used by thousands of people globally, it requires management of servers, services, regions, storage, security, etc. Naturally, our next step was to explore running OpenAI on Azure. Unfortunately, as the feature was not publicly accessible, we had to fill out a form and submit a request to join the program.

During that period, I had the opportunity to attend the Google Cloud summit, where the company introduced Vertex AI. What appealed to me about Vertex was the concept of dedicated models tailored for specific use cases. Instead of relying on a single, all-encompassing ‘Swiss knife’ model, users could opt for smaller ones trained for problem domains like image recognition, text, chat, etc. This approach is designed to deliver faster response times, lower resource consumption, and ultimately reduce cloud usage costs. An additional advantage for startups leveraging AI services under Google Cloud Platform (GCP) is the seamless integration with other Google services, including App and Compute engines, authentication services, and more — all conveniently housed under the same roof. It sounded promising, so I decided to give it a try.

## **Basic Setup**

The GCP console has grown noticeably more complex since the last time I used it about seven years ago. However, the initial setup for Vertex AI isn’t as intimidating. To get started, simply log in to the Google Cloud console, click the navigation menu in the top left corner of the screen, then expand ‘more products’ and select Vertex AI under the ‘Artificial Intelligence’ menu.

My issues began at this stage. As a new user, I was following their video tutorial (which has been removed by the time of this writing), and it skipped the crucial step of clicking ‘Enable all recommended APIs’. Fortunately, this oversight has already been addressed by their [documentation](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).

Press enter or click to view image in full size

Don’t forget to press that blue button

The consequence of not enabling all the recommended APIs is that when setting up a fine-tuning job and clicking the ‘Start tuning’ button, nothing happens. This was particularly frustrating since the console didn’t provide any errors or warning messages. Out of desperation, I even posted a [question](https://www.googlecloudcommunity.com/gc/AI-ML/Vertex-AI-API-Can-t-launch-text-chat-model-tuning/td-p/658942) on their forums (but received no answers). It turned out to be one of those simple oversights that can consume hours of your time to figure out. In the end, I went through the entire process of setting up Vertex API from scratch and realized I hadn’t pressed that big blue button earlier.

## **Fine-tuning the model**

It took me a week to reach the point where I could successfully execute a fine-tuning job. Here’s why: GCP requires users to manually allocate hardware resource quotas for the services they plan to run. It seems they assume that all users have a background in devops. However, as I mentioned, I don’t have one. While I understand the process of configuring an instance for, let’s say, a rendering engine — ensuring it has not only a CPU but also an activated GPU — in this case, I’m not deploying my own product, nor am I a deep learning engineer. I can only guess what kind of hardware I need to activate in order to train a Vertex AI model.

Press enter or click to view image in full size

All the failures depicted in the screenshot are the result of missing hardware resource quota.

As I mentioned, Google doesn’t establish default hardware quotas; users are responsible for that. Consequently, when setting up a tuning job and initiating the pipeline, it leads to the failure of one of the pipeline nodes, elegantly visualized on an interactive graph in real-time.

Pipeline execution graph

By selecting the failed node, you can see an error dump on the right side of the console.

The ‘RESOURCE_EXHAUSTED’ message doesn’t make sense, at least to me, in this context, as there was no resource set in the first place. I wonder why Google doesn’t provide a default quota for resources that are absolutely required to run a fine-tuning job. In my case I had 3 types of resources missing as their default quotas are set to zero:

_restricted_image_training_a2_cpus_

 _restricted_image_training_nvidia_a100_80gb_gpus_

 _restricted_image_training_tpu_v3_pod_

Google allows users to choose between training on GPUs or TPUs. Since I experimented with both, I had to request quotas for both GPUs and TPUs. A2 CPUs, as I understand, are required in both cases because, as you know, we still need some kind of CPU on computers these days. The challenge is that those of you who have submitted requests for increasing quotas at GCP know that it doesn’t happen immediately. As mentioned earlier, I had to wait for a week until all the quotas were increased by the Google team. This is something I completely fail to understand: why can’t all the essential hardware quotas be allocated to a bare minimum by default?

Quota allocation is a separate issue, and I faced a challenge as I had no idea what the optimal minimum should be to efficiently run the training — where efficiency, for me, means achieving a good balance between speed and costs. Here, I made another mistake that could have been quite painful had I chosen to train on a large dataset.

During the time I conducted these tests, I couldn’t find any documentation explaining how many units of these resources I needed to allocate in quotas. For GPUs, I requested 1 or 2 — I don’t remember exactly. For TPUs, I requested 64 cores because, according to their documentation, TPUs are scaled by a factor of 64. However, I couldn’t find answers to crucial questions: Does fine-tuning need to run on all 64 cores? Can I allocate fewer? What is recommended as the minimum configuration requirement? The outcome of this experiment was a charge of $86 US dollars, in addition to the $400 Google gave me for the trial, for fine-tuning on a dataset consisting of only 200 lines of text, totaling 35 kilobytes of data.

As shown in the pipeline jobs list above, the successful job (green) took almost 7 hours. So, I contacted Google support to understand how this could happen. The answer was, ‘We see you used 400 hours to train the model…’. I couldn’t get reasonable answers, but they gladly refunded my credit card. By then, I was too frustrated to continue with the service but decided to try the fine-tuned model for which I paid $86. Not only did it fail to provide precise answers to the questions I asked (which were part of the training dataset), but the answers I received were nowhere close to the prompts in my datasets. Moreover, the default context had zero impact on the fine-tuned model. Even setting the temperature to zero resulted in answers that completely ignored the context.

Here is an example:

Default context prompt: “ _Your name is White Ball. You are a rabbit who lives in a fairy forest…_ ”

Testing the model:

Vertex AI playground output

## **API usage**

The goal was, of course, to utilize Vertex AI via the REST API in a native application. In this regard, as someone quite distant from web development, I had to grapple with OAuth related procedures. You see, all Google APIs require authentication via OAuth, and the official documentation lists several ways to achieve it. Then I realized the default authentication token expires after one hour, necessitating a refresh upon expiration.

To address this, I created a service account in GCP, allowing me to generate a key file containing all the information needed for creating and refreshing the authentication token. This approach also enables extending the authentication lifetime up to 12 hours. However, despite these efforts, I couldn’t find a practical REST-based example that provided step-by-step guidance on setting up these requests. Eventually, during these experiments, I abandoned attempts to make token refreshment happen automatically and opted to refresh it manually via the command line.

Vertex REST API expects Json formatted payload which looks very similar to OpenAI’s Json.

OpenAI’s format:

Vertex AI format:

As you can see, the JSON structure is not very different. The primary distinction is that in the OpenAI context, it is another type of message where ‘author’ is ‘system,’ whereas Vertex places the context as a separate node alongside the messages array. It’s worth noting that the context in the Vertex AI training dataset is optional. You can set a default one during fine-tuning job setup.

**To summarize:**

All of the above might sound like a rant, but trust me, that is not my intention. The goal of this article is to provide constructive feedback from the perspective of a small startup as a potential user. I invested a significant amount of time testing Vertex AI because GCP was the chosen platform for deploying our product. Unfortunately, my current verdict is that Vertex AI is not ready for commercial use. It feels buggy, challenging to set up, and even harder to fine-tune to meet specific requirements. Business-wise, the complexity of the service set-up could potentially discourage customers who just want to ‘get stuff done.’

As a point of comparison, after testing Vertex, I moved on to testing Azure’s OpenAI. Despite never having used Azure before, it took me around 10 minutes to figure out how to set up the service once accepted into their OpenAI trial. No OAuth, no manual hardware resource allocation. I was able to run REST requests a few hours later after adding all the required infrastructure on the client side. Why should it be so complicated for GCP users?

Hopefully, by the time you finish reading this article, Google has already addressed the problems I mentioned here. And if it hasn’t, well, there are alternatives. If this writing helps people working for Google make their products less cumbersome to use, then the time I spent writing it won’t have been wasted.

[Google](https://medium.com/tag/google?source=post_page-----c604964888f0---------------------------------------)

[AI](https://medium.com/tag/ai?source=post_page-----c604964888f0---------------------------------------)

[Vertex AI](https://medium.com/tag/vertex-ai?source=post_page-----c604964888f0---------------------------------------)

[OpenAI](https://medium.com/tag/openai?source=post_page-----c604964888f0---------------------------------------)

[Azure](https://medium.com/tag/azure?source=post_page-----c604964888f0---------------------------------------)

[![Michael Ivanov](https://miro.medium.com/v2/resize:fill:96:96/0*7tXoKy1wHP5TTa1L.png)](/?source=post_page---post_author_info--c604964888f0---------------------------------------)

[![Michael Ivanov](https://miro.medium.com/v2/resize:fill:128:128/0*7tXoKy1wHP5TTa1L.png)](/?source=post_page---post_author_info--c604964888f0---------------------------------------)

## [Written by Michael Ivanov](/?source=post_page---post_author_info--c604964888f0---------------------------------------)

[27 followers](/followers?source=post_page---post_author_info--c604964888f0---------------------------------------)

·[17 following](/following?source=post_page---post_author_info--c604964888f0---------------------------------------)

Founder and CTO at [codeartworks.com](http://codeartworks.com)

## Responses (2)

[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--c604964888f0---------------------------------------)

See all responses

[Help](https://help.medium.com/hc/en-us?source=post_page-----c604964888f0---------------------------------------)

[Status](https://status.medium.com/?source=post_page-----c604964888f0---------------------------------------)

[About](https://medium.com/about?autoplay=1&source=post_page-----c604964888f0---------------------------------------)

[Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----c604964888f0---------------------------------------)

[Press](mailto:pressinquiries@medium.com)

[Blog](https://blog.medium.com/?source=post_page-----c604964888f0---------------------------------------)

[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c604964888f0---------------------------------------)

[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----c604964888f0---------------------------------------)

[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c604964888f0---------------------------------------)

[Text to speech](https://speechify.com/medium?source=post_page-----c604964888f0---------------------------------------)
Skip to main content 

[ ![Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v0a8f38b07c3863b7ced1d678d2584c8bd483c306fc4b8f547093e71dea088feb/cloud/images/cloud-logo.svg) ](/)

  * 


`/`

  * English
  * Deutsch
  * Español
  * Español – América Latina
  * Français
  * Indonesia
  * Italiano
  * Português
  * Português – Brasil
  * 中文 – 简体
  * 中文 – 繁體
  * 日本語
  * 한국어

[ Console ](//console.cloud.google.com/) Sign in

  * [ Generative AI on Vertex AI ](https://cloud.google.com/vertex-ai/generative-ai/docs)



[Contact Us](https://cloud.google.com/contact) [Start free](//console.cloud.google.com/freetrial)

  * [ Home ](https://cloud.google.com/)
  * [ Generative AI on Vertex AI ](https://cloud.google.com/vertex-ai/generative-ai/docs)
  * [ Documentation ](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview)



Send feedback 

#  Vertex AI Agent Engine overview

Stay organized with collections  Save and categorize content based on your preferences. 

Vertex AI Agent Engine, a part of the Vertex AI Platform, is a set of services that enables developers to deploy, manage, and scale AI agents in production. Agent Engine handles the infrastructure to scale agents in production so you can focus on creating applications. Vertex AI Agent Engine offers the following services that you can use individually or in combination:

  * **Runtime** :

    * [Deploy](/vertex-ai/generative-ai/docs/agent-engine/deploy) and scale agents with a managed runtime and end-to-end management capabilities.
    * Customize the agent's container image with build-time installation scripts for system dependencies.
    * Use security features including VPC-SC compliance and configuration of authentication and IAM.
    * Access models and tools such as [function calling](/vertex-ai/generative-ai/docs/multimodal/function-calling).
    * Deploy agents built using different Python frameworks and the [Agent2Agent open protocol](/vertex-ai/generative-ai/docs/agent-engine/develop/a2a).
    * Understand agent behavior with [Google Cloud Trace](/vertex-ai/generative-ai/docs/agent-engine/manage/tracing) (supporting [OpenTelemetry](https://opentelemetry.io/)), [Cloud Monitoring](/vertex-ai/generative-ai/docs/agent-engine/manage/monitoring), and [Cloud Logging](/vertex-ai/generative-ai/docs/agent-engine/manage/logging).
  * **Quality and evaluation** (Preview): Evaluate agent quality with the integrated [Gen AI Evaluation service](/vertex-ai/generative-ai/docs/agent-engine/evaluate) and optimize agents with Gemini model training runs.

  * [**Example Store**](/vertex-ai/generative-ai/docs/example-store/overview) (Preview): Store and dynamically retrieve few-shot examples to improve agent performance.

  * [**Sessions**](/vertex-ai/generative-ai/docs/agent-engine/sessions/overview) (Preview): Agent Engine Sessions lets you store individual interactions between users and agents, providing definitive sources for conversation context.

  * [**Memory Bank**](/vertex-ai/generative-ai/docs/agent-engine/memory-bank/overview) (Preview): Agent Engine Memory Bank lets you store and retrieve information from sessions to personalize agent interactions.

  * [**Code Execution**](/vertex-ai/generative-ai/docs/agent-engine/code-execution/overview) (Preview): Agent Engine Code Execution lets your agent run code in a secure, isolated, and managed sandbox environment.




![Vertex AI Agent Engine conceptual overview](/static/vertex-ai/generative-ai/docs/agent-engine/images/agent-engine.png)

Vertex AI Agent Engine is part of [Vertex AI Agent Builder](/vertex-ai/generative-ai/docs/agent-builder/overview), a suite of features for discovering, building, and deploying AI agents.

## Create and deploy on Vertex AI Agent Engine

**Note:** For a streamlined, _IDE-based_ development and deployment experience with Vertex AI Agent Engine, consider the [agent-starter-pack](https://github.com/GoogleCloudPlatform/agent-starter-pack). It provides ready-to-use templates, a built-in UI for experimentation, and simplifies deployment, operations, evaluation, customization, and observability.

The workflow for building an agent on Vertex AI Agent Engine is:

Steps | Description  
---|---  
1\. [Set up the environment](/vertex-ai/generative-ai/docs/agent-engine/set-up) | Set up your Google project and install the latest version of the Vertex AI SDK for Python.  
2\. [Develop an agent](/vertex-ai/generative-ai/docs/agent-engine/develop) | Develop an agent that can be deployed on Vertex AI Agent Engine.  
3\. [Deploy the agent](/vertex-ai/generative-ai/docs/agent-engine/deploy) | Deploy the agent on the Vertex AI Agent Engine managed runtime.  
4\. [Use the agent](/vertex-ai/generative-ai/docs/agent-engine/use) | Query the agent by sending an API request.  
5\. [Manage the deployed agent](/vertex-ai/generative-ai/docs/agent-engine/manage) | Manage and delete agents that you have deployed to Vertex AI Agent Engine.  
  
The steps are illustrated by the following diagram:

![Create and deploy an agent](/static/vertex-ai/generative-ai/docs/agent-engine/images/build-app.png)   


## Supported frameworks

The following table describes the level of support Vertex AI Agent Engine provides for various agent frameworks:

Support level | Agent frameworks  
---|---  
**Custom template** : You can adapt a custom template to support deployment to Vertex AI Agent Engine from your framework. | [CrewAI](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/evaluating_crewai_agent_engine_customized_template.ipynb), [custom frameworks](/vertex-ai/generative-ai/docs/agent-engine/develop/custom)  
**Vertex AI SDK integration** : Vertex AI Agent Engine provides managed templates per framework in the Vertex AI SDK and documentation. | [AG2](/vertex-ai/generative-ai/docs/agent-engine/develop/ag2), [LlamaIndex](/vertex-ai/generative-ai/docs/agent-engine/develop/llama-index/query-pipeline)  
**Full integration** : Features are integrated to work across the framework, Vertex AI Agent Engine, and broader Google Cloud ecosystem. | [Agent Development Kit (ADK)](/vertex-ai/generative-ai/docs/agent-engine/develop/adk), [LangChain](/vertex-ai/generative-ai/docs/agent-engine/develop/langchain), [LangGraph](/vertex-ai/generative-ai/docs/agent-engine/develop/langgraph)  
  
## Deploy in production with Agent Starter Pack

The [Agent Starter Pack](https://github.com/GoogleCloudPlatform/agent-starter-pack) is a collection of production-ready generative AI agent templates built for Vertex AI Agent Engine. The Agent Starter Pack provides the following:

  * **Pre-built agent templates:** ReAct, RAG, multi-agent, and other templates.
  * **Interactive playground** : Test and interact with your agent.
  * **Automated infrastructure** : Uses [Terraform](https://cloud.google.com/docs/terraform) for streamlined resource management.
  * **CI/CD pipelines** : Automated deployment workflows leveraging Cloud Build.
  * **Observability** : Built-in support for Cloud Trace and Cloud Logging.



To get started, see the [Quickstart](https://github.com/GoogleCloudPlatform/agent-starter-pack?tab=readme-ov-file#-get-started-in-1-minute).

## Use cases

To learn about Vertex AI Agent Engine with end-to-end examples, see the following resources:

Use Case | Description | Links  
---|---|---  
Build agents by connecting to public APIs | Convert between currencies.   
  
Create a function that connects to a currency exchange app, allowing the model to provide accurate answers to queries such as "What's the exchange rate for euros to dollars today?" | [Vertex AI SDK for Python notebook - Intro to Building and Deploying an Agent with Vertex AI Agent Engine](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/intro_agent_engine.ipynb)  
Designing a community solar project.   
  
Identify potential locations, look up relevant government offices and suppliers, and review satellite images and solar potential of regions and buildings to find the optimal location to install your solar panels. | [Vertex AI SDK for Python notebook - Building and Deploying a Google Maps API Agent with Vertex AI Agent Engine](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/tutorial_google_maps_agent.ipynb)  
Build agents by connecting to databases | Integration with AlloyDB and Cloud SQL for PostgreSQL. | [Blog post - Announcing LangChain on Vertex AI for AlloyDB and Cloud SQL for PostgreSQL](https://cloud.google.com/blog/products/databases/alloydb-and-cloudsql-for-postgresql-on-langchain-on-vertex-ai)   
  
[Vertex AI SDK for Python notebook - Deploying a RAG Application with Cloud SQL for PostgreSQL to Vertex AI Agent Engine](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/tutorial_cloud_sql_pg_rag_agent.ipynb)   
  
[Vertex AI SDK for Python notebook - Deploying a RAG Application with AlloyDB for PostgreSQL to Vertex AI Agent Engine](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/tutorial_alloydb_rag_agent.ipynb)  
Build agents with tools that access data in your database. | [Vertex AI SDK for Python notebook - Deploying an Agent with Vertex AI Agent Engine and MCP Toolbox for Databases](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/tutorial_mcp_toolbox_for_databases.ipynb)  
Query and understand structured datastores using natural language. | [Vertex AI SDK for Python notebook - Building a Conversational Search Agent with Vertex AI Agent Engine and RAG on Vertex AI Search](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/tutorial_vertex_ai_search_rag_agent.ipynb)  
Query and understand graph databases using natural language | [Blog post - GenAI GraphRAG and AI agents using Vertex AI Agent Engine with LangChain and Neo4j](https://www.googlecloudcommunity.com/gc/Cloud-Product-Articles/GenAI-GraphRAG-and-AI-agents-using-Vertex-AI-Reasoning-Engine/ta-p/789066)  
Query and understand vector stores using natural language | [Blog post - Simplify GenAI RAG with MongoDB Atlas and Vertex AI Agent Engine](https://www.mongodb.com/developer/products/atlas/ragdeployment-vertex-ai-reasoning-engine/)  
Build agents with Agent Development Kit | Build and deploy agents using Agent Development Kit. | [Agent Development Kit -- Deploy to Vertex AI Agent Engine](http://google.github.io/adk-docs/deploy/agent-engine)  
Manage context with Vertex AI Agent Engine Sessions and Memory Bank in Vertex AI express mode without billing. | [Agent Development Kit -- Vertex AI Agent Engine Sessions and Memory Bank in Vertex AI express mode.](http://google.github.io/adk-docs/sessions/express-mode/)  
Build agents with OSS frameworks | Build and deploy agents using the OneTwo open-source framework. | [Blog post - OneTwo and Vertex AI Agent Engine: exploring advanced AI agent development on Google Cloud](https://www.googlecloudcommunity.com/gc/Community-Blogs/OneTwo-and-Vertex-AI-Reasoning-Engine-exploring-advanced-AI/ba-p/788254)  
Build and deploy agents using the LangGraph open-source framework. | [Vertex AI SDK for Python notebook - Building and Deploying a LangGraph Application with Vertex AI Agent Engine](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/tutorial_langgraph.ipynb)  
Debugging and optimizing agents | Build and trace agents using OpenTelemetry and Cloud Trace. | [Vertex AI SDK for Python notebook - Debugging and Optimizing Agents: A Guide to Tracing in Vertex AI Agent Engine](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/tracing_agents_in_agent_engine.ipynb)  
Build multi-agent systems with A2A protocol (preview) | Build interoperable agents that communicate and collaborate with other agents regardless of their framework. | For more information, see the [A2A protocol documentation](https://a2a-protocol.org/).  
  
## Enterprise security

Vertex AI Agent Engine supports several features to help you meet enterprise security requirements, adhere to your organization's security policies, and follow security best practices. The following features are supported:

  * **VPC Service Controls** : Vertex AI Agent Engine supports [VPC Service Controls](/vertex-ai/docs/general/vpc-service-controls) to strengthen data security and mitigate the risks of data exfiltration. When VPC Service Controls is configured, the deployed agent retains secure access to Google APIs and services, such as BigQuery API, Cloud SQL Admin API, and Vertex AI API, verifying seamless operation within your defined perimeter. Critically, VPC Service Controls effectively blocks all public internet access, confining data movement to your authorized network boundaries and significantly enhancing your enterprise security posture.

  * **Private Service Connect interface** : For Vertex AI Agent Engine Runtime, [PSC-I](/vpc/docs/about-private-service-connect-interfaces) lets your agents interact with privately hosted services in a user's VPC. For more information, see [Using Private Service Connect interface with Vertex AI Agent Engine](/vertex-ai/generative-ai/docs/agent-engine/private-service-connect-interface).

  * **Customer-managed encryption keys (CMEK)** : Vertex AI Agent Engine supports [CMEK](/kms/docs/cmek) to protect your data with your own encryption keys, which gives you ownership and full control of the keys that protect your data at rest in Google Cloud. For more information, see [Agent Engine CMEK](/vertex-ai/generative-ai/docs/agent-engine/manage/access#cmek).

  * **Data residency (DRZ)** : Vertex AI Agent Engine supports [Data residency (DRZ)](/vertex-ai/generative-ai/docs/learn/data-residency) to ensure that all data at rest and in use are stored within the specified region.

  * **HIPAA** : As a part of Vertex AI Platform, Vertex AI Agent Engine supports [HIPAA](https://cloud.google.com/security/compliance/hipaa) workloads.

  * **Access Transparency** : Access Transparency provides you with logs that capture the actions Google personnel take when accessing your content. For more information about how to enable Access Transparency for Vertex AI Agent Engine, see [Access Transparency in Vertex AI](/vertex-ai/docs/general/access-transparency).




The following table shows which enterprise security features are supported for each Agent Engine service:

Security feature | Runtime | Sessions | Memory Bank | Example Store | Code Execution  
---|---|---|---|---|---  
VPC Service Controls | Yes | Yes | Yes | No | No  
Customer-managed encryption keys | Yes | Yes | Yes | No | No  
Data residency (DRZ) at rest | Yes | Yes | Yes | No | No  
Data residency (DRZ) in use | No | Yes | Yes* | No | Yes  
HIPAA | Yes | Yes | Yes | Yes | No  
Access Transparency | Yes | Yes | Yes | No | No  
  
* Only when using a [Gemini regional endpoint](/vertex-ai/generative-ai/docs/learn/locations).

## Supported regions

Vertex AI Agent Engine Runtime, [Agent Engine Sessions](/vertex-ai/generative-ai/docs/agent-engine/sessions/overview), and [Vertex AI Agent Engine Memory Bank](/vertex-ai/generative-ai/docs/agent-engine/memory-bank/overview) are supported in the following regions:

Region | Location | Supported versions  
---|---|---  
`us-central1` | Iowa | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`us-east4` | Northern Virginia | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`us-west1` | Oregon | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`europe-west1` | Belgium | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`europe-west2` | London | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`europe-west3` | Frankfurt | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`europe-west4` | Netherlands | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`europe-southwest1` | Madrid | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`asia-east1` | Taiwan | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`asia-northeast1` | Tokyo | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`asia-south1` | Mumbai | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`asia-southeast1` | Singapore | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
`australia-southeast2` | Melbourne | `v1` is supported for GA features. `v1beta1` is supported for Preview features.  
  
For [Agent Engine Code Execution](/vertex-ai/generative-ai/docs/agent-engine/code-execution/overview) (Preview), the following regions are supported.

Region | Location | Supported versions  
---|---|---  
`us-central1` | Iowa | `v1beta1` version is supported.  
  
## Quota

The following limits apply to [Vertex AI Agent Engine](/vertex-ai/generative-ai/docs/agent-engine/overview) for a given project in each region: 

Description | Limit  
---|---  
Create, delete, or update Vertex AI Agent Engine per minute | 10  
Create, delete, or update Vertex AI Agent Engine sessions per minute | 100  
`Query` or `StreamQuery` Vertex AI Agent Engine per minute | 90  
Append event to Vertex AI Agent Engine sessions per minute | 300  
Maximum number of Vertex AI Agent Engine resources | 100  
Create, delete, or update Vertex AI Agent Engine memory resources per minute | 100  
Get, list, or retrieve from Vertex AI Agent Engine Memory Bank per minute | 300  
Sandbox environment (Code Execution) execute requests per minute | 1000  
Sandbox environment (Code Execution) entities per region | 1000  
A2A Agent post requests like `sendMessage` and `cancelTask`per minute | 60  
A2A Agent get requests like `getTask` and `getCard` per minute | 600  
Concurrent live bidirectional connections using the `BidiStreamQuery` API per minute | 10  
  
## Pricing

For information about pricing for Agent Engine Runtime, see [Vertex AI pricing](/vertex-ai/pricing#agent_engine).

## Migration to the client-based SDK

The `agent_engines` module within the Vertex AI SDK for Python is being refactored to a client-based design for the following key reasons:

  * To align with [Google ADK](https://google.github.io/adk-docs/) and Google Gen AI SDK in canonical type representations. This ensures a consistent and standardized way of representing data types across different SDKs, which simplifies interoperability and reduces conversion overhead.
  * For client-level scoping of Google Cloud parameters in multi-project multi-location applications. This allows an application to manage interactions with resources across different Google Cloud projects and geographical locations by configuring each client instance with its specific project and location settings.
  * To improve discoverability and cohesive of Vertex AI Agent Engine services



## What's next

  * [Set up the environment](/vertex-ai/generative-ai/docs/agent-engine/set-up).
  * [Get support](/vertex-ai/generative-ai/docs/agent-engine/support).



Send feedback 

Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-10-10 UTC.

Need to tell us more?  [[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Hard to understand","hardToUnderstand","thumb-down"],["Incorrect information or sample code","incorrectInformationOrSampleCode","thumb-down"],["Missing the information/samples I need","missingTheInformationSamplesINeed","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-10-10 UTC."],[],[]] 
02/10/2025, 16:09

Vertex AI RAG Engine overview | Generative AI on Vertex AI | Google Cloud

Vertex AI RAG Engine overview
The VPC-SC security controls (/vertex-ai/generative-ai/docs/security-controls) and CMEK are supported
by Vertex AI RAG Engine. Data residency and AXT security controls aren't supported.

The Vertex AI RAG Engine-managed Spanner instance is used as a vector database and is GA with billing
enabled. For more information, see Vertex AI RAG Engine billing
(/vertex-ai/generative-ai/docs/rag-engine/rag-engine-billing).

You must be added to the allowlist to access Vertex AI RAG Engine in us-central1. For users with
existing projects, there is no impact. For users with new projects, you can try other regions, or contact

vertex-ai-rag-engine-support@google.com to onboard to us-central1.
This page describes what Vertex AI RAG Engine is and how it works.

Description

Console

To learn how to use the Vertex AI SDK to run Vertex

Try Vertex AI RAG Engine (https://console.cloud.goo

AI RAG Engine tasks, see the RAG quickstart for
Python
(/vertex-ai/generative-ai/docs/rag-quickstart).

Overview
Vertex AI RAG Engine, a component of the Vertex AI Platform, facilitates RetrievalAugmented Generation (RAG). Vertex AI RAG Engine is also a data framework for
developing context-augmented large language model (LLM) applications. Context
augmentation occurs when you apply an LLM to your data. This implements retrievalaugmented generation (RAG).
A common problem with LLMs is that they don't understand private knowledge, that is, your
organization's data. With Vertex AI RAG Engine, you can enrich the LLM context with
additional private information, because the model can reduce hallucination and answer
questions more accurately.

https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/rag-overview

1/4

02/10/2025, 16:09

Vertex AI RAG Engine overview | Generative AI on Vertex AI | Google Cloud

By combining additional knowledge sources with the existing knowledge that LLMs have, a
better context is provided. The improved context along with the query enhances the quality
of the LLM's response.
The following image illustrates the key concepts to understanding Vertex AI RAG Engine.

These concepts are listed in the order of the retrieval-augmented generation (RAG) process.
1. Data ingestion: Intake data from different data sources. For example, local files, Cloud
Storage, and Google Drive.
2. Data transformation (/vertex-ai/generative-ai/docs/fine-tune-rag-transformations):
Conversion of the data in preparation for indexing. For example, data is split into
chunks.
3. Embedding (/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings): Numerical
representations of words or pieces of text. These numbers capture the semantic
meaning and context of the text. Similar or related words or text tend to have similar
embeddings, which means they are closer together in the high-dimensional vector
space.
4. Data indexing: Vertex AI RAG Engine creates an index called a corpus
(/vertex-ai/generative-ai/docs/manage-your-rag-corpus#corpus-management). The index

structures the knowledge base so it's optimized for searching. For example, the index
is like a detailed table of contents for a massive reference book.
5. Retrieval: When a user asks a question or provides a prompt, the retrieval component
in Vertex AI RAG Engine searches through its knowledge base to find information that
is relevant to the query.
6. Generation: The retrieved information becomes the context added to the original user
query as a guide for the generative AI model to generate factually grounded
(/vertex-ai/generative-ai/docs/grounding/overview) and relevant responses.

https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/rag-overview

2/4

02/10/2025, 16:09

Vertex AI RAG Engine overview | Generative AI on Vertex AI | Google Cloud

Supported regions
Vertex AI RAG Engine is supported in the following regions:

Region

Location

Description

Launch stage

us-central1

Iowa

v1 and v1beta1 versions are supported.

Allowlist

us-east4

Virginia

v1 and v1beta1 versions are supported.

GA

v1 and v1beta1 versions are supported.

GA

europe-west4 Eemshaven, Netherlands v1 and v1beta1 versions are supported.

GA

europe-west3 Frankfurt, Germany

us-central1 is changed to Allowlist. If you'd like to experiment with Vertex AI RAG
Engine, try other regions. If you plan to onboard your production traffic to uscentral1, contact vertex-ai-rag-engine-support@google.com.

Delete Vertex AI RAG Engine
The following code samples demonstrate how to delete a Vertex AI RAG Engine for the
Google Cloud console, Python, and REST:
Version 1 (v1) API parameters
(/vertex-ai/generative-ai/docs/model-reference/rag-api-v1#project-management-params-api)

and code samples
(/vertex-ai/generative-ai/docs/model-reference/rag-apiv1#update_your_ragengineconfig_to_the_unprovisioned_tier)

.
v1beta1 API parameters
(/vertex-ai/generative-ai/docs/model-reference/rag-api#project-management-params-api) and

code samples
(/vertex-ai/generative-ai/docs/model-reference/ragapi#update_your_ragengineconfig_to_the_unprovisioned_tier)

.

Submit feedback

https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/rag-overview

3/4

02/10/2025, 16:09

Vertex AI RAG Engine overview | Generative AI on Vertex AI | Google Cloud

To chat with Google support, go to the Vertex AI RAG Engine support group
(https://groups.google.com/a/google.com/g/vertex-ai-rag-engine-support).

To send an email, use the email address vertex-ai-rag-engine-support@google.com.

What's next
To learn how to use the Vertex AI SDK to run Vertex AI RAG Engine tasks, see RAG
quickstart for Python (/vertex-ai/generative-ai/docs/rag-quickstart).
To learn about grounding, see Grounding overview
(/vertex-ai/generative-ai/docs/grounding/overview).

To learn more about the responses from RAG, see Retrieval and Generation Output of
Vertex AI RAG Engine (/vertex-ai/generative-ai/docs/model-reference/rag-output-explained).
To learn about the RAG architecture:
Infrastructure for a RAG-capable generative AI application using Vertex AI and
Vector Search (/architecture/gen-ai-rag-vertex-ai-vector-search)
Infrastructure for a RAG-capable generative AI application using Vertex AI and
AlloyDB for PostgreSQL (/architecture/rag-capable-gen-ai-app-using-vertex-ai).
Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0
License (https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the Apache
2.0 License (https://www.apache.org/licenses/LICENSE-2.0). For details, see the Google Developers Site
Policies (https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its
affiliates.
Last updated 2025-10-02 UTC.

https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/rag-overview

4/4

Skip to main content 

[ ![Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v0a8f38b07c3863b7ced1d678d2584c8bd483c306fc4b8f547093e71dea088feb/cloud/images/cloud-logo.svg) ](/)

  * 


`/`

  * English
  * Deutsch
  * Español
  * Español – América Latina
  * Français
  * Indonesia
  * Italiano
  * Português
  * Português – Brasil
  * 中文 – 简体
  * 中文 – 繁體
  * 日本語
  * 한국어

[ Console ](//console.cloud.google.com/) Sign in

  * [ Generative AI on Vertex AI ](https://cloud.google.com/vertex-ai/generative-ai/docs)



[Contact Us](https://cloud.google.com/contact) [Start free](//console.cloud.google.com/freetrial)

  * [ Home ](https://cloud.google.com/)
  * [ Generative AI on Vertex AI ](https://cloud.google.com/vertex-ai/generative-ai/docs)
  * [ Documentation ](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview)



Send feedback 

#  Vertex AI RAG Engine overview

Stay organized with collections  Save and categorize content based on your preferences. 

This page describes what Vertex AI RAG Engine is and how it works.

**Description** | **Console**  
---|---  
To learn how to use the Vertex AI SDK to run Vertex AI RAG Engine tasks, see the [RAG quickstart for Python](/vertex-ai/generative-ai/docs/rag-quickstart). | [Try Vertex AI RAG Engine](https://console.cloud.google.com/vertex-ai/rag)  
  
## Overview

Vertex AI RAG Engine, a component of the Vertex AI Platform, facilitates Retrieval-Augmented Generation (RAG). Vertex AI RAG Engine is also a data framework for developing context-augmented large language model (LLM) applications. Context augmentation occurs when you apply an LLM to your data. This implements retrieval-augmented generation (RAG).

A common problem with LLMs is that they don't understand private knowledge, that is, your organization's data. With Vertex AI RAG Engine, you can enrich the LLM context with additional private information, because the model can reduce hallucination and answer questions more accurately.

By combining additional knowledge sources with the existing knowledge that LLMs have, a better context is provided. The improved context along with the query enhances the quality of the LLM's response.

The following image illustrates the key concepts to understanding Vertex AI RAG Engine.

![Vertex AI RAG key
concepts](/static/vertex-ai/images/Vertex-RAG-Diagram.png)

These concepts are listed in the order of the retrieval-augmented generation (RAG) process.

  1. **Data ingestion** : Intake data from different data sources. For example, local files, Cloud Storage, and Google Drive.

  2. [**Data transformation**](/vertex-ai/generative-ai/docs/fine-tune-rag-transformations): Conversion of the data in preparation for indexing. For example, data is split into chunks.

  3. [**Embedding**](/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings): Numerical representations of words or pieces of text. These numbers capture the semantic meaning and context of the text. Similar or related words or text tend to have similar embeddings, which means they are closer together in the high-dimensional vector space.

  4. **Data indexing** : Vertex AI RAG Engine creates an index called a [corpus](/vertex-ai/generative-ai/docs/manage-your-rag-corpus#corpus-management). The index structures the knowledge base so it's optimized for searching. For example, the index is like a detailed table of contents for a massive reference book.

  5. **Retrieval** : When a user asks a question or provides a prompt, the retrieval component in Vertex AI RAG Engine searches through its knowledge base to find information that is relevant to the query.

  6. **Generation** : The retrieved information becomes the context added to the original user query as a guide for the generative AI model to generate factually [grounded](/vertex-ai/generative-ai/docs/grounding/overview) and relevant responses.




## Supported regions

Vertex AI RAG Engine is supported in the following regions:

Region | Location | Description | Launch stage  
---|---|---|---  
`us-central1` | Iowa | `v1` and `v1beta1` versions are supported. | Allowlist  
`us-east4` | Virginia | `v1` and `v1beta1` versions are supported. | GA  
`europe-west3` | Frankfurt, Germany | `v1` and `v1beta1` versions are supported. | GA  
`europe-west4` | Eemshaven, Netherlands | `v1` and `v1beta1` versions are supported. | GA  
  
  * `us-central1` is changed to `Allowlist`. If you'd like to experiment with Vertex AI RAG Engine, try other regions. If you plan to onboard your production traffic to `us-central1`, contact `vertex-ai-rag-engine-support@google.com`.



## Delete Vertex AI RAG Engine

The following code samples demonstrate how to delete a Vertex AI RAG Engine for the Google Cloud console, Python, and REST:

  * Version 1 (v1) API [parameters](/vertex-ai/generative-ai/docs/model-reference/rag-api-v1#project-management-params-api) and [code samples](/vertex-ai/generative-ai/docs/model-reference/rag-api-v1#update_your_ragengineconfig_to_the_unprovisioned_tier).

  * v1beta1 API [parameters](/vertex-ai/generative-ai/docs/model-reference/rag-api#project-management-params-api) and [code samples](/vertex-ai/generative-ai/docs/model-reference/rag-api#update_your_ragengineconfig_to_the_unprovisioned_tier).




## Submit feedback

To chat with Google support, go to the [Vertex AI RAG Engine support group](https://groups.google.com/a/google.com/g/vertex-ai-rag-engine-support).

To send an email, use the email address `vertex-ai-rag-engine-support@google.com`.

## What's next

  * To learn how to use the Vertex AI SDK to run Vertex AI RAG Engine tasks, see [RAG quickstart for Python](/vertex-ai/generative-ai/docs/rag-quickstart).
  * To learn about grounding, see [Grounding overview](/vertex-ai/generative-ai/docs/grounding/overview).
  * To learn more about the responses from RAG, see [Retrieval and Generation Output of Vertex AI RAG Engine](/vertex-ai/generative-ai/docs/model-reference/rag-output-explained).
  * To learn about the RAG architecture: 
    * [Infrastructure for a RAG-capable generative AI application using Vertex AI and Vector Search](/architecture/gen-ai-rag-vertex-ai-vector-search)
    * [Infrastructure for a RAG-capable generative AI application using Vertex AI and AlloyDB for PostgreSQL](/architecture/rag-capable-gen-ai-app-using-vertex-ai).



Send feedback 

Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-10-10 UTC.

Need to tell us more?  [[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Hard to understand","hardToUnderstand","thumb-down"],["Incorrect information or sample code","incorrectInformationOrSampleCode","thumb-down"],["Missing the information/samples I need","missingTheInformationSamplesINeed","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-10-10 UTC."],[],[]] 
Skip to main content 

[ ![Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v0a8f38b07c3863b7ced1d678d2584c8bd483c306fc4b8f547093e71dea088feb/cloud/images/cloud-logo.svg) ](/)

  * 


`/`

  * English
  * Deutsch
  * Español – América Latina
  * Français
  * Português – Brasil
  * 中文 – 简体
  * 日本語
  * 한국어

[ Console ](//console.cloud.google.com/) Sign in

  * [ Vertex AI ](https://cloud.google.com/vertex-ai/docs)



[Contact Us](https://cloud.google.com/contact) [Start free](//console.cloud.google.com/freetrial)

  * [ Home ](https://cloud.google.com/)
  * [ Documentation ](https://cloud.google.com/docs)
  * [ AI and ML ](https://cloud.google.com/docs/ai-ml)
  * [ Vertex AI ](https://cloud.google.com/vertex-ai/docs)
  * [ Reference ](https://cloud.google.com/vertex-ai/docs/reference)



Send feedback 

#  Vertex AI API

Stay organized with collections  Save and categorize content based on your preferences. 

Train high-quality custom machine learning models with minimal machine learning expertise and effort.

## Service: aiplatform.googleapis.com

To call this service, we recommend that you use the Google-provided [client libraries](https://cloud.google.com/apis/docs/client-libraries-explained). If your application needs to use your own libraries to call this service, use the following information when you make the API requests.

### Discovery document

A [Discovery Document](https://developers.google.com/discovery/v1/reference/apis) is a machine-readable specification for describing and consuming REST APIs. It is used to build client libraries, IDE plugins, and other tools that interact with Google APIs. One service may provide multiple discovery documents. This service provides the following discovery documents:

  * <https://aiplatform.googleapis.com/$discovery/rest?version=v1>
  * <https://aiplatform.googleapis.com/$discovery/rest?version=v1beta1>



### Service endpoint

A [service endpoint](https://cloud.google.com/apis/design/glossary#api_service_endpoint) is a base URL that specifies the network address of an API service. One service might have multiple service endpoints. This service has the following service endpoints and all URIs below are relative to these service endpoints:

  * `https://aiplatform.googleapis.com`
  * `https://africa-south1-aiplatform.googleapis.com`
  * `https://asia-east1-aiplatform.googleapis.com`
  * `https://asia-east2-aiplatform.googleapis.com`
  * `https://asia-northeast1-aiplatform.googleapis.com`
  * `https://asia-northeast2-aiplatform.googleapis.com`
  * `https://asia-northeast3-aiplatform.googleapis.com`
  * `https://asia-south1-aiplatform.googleapis.com`
  * `https://asia-southeast1-aiplatform.googleapis.com`
  * `https://asia-southeast2-aiplatform.googleapis.com`
  * `https://australia-southeast1-aiplatform.googleapis.com`
  * `https://australia-southeast2-aiplatform.googleapis.com`
  * `https://europe-central2-aiplatform.googleapis.com`
  * `https://europe-north1-aiplatform.googleapis.com`
  * `https://europe-southwest1-aiplatform.googleapis.com`
  * `https://europe-west1-aiplatform.googleapis.com`
  * `https://europe-west2-aiplatform.googleapis.com`
  * `https://europe-west3-aiplatform.googleapis.com`
  * `https://europe-west4-aiplatform.googleapis.com`
  * `https://europe-west6-aiplatform.googleapis.com`
  * `https://europe-west8-aiplatform.googleapis.com`
  * `https://europe-west9-aiplatform.googleapis.com`
  * `https://europe-west12-aiplatform.googleapis.com`
  * `https://me-central1-aiplatform.googleapis.com`
  * `https://me-central2-aiplatform.googleapis.com`
  * `https://me-west1-aiplatform.googleapis.com`
  * `https://northamerica-northeast1-aiplatform.googleapis.com`
  * `https://northamerica-northeast2-aiplatform.googleapis.com`
  * `https://southamerica-east1-aiplatform.googleapis.com`
  * `https://southamerica-west1-aiplatform.googleapis.com`
  * `https://us-central1-aiplatform.googleapis.com`
  * `https://us-east1-aiplatform.googleapis.com`
  * `https://us-east4-aiplatform.googleapis.com`
  * `https://us-south1-aiplatform.googleapis.com`
  * `https://us-west1-aiplatform.googleapis.com`
  * `https://us-west2-aiplatform.googleapis.com`
  * `https://us-west3-aiplatform.googleapis.com`
  * `https://us-west4-aiplatform.googleapis.com`
  * `https://us-east5-aiplatform.googleapis.com`



See [Feature availability](/vertex-ai/docs/general/locations#feature-availability) for the supported features for each region. 

## REST Resource: [v1.media](/vertex-ai/docs/reference/rest/v1/media)

Methods  
---  
`[upload](/vertex-ai/docs/reference/rest/v1/media/upload)` |  `POST /v1/{parent}/ragFiles:upload`   
`POST /upload/v1/{parent}/ragFiles:upload`   
Upload a file into a RagCorpus.  
  
## REST Resource: [v1.projects.locations](/vertex-ai/docs/reference/rest/v1/projects.locations)

Methods  
---  
`[augmentPrompt](/vertex-ai/docs/reference/rest/v1/projects.locations/augmentPrompt)` |  `POST /v1/{parent}:augmentPrompt`   
Given an input prompt, it returns augmented prompt from vertex rag store to guide LLM towards generating grounded responses.  
`[corroborateContent](/vertex-ai/docs/reference/rest/v1/projects.locations/corroborateContent)` |  `POST /v1/{parent}:corroborateContent`   
Given an input text, it returns a score that evaluates the factuality of the text.  
`[deploy](/vertex-ai/docs/reference/rest/v1/projects.locations/deploy)` |  `POST /v1/{destination}:deploy`   
Deploys a model to a new endpoint.  
`[evaluateInstances](/vertex-ai/docs/reference/rest/v1/projects.locations/evaluateInstances)` |  `POST /v1/{location}:evaluateInstances`   
Evaluates instances based on a given metric.  
`[getRagEngineConfig](/vertex-ai/docs/reference/rest/v1/projects.locations/getRagEngineConfig)` |  `GET /v1/{name}`   
Gets a RagEngineConfig.  
`[retrieveContexts](/vertex-ai/docs/reference/rest/v1/projects.locations/retrieveContexts)` |  `POST /v1/{parent}:retrieveContexts`   
Retrieves relevant contexts for a query.  
`[updateRagEngineConfig](/vertex-ai/docs/reference/rest/v1/projects.locations/updateRagEngineConfig)` |  `PATCH /v1/{ragEngineConfig.name}`   
Updates a RagEngineConfig.  
  
## REST Resource: [v1.projects.locations.batchPredictionJobs](/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs/cancel)` |  `POST /v1/{name}:cancel`   
Cancels a BatchPredictionJob.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs/create)` |  `POST /v1/{parent}/batchPredictionJobs`   
Creates a BatchPredictionJob.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs/delete)` |  `DELETE /v1/{name}`   
Deletes a BatchPredictionJob.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs/get)` |  `GET /v1/{name}`   
Gets a BatchPredictionJob  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs/list)` |  `GET /v1/{parent}/batchPredictionJobs`   
Lists BatchPredictionJobs in a Location.  
  
## REST Resource: [v1.projects.locations.cachedContents](/vertex-ai/docs/reference/rest/v1/projects.locations.cachedContents)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.cachedContents/create)` |  `POST /v1/{parent}/cachedContents`   
Creates cached content, this call will initialize the cached content in the data storage, and users need to pay for the cache data storage.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.cachedContents/delete)` |  `DELETE /v1/{name}`   
Deletes cached content  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.cachedContents/get)` |  `GET /v1/{name}`   
Gets cached content configurations  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.cachedContents/list)` |  `GET /v1/{parent}/cachedContents`   
Lists cached contents in a project  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.cachedContents/patch)` |  `PATCH /v1/{cachedContent.name}`   
Updates cached content configurations  
  
## REST Resource: [v1.projects.locations.customJobs](/vertex-ai/docs/reference/rest/v1/projects.locations.customJobs)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1/projects.locations.customJobs/cancel)` |  `POST /v1/{name}:cancel`   
Cancels a CustomJob.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.customJobs/create)` |  `POST /v1/{parent}/customJobs`   
Creates a CustomJob.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.customJobs/delete)` |  `DELETE /v1/{name}`   
Deletes a CustomJob.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.customJobs/get)` |  `GET /v1/{name}`   
Gets a CustomJob.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.customJobs/list)` |  `GET /v1/{parent}/customJobs`   
Lists CustomJobs in a Location.  
  
## REST Resource: [v1.projects.locations.datasets](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets/create)` |  `POST /v1/{parent}/datasets`   
Creates a Dataset.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets/delete)` |  `DELETE /v1/{name}`   
Deletes a Dataset.  
`[export](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets/export)` |  `POST /v1/{name}:export`   
Exports data from a Dataset.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets/get)` |  `GET /v1/{name}`   
Gets a Dataset.  
`[import](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets/import)` |  `POST /v1/{name}:import`   
Imports data into a Dataset.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets/list)` |  `GET /v1/{parent}/datasets`   
Lists Datasets in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets/patch)` |  `PATCH /v1/{dataset.name}`   
Updates a Dataset.  
`[searchDataItems](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets/searchDataItems)` |  `GET /v1/{dataset}:searchDataItems`   
Searches DataItems in a Dataset.  
  
## REST Resource: [v1.projects.locations.datasets.annotationSpecs](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.annotationSpecs)

Methods  
---  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.annotationSpecs/get)` |  `GET /v1/{name}`   
Gets an AnnotationSpec.  
  
## REST Resource: [v1.projects.locations.datasets.dataItems](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.dataItems)

Methods  
---  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.dataItems/list)` |  `GET /v1/{parent}/dataItems`   
Lists DataItems in a Dataset.  
  
## REST Resource: [v1.projects.locations.datasets.dataItems.annotations](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.dataItems.annotations)

Methods  
---  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.dataItems.annotations/list)` |  `GET /v1/{parent}/annotations`   
Lists Annotations belongs to a dataitem.  
  
## REST Resource: [v1.projects.locations.datasets.datasetVersions](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.datasetVersions)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.datasetVersions/create)` |  `POST /v1/{parent}/datasetVersions`   
Create a version from a Dataset.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.datasetVersions/delete)` |  `DELETE /v1/{name}`   
Deletes a Dataset version.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.datasetVersions/get)` |  `GET /v1/{name}`   
Gets a Dataset version.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.datasetVersions/list)` |  `GET /v1/{parent}/datasetVersions`   
Lists DatasetVersions in a Dataset.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.datasetVersions/patch)` |  `PATCH /v1/{datasetVersion.name}`   
Updates a DatasetVersion.  
`[restore](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.datasetVersions/restore)` |  `GET /v1/{name}:restore`   
Restores a dataset version.  
  
## REST Resource: [v1.projects.locations.datasets.savedQueries](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.savedQueries)

Methods  
---  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.savedQueries/delete)` |  `DELETE /v1/{name}`   
Deletes a SavedQuery.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.datasets.savedQueries/list)` |  `GET /v1/{parent}/savedQueries`   
Lists SavedQueries in a Dataset.  
  
## REST Resource: [v1.projects.locations.deploymentResourcePools](/vertex-ai/docs/reference/rest/v1/projects.locations.deploymentResourcePools)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.deploymentResourcePools/create)` |  `POST /v1/{parent}/deploymentResourcePools`   
Create a DeploymentResourcePool.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.deploymentResourcePools/delete)` |  `DELETE /v1/{name}`   
Delete a DeploymentResourcePool.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.deploymentResourcePools/get)` |  `GET /v1/{name}`   
Get a DeploymentResourcePool.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.deploymentResourcePools/list)` |  `GET /v1/{parent}/deploymentResourcePools`   
List DeploymentResourcePools in a location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.deploymentResourcePools/patch)` |  `PATCH /v1/{deploymentResourcePool.name}`   
Update a DeploymentResourcePool.  
`[queryDeployedModels](/vertex-ai/docs/reference/rest/v1/projects.locations.deploymentResourcePools/queryDeployedModels)` |  `GET /v1/{deploymentResourcePool}:queryDeployedModels`   
List DeployedModels that have been deployed on this DeploymentResourcePool.  
  
## REST Resource: [v1.projects.locations.endpoints](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints)

Methods  
---  
`[computeTokens](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/computeTokens)` |  `POST /v1/{endpoint}:computeTokens`   
Return a list of tokens based on the input text.  
`[countTokens](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/countTokens)` |  `POST /v1/{endpoint}:countTokens`   
Perform a token counting.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/create)` |  `POST /v1/{parent}/endpoints`   
Creates an Endpoint.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/delete)` |  `DELETE /v1/{name}`   
Deletes an Endpoint.  
`[deployModel](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/deployModel)` |  `POST /v1/{endpoint}:deployModel`   
Deploys a Model into this Endpoint, creating a DeployedModel within it.  
`[directPredict](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/directPredict)` |  `POST /v1/{endpoint}:directPredict`   
Perform an unary online prediction request to a gRPC model server for Vertex first-party products and frameworks.  
`[directRawPredict](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/directRawPredict)` |  `POST /v1/{endpoint}:directRawPredict`   
Perform an unary online prediction request to a gRPC model server for custom containers.  
`[explain](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/explain)` |  `POST /v1/{endpoint}:explain`   
Perform an online explanation.  
`[generateContent](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/generateContent)` |  `POST /v1/{model}:generateContent`   
Generate content with multimodal inputs.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/get)` |  `GET /v1/{name}`   
Gets an Endpoint.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/list)` |  `GET /v1/{parent}/endpoints`   
Lists Endpoints in a Location.  
`[mutateDeployedModel](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/mutateDeployedModel)` |  `POST /v1/{endpoint}:mutateDeployedModel`   
Updates an existing deployed model.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/patch)` |  `PATCH /v1/{endpoint.name}`   
Updates an Endpoint.  
`[predict](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/predict)` |  `POST /v1/{endpoint}:predict`   
Perform an online prediction.  
`[predictLongRunning](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/predictLongRunning)` |  `POST /v1/{endpoint}:predictLongRunning`   
  
`[rawPredict](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/rawPredict)` |  `POST /v1/{endpoint}:rawPredict`   
Perform an online prediction with an arbitrary HTTP payload.  
`[serverStreamingPredict](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/serverStreamingPredict)` |  `POST /v1/{endpoint}:serverStreamingPredict`   
Perform a server-side streaming online prediction request for Vertex LLM streaming.  
`[streamRawPredict](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/streamRawPredict)` |  `POST /v1/{endpoint}:streamRawPredict`   
Perform a streaming online prediction with an arbitrary HTTP payload.  
`[undeployModel](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/undeployModel)` |  `POST /v1/{endpoint}:undeployModel`   
Undeploys a Model from an Endpoint, removing a DeployedModel from it, and freeing all resources it's using.  
`[update](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/update)` |  `POST /v1/{endpoint.name}:update`   
Updates an Endpoint with a long running operation.  
  
## REST Resource: [v1.projects.locations.featureGroups](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups/create)` |  `POST /v1/{parent}/featureGroups`   
Creates a new FeatureGroup in a given project and location.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups/delete)` |  `DELETE /v1/{name}`   
Deletes a single FeatureGroup.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups/get)` |  `GET /v1/{name}`   
Gets details of a single FeatureGroup.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups/getIamPolicy)` |  `POST /v1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups/list)` |  `GET /v1/{parent}/featureGroups`   
Lists FeatureGroups in a given project and location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups/patch)` |  `PATCH /v1/{featureGroup.name}`   
Updates the parameters of a single FeatureGroup.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups/setIamPolicy)` |  `POST /v1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups/testIamPermissions)` |  `POST /v1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
  
## REST Resource: [v1.projects.locations.featureGroups.features](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups.features)

Methods  
---  
`[batchCreate](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups.features/batchCreate)` |  `POST /v1/{parent}/features:batchCreate`   
Creates a batch of Features in a given FeatureGroup.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups.features/create)` |  `POST /v1/{parent}/features`   
Creates a new Feature in a given FeatureGroup.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups.features/delete)` |  `DELETE /v1/{name}`   
Deletes a single Feature.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups.features/get)` |  `GET /v1/{name}`   
Gets details of a single Feature.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups.features/list)` |  `GET /v1/{parent}/features`   
Lists Features in a given FeatureGroup.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.featureGroups.features/patch)` |  `PATCH /v1/{feature.name}`   
Updates the parameters of a single Feature.  
  
## REST Resource: [v1.projects.locations.featureOnlineStores](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores/create)` |  `POST /v1/{parent}/featureOnlineStores`   
Creates a new FeatureOnlineStore in a given project and location.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores/delete)` |  `DELETE /v1/{name}`   
Deletes a single FeatureOnlineStore.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores/get)` |  `GET /v1/{name}`   
Gets details of a single FeatureOnlineStore.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores/getIamPolicy)` |  `POST /v1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores/list)` |  `GET /v1/{parent}/featureOnlineStores`   
Lists FeatureOnlineStores in a given project and location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores/patch)` |  `PATCH /v1/{featureOnlineStore.name}`   
Updates the parameters of a single FeatureOnlineStore.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores/setIamPolicy)` |  `POST /v1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores/testIamPermissions)` |  `POST /v1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
  
## REST Resource: [v1.projects.locations.featureOnlineStores.featureViews](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/create)` |  `POST /v1/{parent}/featureViews`   
Creates a new FeatureView in a given FeatureOnlineStore.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/delete)` |  `DELETE /v1/{name}`   
Deletes a single FeatureView.  
`[directWrite](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/directWrite)` |  `POST /v1/{featureView}:directWrite`   
Bidirectional streaming RPC to directly write to feature values in a feature view.  
`[fetchFeatureValues](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/fetchFeatureValues)` |  `POST /v1/{featureView}:fetchFeatureValues`   
Fetch feature values under a FeatureView.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/get)` |  `GET /v1/{name}`   
Gets details of a single FeatureView.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/getIamPolicy)` |  `POST /v1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/list)` |  `GET /v1/{parent}/featureViews`   
Lists FeatureViews in a given FeatureOnlineStore.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/patch)` |  `PATCH /v1/{featureView.name}`   
Updates the parameters of a single FeatureView.  
`[searchNearestEntities](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/searchNearestEntities)` |  `POST /v1/{featureView}:searchNearestEntities`   
Search the nearest entities under a FeatureView.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/setIamPolicy)` |  `POST /v1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[sync](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/sync)` |  `POST /v1/{featureView}:sync`   
Triggers on-demand sync for the FeatureView.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews/testIamPermissions)` |  `POST /v1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
  
## REST Resource: [v1.projects.locations.featureOnlineStores.featureViews.featureViewSyncs](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews.featureViewSyncs)

Methods  
---  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews.featureViewSyncs/get)` |  `GET /v1/{name}`   
Gets details of a single FeatureViewSync.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores.featureViews.featureViewSyncs/list)` |  `GET /v1/{parent}/featureViewSyncs`   
Lists FeatureViewSyncs in a given FeatureView.  
  
## REST Resource: [v1.projects.locations.featurestores](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores)

Methods  
---  
`[batchReadFeatureValues](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores/batchReadFeatureValues)` |  `POST /v1/{featurestore}:batchReadFeatureValues`   
Batch reads Feature values from a Featurestore.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores/create)` |  `POST /v1/{parent}/featurestores`   
Creates a new Featurestore in a given project and location.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores/delete)` |  `DELETE /v1/{name}`   
Deletes a single Featurestore.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores/get)` |  `GET /v1/{name}`   
Gets details of a single Featurestore.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores/getIamPolicy)` |  `POST /v1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores/list)` |  `GET /v1/{parent}/featurestores`   
Lists Featurestores in a given project and location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores/patch)` |  `PATCH /v1/{featurestore.name}`   
Updates the parameters of a single Featurestore.  
`[searchFeatures](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores/searchFeatures)` |  `GET /v1/{location}/featurestores:searchFeatures`   
Searches Features matching a query in a given project.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores/setIamPolicy)` |  `POST /v1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores/testIamPermissions)` |  `POST /v1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
  
## REST Resource: [v1.projects.locations.featurestores.entityTypes](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/create)` |  `POST /v1/{parent}/entityTypes`   
Creates a new EntityType in a given Featurestore.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/delete)` |  `DELETE /v1/{name}`   
Deletes a single EntityType.  
`[deleteFeatureValues](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/deleteFeatureValues)` |  `POST /v1/{entityType}:deleteFeatureValues`   
Delete Feature values from Featurestore.  
`[exportFeatureValues](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/exportFeatureValues)` |  `POST /v1/{entityType}:exportFeatureValues`   
Exports Feature values from all the entities of a target EntityType.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/get)` |  `GET /v1/{name}`   
Gets details of a single EntityType.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/getIamPolicy)` |  `POST /v1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[importFeatureValues](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/importFeatureValues)` |  `POST /v1/{entityType}:importFeatureValues`   
Imports Feature values into the Featurestore from a source storage.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/list)` |  `GET /v1/{parent}/entityTypes`   
Lists EntityTypes in a given Featurestore.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/patch)` |  `PATCH /v1/{entityType.name}`   
Updates the parameters of a single EntityType.  
`[readFeatureValues](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/readFeatureValues)` |  `POST /v1/{entityType}:readFeatureValues`   
Reads Feature values of a specific entity of an EntityType.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/setIamPolicy)` |  `POST /v1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[streamingReadFeatureValues](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/streamingReadFeatureValues)` |  `POST /v1/{entityType}:streamingReadFeatureValues`   
Reads Feature values for multiple entities.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/testIamPermissions)` |  `POST /v1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
`[writeFeatureValues](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/writeFeatureValues)` |  `POST /v1/{entityType}:writeFeatureValues`   
Writes Feature values of one or more entities of an EntityType.  
  
## REST Resource: [v1.projects.locations.featurestores.entityTypes.features](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes.features)

Methods  
---  
`[batchCreate](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes.features/batchCreate)` |  `POST /v1/{parent}/features:batchCreate`   
Creates a batch of Features in a given EntityType.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes.features/create)` |  `POST /v1/{parent}/features`   
Creates a new Feature in a given EntityType.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes.features/delete)` |  `DELETE /v1/{name}`   
Deletes a single Feature.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes.features/get)` |  `GET /v1/{name}`   
Gets details of a single Feature.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes.features/list)` |  `GET /v1/{parent}/features`   
Lists Features in a given EntityType.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes.features/patch)` |  `PATCH /v1/{feature.name}`   
Updates the parameters of a single Feature.  
  
## REST Resource: [v1.projects.locations.hyperparameterTuningJobs](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs/cancel)` |  `POST /v1/{name}:cancel`   
Cancels a HyperparameterTuningJob.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs/create)` |  `POST /v1/{parent}/hyperparameterTuningJobs`   
Creates a HyperparameterTuningJob  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs/delete)` |  `DELETE /v1/{name}`   
Deletes a HyperparameterTuningJob.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs/get)` |  `GET /v1/{name}`   
Gets a HyperparameterTuningJob  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs/list)` |  `GET /v1/{parent}/hyperparameterTuningJobs`   
Lists HyperparameterTuningJobs in a Location.  
  
## REST Resource: [v1.projects.locations.indexEndpoints](/vertex-ai/docs/reference/rest/v1/projects.locations.indexEndpoints)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.indexEndpoints/create)` |  `POST /v1/{parent}/indexEndpoints`   
Creates an IndexEndpoint.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.indexEndpoints/delete)` |  `DELETE /v1/{name}`   
Deletes an IndexEndpoint.  
`[deployIndex](/vertex-ai/docs/reference/rest/v1/projects.locations.indexEndpoints/deployIndex)` |  `POST /v1/{indexEndpoint}:deployIndex`   
Deploys an Index into this IndexEndpoint, creating a DeployedIndex within it.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.indexEndpoints/get)` |  `GET /v1/{name}`   
Gets an IndexEndpoint.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.indexEndpoints/list)` |  `GET /v1/{parent}/indexEndpoints`   
Lists IndexEndpoints in a Location.  
`[mutateDeployedIndex](/vertex-ai/docs/reference/rest/v1/projects.locations.indexEndpoints/mutateDeployedIndex)` |  `POST /v1/{indexEndpoint}:mutateDeployedIndex`   
Update an existing DeployedIndex under an IndexEndpoint.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.indexEndpoints/patch)` |  `PATCH /v1/{indexEndpoint.name}`   
Updates an IndexEndpoint.  
`[undeployIndex](/vertex-ai/docs/reference/rest/v1/projects.locations.indexEndpoints/undeployIndex)` |  `POST /v1/{indexEndpoint}:undeployIndex`   
Undeploys an Index from an IndexEndpoint, removing a DeployedIndex from it, and freeing all resources it's using.  
  
## REST Resource: [v1.projects.locations.indexes](/vertex-ai/docs/reference/rest/v1/projects.locations.indexes)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.indexes/create)` |  `POST /v1/{parent}/indexes`   
Creates an Index.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.indexes/delete)` |  `DELETE /v1/{name}`   
Deletes an Index.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.indexes/get)` |  `GET /v1/{name}`   
Gets an Index.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.indexes/list)` |  `GET /v1/{parent}/indexes`   
Lists Indexes in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.indexes/patch)` |  `PATCH /v1/{index.name}`   
Updates an Index.  
`[removeDatapoints](/vertex-ai/docs/reference/rest/v1/projects.locations.indexes/removeDatapoints)` |  `POST /v1/{index}:removeDatapoints`   
Remove Datapoints from an Index.  
`[upsertDatapoints](/vertex-ai/docs/reference/rest/v1/projects.locations.indexes/upsertDatapoints)` |  `POST /v1/{index}:upsertDatapoints`   
Add/update Datapoints into an Index.  
  
## REST Resource: [v1.projects.locations.metadataStores](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores/create)` |  `POST /v1/{parent}/metadataStores`   
Initializes a MetadataStore, including allocation of resources.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores/delete)` |  `DELETE /v1/{name}`   
Deletes a single MetadataStore and all its child resources (Artifacts, Executions, and Contexts).  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores/get)` |  `GET /v1/{name}`   
Retrieves a specific MetadataStore.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores/list)` |  `GET /v1/{parent}/metadataStores`   
Lists MetadataStores for a Location.  
  
## REST Resource: [v1.projects.locations.metadataStores.artifacts](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.artifacts)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.artifacts/create)` |  `POST /v1/{parent}/artifacts`   
Creates an Artifact associated with a MetadataStore.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.artifacts/delete)` |  `DELETE /v1/{name}`   
Deletes an Artifact.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.artifacts/get)` |  `GET /v1/{name}`   
Retrieves a specific Artifact.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.artifacts/list)` |  `GET /v1/{parent}/artifacts`   
Lists Artifacts in the MetadataStore.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.artifacts/patch)` |  `PATCH /v1/{artifact.name}`   
Updates a stored Artifact.  
`[purge](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.artifacts/purge)` |  `POST /v1/{parent}/artifacts:purge`   
Purges Artifacts.  
`[queryArtifactLineageSubgraph](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.artifacts/queryArtifactLineageSubgraph)` |  `GET /v1/{artifact}:queryArtifactLineageSubgraph`   
Retrieves lineage of an Artifact represented through Artifacts and Executions connected by Event edges and returned as a LineageSubgraph.  
  
## REST Resource: [v1.projects.locations.metadataStores.contexts](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.contexts)

Methods  
---  
`[addContextArtifactsAndExecutions](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.contexts/addContextArtifactsAndExecutions)` |  `POST /v1/{context}:addContextArtifactsAndExecutions`   
Adds a set of Artifacts and Executions to a Context.  
`[addContextChildren](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.contexts/addContextChildren)` |  `POST /v1/{context}:addContextChildren`   
Adds a set of Contexts as children to a parent Context.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.contexts/create)` |  `POST /v1/{parent}/contexts`   
Creates a Context associated with a MetadataStore.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.contexts/delete)` |  `DELETE /v1/{name}`   
Deletes a stored Context.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.contexts/get)` |  `GET /v1/{name}`   
Retrieves a specific Context.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.contexts/list)` |  `GET /v1/{parent}/contexts`   
Lists Contexts on the MetadataStore.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.contexts/patch)` |  `PATCH /v1/{context.name}`   
Updates a stored Context.  
`[purge](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.contexts/purge)` |  `POST /v1/{parent}/contexts:purge`   
Purges Contexts.  
`[queryContextLineageSubgraph](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.contexts/queryContextLineageSubgraph)` |  `GET /v1/{context}:queryContextLineageSubgraph`   
Retrieves Artifacts and Executions within the specified Context, connected by Event edges and returned as a LineageSubgraph.  
`[removeContextChildren](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.contexts/removeContextChildren)` |  `POST /v1/{context}:removeContextChildren`   
Remove a set of children contexts from a parent Context.  
  
## REST Resource: [v1.projects.locations.metadataStores.executions](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.executions)

Methods  
---  
`[addExecutionEvents](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.executions/addExecutionEvents)` |  `POST /v1/{execution}:addExecutionEvents`   
Adds Events to the specified Execution.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.executions/create)` |  `POST /v1/{parent}/executions`   
Creates an Execution associated with a MetadataStore.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.executions/delete)` |  `DELETE /v1/{name}`   
Deletes an Execution.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.executions/get)` |  `GET /v1/{name}`   
Retrieves a specific Execution.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.executions/list)` |  `GET /v1/{parent}/executions`   
Lists Executions in the MetadataStore.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.executions/patch)` |  `PATCH /v1/{execution.name}`   
Updates a stored Execution.  
`[purge](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.executions/purge)` |  `POST /v1/{parent}/executions:purge`   
Purges Executions.  
`[queryExecutionInputsAndOutputs](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.executions/queryExecutionInputsAndOutputs)` |  `GET /v1/{execution}:queryExecutionInputsAndOutputs`   
Obtains the set of input and output Artifacts for this Execution, in the form of LineageSubgraph that also contains the Execution and connecting Events.  
  
## REST Resource: [v1.projects.locations.metadataStores.metadataSchemas](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.metadataSchemas)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.metadataSchemas/create)` |  `POST /v1/{parent}/metadataSchemas`   
Creates a MetadataSchema.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.metadataSchemas/get)` |  `GET /v1/{name}`   
Retrieves a specific MetadataSchema.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores.metadataSchemas/list)` |  `GET /v1/{parent}/metadataSchemas`   
Lists MetadataSchemas.  
  
## REST Resource: [v1.projects.locations.migratableResources](/vertex-ai/docs/reference/rest/v1/projects.locations.migratableResources)

Methods  
---  
`[batchMigrate](/vertex-ai/docs/reference/rest/v1/projects.locations.migratableResources/batchMigrate)` |  `POST /v1/{parent}/migratableResources:batchMigrate`   
Batch migrates resources from ml.googleapis.com, automl.googleapis.com, and datalabeling.googleapis.com to Vertex AI.  
`[search](/vertex-ai/docs/reference/rest/v1/projects.locations.migratableResources/search)` |  `POST /v1/{parent}/migratableResources:search`   
Searches all of the resources in automl.googleapis.com, datalabeling.googleapis.com and ml.googleapis.com that can be migrated to Vertex AI's given location.  
  
## REST Resource: [v1.projects.locations.modelDeploymentMonitoringJobs](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs/create)` |  `POST /v1/{parent}/modelDeploymentMonitoringJobs`   
Creates a ModelDeploymentMonitoringJob.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs/delete)` |  `DELETE /v1/{name}`   
Deletes a ModelDeploymentMonitoringJob.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs/get)` |  `GET /v1/{name}`   
Gets a ModelDeploymentMonitoringJob.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs/list)` |  `GET /v1/{parent}/modelDeploymentMonitoringJobs`   
Lists ModelDeploymentMonitoringJobs in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs/patch)` |  `PATCH /v1/{modelDeploymentMonitoringJob.name}`   
Updates a ModelDeploymentMonitoringJob.  
`[pause](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs/pause)` |  `POST /v1/{name}:pause`   
Pauses a ModelDeploymentMonitoringJob.  
`[resume](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs/resume)` |  `POST /v1/{name}:resume`   
Resumes a paused ModelDeploymentMonitoringJob.  
`[searchModelDeploymentMonitoringStatsAnomalies](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs/searchModelDeploymentMonitoringStatsAnomalies)` |  `POST /v1/{modelDeploymentMonitoringJob}:searchModelDeploymentMonitoringStatsAnomalies`   
Searches Model Monitoring Statistics generated within a given time window.  
  
## REST Resource: [v1.projects.locations.models](/vertex-ai/docs/reference/rest/v1/projects.locations.models)

Methods  
---  
`[copy](/vertex-ai/docs/reference/rest/v1/projects.locations.models/copy)` |  `POST /v1/{parent}/models:copy`   
Copies an already existing Vertex AI Model into the specified Location.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.models/delete)` |  `DELETE /v1/{name}`   
Deletes a Model.  
`[deleteVersion](/vertex-ai/docs/reference/rest/v1/projects.locations.models/deleteVersion)` |  `DELETE /v1/{name}:deleteVersion`   
Deletes a Model version.  
`[export](/vertex-ai/docs/reference/rest/v1/projects.locations.models/export)` |  `POST /v1/{name}:export`   
Exports a trained, exportable Model to a location specified by the user.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.models/get)` |  `GET /v1/{name}`   
Gets a Model.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.models/getIamPolicy)` |  `POST /v1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.models/list)` |  `GET /v1/{parent}/models`   
Lists Models in a Location.  
`[listCheckpoints](/vertex-ai/docs/reference/rest/v1/projects.locations.models/listCheckpoints)` |  `GET /v1/{name}:listCheckpoints`   
Lists checkpoints of the specified model version.  
`[listVersions](/vertex-ai/docs/reference/rest/v1/projects.locations.models/listVersions)` |  `GET /v1/{name}:listVersions`   
Lists versions of the specified model.  
`[mergeVersionAliases](/vertex-ai/docs/reference/rest/v1/projects.locations.models/mergeVersionAliases)` |  `POST /v1/{name}:mergeVersionAliases`   
Merges a set of aliases for a Model version.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.models/patch)` |  `PATCH /v1/{model.name}`   
Updates a Model.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.models/setIamPolicy)` |  `POST /v1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1/projects.locations.models/testIamPermissions)` |  `POST /v1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
`[updateExplanationDataset](/vertex-ai/docs/reference/rest/v1/projects.locations.models/updateExplanationDataset)` |  `POST /v1/{model}:updateExplanationDataset`   
Incrementally update the dataset used for an examples model.  
`[upload](/vertex-ai/docs/reference/rest/v1/projects.locations.models/upload)` |  `POST /v1/{parent}/models:upload`   
Uploads a Model artifact into Vertex AI.  
  
## REST Resource: [v1.projects.locations.models.evaluations](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations)

Methods  
---  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations/get)` |  `GET /v1/{name}`   
Gets a ModelEvaluation.  
`[import](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations/import)` |  `POST /v1/{parent}/evaluations:import`   
Imports an externally generated ModelEvaluation.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations/list)` |  `GET /v1/{parent}/evaluations`   
Lists ModelEvaluations in a Model.  
  
## REST Resource: [v1.projects.locations.models.evaluations.slices](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations.slices)

Methods  
---  
`[batchImport](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations.slices/batchImport)` |  `POST /v1/{parent}:batchImport`   
Imports a list of externally generated EvaluatedAnnotations.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations.slices/get)` |  `GET /v1/{name}`   
Gets a ModelEvaluationSlice.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations.slices/list)` |  `GET /v1/{parent}/slices`   
Lists ModelEvaluationSlices in a ModelEvaluation.  
  
## REST Resource: [v1.projects.locations.nasJobs](/vertex-ai/docs/reference/rest/v1/projects.locations.nasJobs)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1/projects.locations.nasJobs/cancel)` |  `POST /v1/{name}:cancel`   
Cancels a NasJob.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.nasJobs/create)` |  `POST /v1/{parent}/nasJobs`   
Creates a NasJob  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.nasJobs/delete)` |  `DELETE /v1/{name}`   
Deletes a NasJob.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.nasJobs/get)` |  `GET /v1/{name}`   
Gets a NasJob  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.nasJobs/list)` |  `GET /v1/{parent}/nasJobs`   
Lists NasJobs in a Location.  
  
## REST Resource: [v1.projects.locations.nasJobs.nasTrialDetails](/vertex-ai/docs/reference/rest/v1/projects.locations.nasJobs.nasTrialDetails)

Methods  
---  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.nasJobs.nasTrialDetails/get)` |  `GET /v1/{name}`   
Gets a NasTrialDetail.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.nasJobs.nasTrialDetails/list)` |  `GET /v1/{parent}/nasTrialDetails`   
List top NasTrialDetails of a NasJob.  
  
## REST Resource: [v1.projects.locations.notebookExecutionJobs](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookExecutionJobs)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookExecutionJobs/create)` |  `POST /v1/{parent}/notebookExecutionJobs`   
Creates a NotebookExecutionJob.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookExecutionJobs/delete)` |  `DELETE /v1/{name}`   
Deletes a NotebookExecutionJob.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookExecutionJobs/get)` |  `GET /v1/{name}`   
Gets a NotebookExecutionJob.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookExecutionJobs/list)` |  `GET /v1/{parent}/notebookExecutionJobs`   
Lists NotebookExecutionJobs in a Location.  
  
## REST Resource: [v1.projects.locations.notebookRuntimeTemplates](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimeTemplates)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimeTemplates/create)` |  `POST /v1/{parent}/notebookRuntimeTemplates`   
Creates a NotebookRuntimeTemplate.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimeTemplates/delete)` |  `DELETE /v1/{name}`   
Deletes a NotebookRuntimeTemplate.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimeTemplates/get)` |  `GET /v1/{name}`   
Gets a NotebookRuntimeTemplate.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimeTemplates/getIamPolicy)` |  `POST /v1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimeTemplates/list)` |  `GET /v1/{parent}/notebookRuntimeTemplates`   
Lists NotebookRuntimeTemplates in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimeTemplates/patch)` |  `PATCH /v1/{notebookRuntimeTemplate.name}`   
Updates a NotebookRuntimeTemplate.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimeTemplates/setIamPolicy)` |  `POST /v1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimeTemplates/testIamPermissions)` |  `POST /v1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
  
## REST Resource: [v1.projects.locations.notebookRuntimes](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimes)

Methods  
---  
`[assign](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimes/assign)` |  `POST /v1/{parent}/notebookRuntimes:assign`   
Assigns a NotebookRuntime to a user for a particular Notebook file.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimes/delete)` |  `DELETE /v1/{name}`   
Deletes a NotebookRuntime.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimes/get)` |  `GET /v1/{name}`   
Gets a NotebookRuntime.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimes/list)` |  `GET /v1/{parent}/notebookRuntimes`   
Lists NotebookRuntimes in a Location.  
`[start](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimes/start)` |  `POST /v1/{name}:start`   
Starts a NotebookRuntime.  
`[stop](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimes/stop)` |  `POST /v1/{name}:stop`   
Stops a NotebookRuntime.  
`[upgrade](/vertex-ai/docs/reference/rest/v1/projects.locations.notebookRuntimes/upgrade)` |  `POST /v1/{name}:upgrade`   
Upgrades a NotebookRuntime.  
  
## REST Resource: [v1.projects.locations.operations](/vertex-ai/docs/reference/rest/v1/projects.locations.operations)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1/projects.locations.operations/cancel)` |  `POST /v1/{name}:cancel`   
Starts asynchronous cancellation on a long-running operation.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.operations/delete)` |  `DELETE /v1/{name}`   
Deletes a long-running operation.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.operations/get)` |  `GET /v1/{name}`   
Gets the latest state of a long-running operation.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.operations/list)` |  `GET /v1/{name}/operations`   
Lists operations that match the specified filter in the request.  
`[wait](/vertex-ai/docs/reference/rest/v1/projects.locations.operations/wait)` |  `POST /v1/{name}:wait`   
Waits until the specified long-running operation is done or reaches at most a specified timeout, returning the latest state.  
  
## REST Resource: [v1.projects.locations.persistentResources](/vertex-ai/docs/reference/rest/v1/projects.locations.persistentResources)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.persistentResources/create)` |  `POST /v1/{parent}/persistentResources`   
Creates a PersistentResource.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.persistentResources/delete)` |  `DELETE /v1/{name}`   
Deletes a PersistentResource.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.persistentResources/get)` |  `GET /v1/{name}`   
Gets a PersistentResource.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.persistentResources/list)` |  `GET /v1/{parent}/persistentResources`   
Lists PersistentResources in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.persistentResources/patch)` |  `PATCH /v1/{persistentResource.name}`   
Updates a PersistentResource.  
`[reboot](/vertex-ai/docs/reference/rest/v1/projects.locations.persistentResources/reboot)` |  `POST /v1/{name}:reboot`   
Reboots a PersistentResource.  
  
## REST Resource: [v1.projects.locations.pipelineJobs](/vertex-ai/docs/reference/rest/v1/projects.locations.pipelineJobs)

Methods  
---  
`[batchCancel](/vertex-ai/docs/reference/rest/v1/projects.locations.pipelineJobs/batchCancel)` |  `POST /v1/{parent}/pipelineJobs:batchCancel`   
Batch cancel PipelineJobs.  
`[batchDelete](/vertex-ai/docs/reference/rest/v1/projects.locations.pipelineJobs/batchDelete)` |  `POST /v1/{parent}/pipelineJobs:batchDelete`   
Batch deletes PipelineJobs The Operation is atomic.  
`[cancel](/vertex-ai/docs/reference/rest/v1/projects.locations.pipelineJobs/cancel)` |  `POST /v1/{name}:cancel`   
Cancels a PipelineJob.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.pipelineJobs/create)` |  `POST /v1/{parent}/pipelineJobs`   
Creates a PipelineJob.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.pipelineJobs/delete)` |  `DELETE /v1/{name}`   
Deletes a PipelineJob.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.pipelineJobs/get)` |  `GET /v1/{name}`   
Gets a PipelineJob.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.pipelineJobs/list)` |  `GET /v1/{parent}/pipelineJobs`   
Lists PipelineJobs in a Location.  
  
## REST Resource: [v1.projects.locations.publishers.models](/vertex-ai/docs/reference/rest/v1/projects.locations.publishers.models)

Methods  
---  
`[computeTokens](/vertex-ai/docs/reference/rest/v1/projects.locations.publishers.models/computeTokens)` |  `POST /v1/{endpoint}:computeTokens`   
Return a list of tokens based on the input text.  
`[countTokens](/vertex-ai/docs/reference/rest/v1/projects.locations.publishers.models/countTokens)` |  `POST /v1/{endpoint}:countTokens`   
Perform a token counting.  
`[generateContent](/vertex-ai/docs/reference/rest/v1/projects.locations.publishers.models/generateContent)` |  `POST /v1/{model}:generateContent`   
Generate content with multimodal inputs.  
`[predict](/vertex-ai/docs/reference/rest/v1/projects.locations.publishers.models/predict)` |  `POST /v1/{endpoint}:predict`   
Perform an online prediction.  
`[predictLongRunning](/vertex-ai/docs/reference/rest/v1/projects.locations.publishers.models/predictLongRunning)` |  `POST /v1/{endpoint}:predictLongRunning`   
  
`[rawPredict](/vertex-ai/docs/reference/rest/v1/projects.locations.publishers.models/rawPredict)` |  `POST /v1/{endpoint}:rawPredict`   
Perform an online prediction with an arbitrary HTTP payload.  
`[serverStreamingPredict](/vertex-ai/docs/reference/rest/v1/projects.locations.publishers.models/serverStreamingPredict)` |  `POST /v1/{endpoint}:serverStreamingPredict`   
Perform a server-side streaming online prediction request for Vertex LLM streaming.  
`[streamRawPredict](/vertex-ai/docs/reference/rest/v1/projects.locations.publishers.models/streamRawPredict)` |  `POST /v1/{endpoint}:streamRawPredict`   
Perform a streaming online prediction with an arbitrary HTTP payload.  
  
## REST Resource: [v1.projects.locations.ragCorpora](/vertex-ai/docs/reference/rest/v1/projects.locations.ragCorpora)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.ragCorpora/create)` |  `POST /v1/{parent}/ragCorpora`   
Creates a RagCorpus.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.ragCorpora/delete)` |  `DELETE /v1/{name}`   
Deletes a RagCorpus.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.ragCorpora/get)` |  `GET /v1/{name}`   
Gets a RagCorpus.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.ragCorpora/list)` |  `GET /v1/{parent}/ragCorpora`   
Lists RagCorpora in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.ragCorpora/patch)` |  `PATCH /v1/{ragCorpus.name}`   
Updates a RagCorpus.  
  
## REST Resource: [v1.projects.locations.ragCorpora.ragFiles](/vertex-ai/docs/reference/rest/v1/projects.locations.ragCorpora.ragFiles)

Methods  
---  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.ragCorpora.ragFiles/delete)` |  `DELETE /v1/{name}`   
Deletes a RagFile.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.ragCorpora.ragFiles/get)` |  `GET /v1/{name}`   
Gets a RagFile.  
`[import](/vertex-ai/docs/reference/rest/v1/projects.locations.ragCorpora.ragFiles/import)` |  `POST /v1/{parent}/ragFiles:import`   
Import files from Google Cloud Storage or Google Drive into a RagCorpus.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.ragCorpora.ragFiles/list)` |  `GET /v1/{parent}/ragFiles`   
Lists RagFiles in a RagCorpus.  
  
## REST Resource: [v1.projects.locations.reasoningEngines](/vertex-ai/docs/reference/rest/v1/projects.locations.reasoningEngines)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.reasoningEngines/create)` |  `POST /v1/{parent}/reasoningEngines`   
Creates a reasoning engine.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.reasoningEngines/delete)` |  `DELETE /v1/{name}`   
Deletes a reasoning engine.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.reasoningEngines/get)` |  `GET /v1/{name}`   
Gets a reasoning engine.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.reasoningEngines/list)` |  `GET /v1/{parent}/reasoningEngines`   
Lists reasoning engines in a location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.reasoningEngines/patch)` |  `PATCH /v1/{reasoningEngine.name}`   
Updates a reasoning engine.  
`[query](/vertex-ai/docs/reference/rest/v1/projects.locations.reasoningEngines/query)` |  `POST /v1/{name}:query`   
Queries using a reasoning engine.  
`[streamQuery](/vertex-ai/docs/reference/rest/v1/projects.locations.reasoningEngines/streamQuery)` |  `POST /v1/{name}:streamQuery`   
Streams queries using a reasoning engine.  
  
## REST Resource: [v1.projects.locations.schedules](/vertex-ai/docs/reference/rest/v1/projects.locations.schedules)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.schedules/create)` |  `POST /v1/{parent}/schedules`   
Creates a Schedule.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.schedules/delete)` |  `DELETE /v1/{name}`   
Deletes a Schedule.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.schedules/get)` |  `GET /v1/{name}`   
Gets a Schedule.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.schedules/list)` |  `GET /v1/{parent}/schedules`   
Lists Schedules in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.schedules/patch)` |  `PATCH /v1/{schedule.name}`   
Updates an active or paused Schedule.  
`[pause](/vertex-ai/docs/reference/rest/v1/projects.locations.schedules/pause)` |  `POST /v1/{name}:pause`   
Pauses a Schedule.  
`[resume](/vertex-ai/docs/reference/rest/v1/projects.locations.schedules/resume)` |  `POST /v1/{name}:resume`   
Resumes a paused Schedule to start scheduling new runs.  
  
## REST Resource: [v1.projects.locations.specialistPools](/vertex-ai/docs/reference/rest/v1/projects.locations.specialistPools)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.specialistPools/create)` |  `POST /v1/{parent}/specialistPools`   
Creates a SpecialistPool.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.specialistPools/delete)` |  `DELETE /v1/{name}`   
Deletes a SpecialistPool as well as all Specialists in the pool.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.specialistPools/get)` |  `GET /v1/{name}`   
Gets a SpecialistPool.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.specialistPools/list)` |  `GET /v1/{parent}/specialistPools`   
Lists SpecialistPools in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.specialistPools/patch)` |  `PATCH /v1/{specialistPool.name}`   
Updates a SpecialistPool.  
  
## REST Resource: [v1.projects.locations.studies](/vertex-ai/docs/reference/rest/v1/projects.locations.studies)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.studies/create)` |  `POST /v1/{parent}/studies`   
Creates a Study.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.studies/delete)` |  `DELETE /v1/{name}`   
Deletes a Study.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.studies/get)` |  `GET /v1/{name}`   
Gets a Study by name.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.studies/list)` |  `GET /v1/{parent}/studies`   
Lists all the studies in a region for an associated project.  
`[lookup](/vertex-ai/docs/reference/rest/v1/projects.locations.studies/lookup)` |  `POST /v1/{parent}/studies:lookup`   
Looks a study up using the user-defined display_name field instead of the fully qualified resource name.  
  
## REST Resource: [v1.projects.locations.studies.trials](/vertex-ai/docs/reference/rest/v1/projects.locations.studies.trials)

Methods  
---  
`[addTrialMeasurement](/vertex-ai/docs/reference/rest/v1/projects.locations.studies.trials/addTrialMeasurement)` |  `POST /v1/{trialName}:addTrialMeasurement`   
Adds a measurement of the objective metrics to a Trial.  
`[checkTrialEarlyStoppingState](/vertex-ai/docs/reference/rest/v1/projects.locations.studies.trials/checkTrialEarlyStoppingState)` |  `POST /v1/{trialName}:checkTrialEarlyStoppingState`   
Checks whether a Trial should stop or not.  
`[complete](/vertex-ai/docs/reference/rest/v1/projects.locations.studies.trials/complete)` |  `POST /v1/{name}:complete`   
Marks a Trial as complete.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.studies.trials/create)` |  `POST /v1/{parent}/trials`   
Adds a user provided Trial to a Study.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.studies.trials/delete)` |  `DELETE /v1/{name}`   
Deletes a Trial.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.studies.trials/get)` |  `GET /v1/{name}`   
Gets a Trial.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.studies.trials/list)` |  `GET /v1/{parent}/trials`   
Lists the Trials associated with a Study.  
`[listOptimalTrials](/vertex-ai/docs/reference/rest/v1/projects.locations.studies.trials/listOptimalTrials)` |  `POST /v1/{parent}/trials:listOptimalTrials`   
Lists the pareto-optimal Trials for multi-objective Study or the optimal Trials for single-objective Study.  
`[stop](/vertex-ai/docs/reference/rest/v1/projects.locations.studies.trials/stop)` |  `POST /v1/{name}:stop`   
Stops a Trial.  
`[suggest](/vertex-ai/docs/reference/rest/v1/projects.locations.studies.trials/suggest)` |  `POST /v1/{parent}/trials:suggest`   
Adds one or more Trials to a Study, with parameter values suggested by Vertex AI Vizier.  
  
## REST Resource: [v1.projects.locations.tensorboards](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards)

Methods  
---  
`[batchRead](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards/batchRead)` |  `GET /v1/{tensorboard}:batchRead`   
Reads multiple TensorboardTimeSeries' data.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards/create)` |  `POST /v1/{parent}/tensorboards`   
Creates a Tensorboard.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards/delete)` |  `DELETE /v1/{name}`   
Deletes a Tensorboard.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards/get)` |  `GET /v1/{name}`   
Gets a Tensorboard.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards/list)` |  `GET /v1/{parent}/tensorboards`   
Lists Tensorboards in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards/patch)` |  `PATCH /v1/{tensorboard.name}`   
Updates a Tensorboard.  
`[readSize](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards/readSize)` |  `GET /v1/{tensorboard}:readSize`   
Returns the storage size for a given TensorBoard instance.  
`[readUsage](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards/readUsage)` |  `GET /v1/{tensorboard}:readUsage`   
Returns a list of monthly active users for a given TensorBoard instance.  
  
## REST Resource: [v1.projects.locations.tensorboards.experiments](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments)

Methods  
---  
`[batchCreate](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments/batchCreate)` |  `POST /v1/{parent}:batchCreate`   
Batch create TensorboardTimeSeries that belong to a TensorboardExperiment.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments/create)` |  `POST /v1/{parent}/experiments`   
Creates a TensorboardExperiment.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments/delete)` |  `DELETE /v1/{name}`   
Deletes a TensorboardExperiment.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments/get)` |  `GET /v1/{name}`   
Gets a TensorboardExperiment.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments/list)` |  `GET /v1/{parent}/experiments`   
Lists TensorboardExperiments in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments/patch)` |  `PATCH /v1/{tensorboardExperiment.name}`   
Updates a TensorboardExperiment.  
`[write](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments/write)` |  `POST /v1/{tensorboardExperiment}:write`   
Write time series data points of multiple TensorboardTimeSeries in multiple TensorboardRun's.  
  
## REST Resource: [v1.projects.locations.tensorboards.experiments.runs](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs)

Methods  
---  
`[batchCreate](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs/batchCreate)` |  `POST /v1/{parent}/runs:batchCreate`   
Batch create TensorboardRuns.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs/create)` |  `POST /v1/{parent}/runs`   
Creates a TensorboardRun.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs/delete)` |  `DELETE /v1/{name}`   
Deletes a TensorboardRun.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs/get)` |  `GET /v1/{name}`   
Gets a TensorboardRun.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs/list)` |  `GET /v1/{parent}/runs`   
Lists TensorboardRuns in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs/patch)` |  `PATCH /v1/{tensorboardRun.name}`   
Updates a TensorboardRun.  
`[write](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs/write)` |  `POST /v1/{tensorboardRun}:write`   
Write time series data points into multiple TensorboardTimeSeries under a TensorboardRun.  
  
## REST Resource: [v1.projects.locations.tensorboards.experiments.runs.timeSeries](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs.timeSeries)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs.timeSeries/create)` |  `POST /v1/{parent}/timeSeries`   
Creates a TensorboardTimeSeries.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs.timeSeries/delete)` |  `DELETE /v1/{name}`   
Deletes a TensorboardTimeSeries.  
`[exportTensorboardTimeSeries](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs.timeSeries/exportTensorboardTimeSeries)` |  `POST /v1/{tensorboardTimeSeries}:exportTensorboardTimeSeries`   
Exports a TensorboardTimeSeries' data.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs.timeSeries/get)` |  `GET /v1/{name}`   
Gets a TensorboardTimeSeries.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs.timeSeries/list)` |  `GET /v1/{parent}/timeSeries`   
Lists TensorboardTimeSeries in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs.timeSeries/patch)` |  `PATCH /v1/{tensorboardTimeSeries.name}`   
Updates a TensorboardTimeSeries.  
`[read](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs.timeSeries/read)` |  `GET /v1/{tensorboardTimeSeries}:read`   
Reads a TensorboardTimeSeries' data.  
`[readBlobData](/vertex-ai/docs/reference/rest/v1/projects.locations.tensorboards.experiments.runs.timeSeries/readBlobData)` |  `GET /v1/{timeSeries}:readBlobData`   
Gets bytes of TensorboardBlobs.  
  
## REST Resource: [v1.projects.locations.trainingPipelines](/vertex-ai/docs/reference/rest/v1/projects.locations.trainingPipelines)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1/projects.locations.trainingPipelines/cancel)` |  `POST /v1/{name}:cancel`   
Cancels a TrainingPipeline.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.trainingPipelines/create)` |  `POST /v1/{parent}/trainingPipelines`   
Creates a TrainingPipeline.  
`[delete](/vertex-ai/docs/reference/rest/v1/projects.locations.trainingPipelines/delete)` |  `DELETE /v1/{name}`   
Deletes a TrainingPipeline.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.trainingPipelines/get)` |  `GET /v1/{name}`   
Gets a TrainingPipeline.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.trainingPipelines/list)` |  `GET /v1/{parent}/trainingPipelines`   
Lists TrainingPipelines in a Location.  
  
## REST Resource: [v1.projects.locations.tuningJobs](/vertex-ai/docs/reference/rest/v1/projects.locations.tuningJobs)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1/projects.locations.tuningJobs/cancel)` |  `POST /v1/{name}:cancel`   
Cancels a TuningJob.  
`[create](/vertex-ai/docs/reference/rest/v1/projects.locations.tuningJobs/create)` |  `POST /v1/{parent}/tuningJobs`   
Creates a TuningJob.  
`[get](/vertex-ai/docs/reference/rest/v1/projects.locations.tuningJobs/get)` |  `GET /v1/{name}`   
Gets a TuningJob.  
`[list](/vertex-ai/docs/reference/rest/v1/projects.locations.tuningJobs/list)` |  `GET /v1/{parent}/tuningJobs`   
Lists TuningJobs in a Location.  
`[rebaseTunedModel](/vertex-ai/docs/reference/rest/v1/projects.locations.tuningJobs/rebaseTunedModel)` |  `POST /v1/{parent}/tuningJobs:rebaseTunedModel`   
Rebase a TunedModel.  
  
## REST Resource: [v1.publishers.models](/vertex-ai/docs/reference/rest/v1/publishers.models)

Methods  
---  
`[get](/vertex-ai/docs/reference/rest/v1/publishers.models/get)` |  `GET /v1/{name}`   
Gets a Model Garden publisher model.  
  
## REST Resource: [v1beta1.media](/vertex-ai/docs/reference/rest/v1beta1/media)

Methods  
---  
`[upload](/vertex-ai/docs/reference/rest/v1beta1/media/upload)` |  `POST /v1beta1/{parent}/ragFiles:upload`   
`POST /upload/v1beta1/{parent}/ragFiles:upload`   
Upload a file into a RagCorpus.  
  
## REST Resource: [v1beta1.projects](/vertex-ai/docs/reference/rest/v1beta1/projects)

Methods  
---  
`[fetchPublisherModelConfig](/vertex-ai/docs/reference/rest/v1beta1/projects/fetchPublisherModelConfig)` |  `GET /v1beta1/{name}:fetchPublisherModelConfig`   
Fetches the configs of publisher models.  
`[setPublisherModelConfig](/vertex-ai/docs/reference/rest/v1beta1/projects/setPublisherModelConfig)` |  `POST /v1beta1/{name}:setPublisherModelConfig`   
Sets (creates or updates) configs of publisher models.  
  
## REST Resource: [v1beta1.projects.locations](/vertex-ai/docs/reference/rest/v1beta1/projects.locations)

Methods  
---  
`[augmentPrompt](/vertex-ai/docs/reference/rest/v1beta1/projects.locations/augmentPrompt)` |  `POST /v1beta1/{parent}:augmentPrompt`   
Given an input prompt, it returns augmented prompt from vertex rag store to guide LLM towards generating grounded responses.  
`[corroborateContent](/vertex-ai/docs/reference/rest/v1beta1/projects.locations/corroborateContent)` |  `POST /v1beta1/{parent}:corroborateContent`   
Given an input text, it returns a score that evaluates the factuality of the text.  
`[deploy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations/deploy)` |  `POST /v1beta1/{destination}:deploy`   
Deploys a model to a new endpoint.  
`[deployPublisherModel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations/deployPublisherModel)   
**(deprecated)**` |  `POST /v1beta1/{destination}:deployPublisherModel`   
Deploys publisher models.  
`[evaluateDataset](/vertex-ai/docs/reference/rest/v1beta1/projects.locations/evaluateDataset)` |  `POST /v1beta1/{location}:evaluateDataset`   
Evaluates a dataset based on a set of given metrics.  
`[evaluateInstances](/vertex-ai/docs/reference/rest/v1beta1/projects.locations/evaluateInstances)` |  `POST /v1beta1/{location}:evaluateInstances`   
Evaluates instances based on a given metric.  
`[getRagEngineConfig](/vertex-ai/docs/reference/rest/v1beta1/projects.locations/getRagEngineConfig)` |  `GET /v1beta1/{name}`   
Gets a RagEngineConfig.  
`[recommendSpec](/vertex-ai/docs/reference/rest/v1beta1/projects.locations/recommendSpec)` |  `POST /v1beta1/{parent}:recommendSpec`   
Gets a Model's spec recommendations.  
`[retrieveContexts](/vertex-ai/docs/reference/rest/v1beta1/projects.locations/retrieveContexts)` |  `POST /v1beta1/{parent}:retrieveContexts`   
Retrieves relevant contexts for a query.  
`[updateRagEngineConfig](/vertex-ai/docs/reference/rest/v1beta1/projects.locations/updateRagEngineConfig)` |  `PATCH /v1beta1/{ragEngineConfig.name}`   
Updates a RagEngineConfig.  
  
## REST Resource: [v1beta1.projects.locations.batchPredictionJobs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.batchPredictionJobs)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.batchPredictionJobs/cancel)` |  `POST /v1beta1/{name}:cancel`   
Cancels a BatchPredictionJob.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.batchPredictionJobs/create)` |  `POST /v1beta1/{parent}/batchPredictionJobs`   
Creates a BatchPredictionJob.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.batchPredictionJobs/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a BatchPredictionJob.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.batchPredictionJobs/get)` |  `GET /v1beta1/{name}`   
Gets a BatchPredictionJob  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.batchPredictionJobs/list)` |  `GET /v1beta1/{parent}/batchPredictionJobs`   
Lists BatchPredictionJobs in a Location.  
  
## REST Resource: [v1beta1.projects.locations.cachedContents](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.cachedContents)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.cachedContents/create)` |  `POST /v1beta1/{parent}/cachedContents`   
Creates cached content, this call will initialize the cached content in the data storage, and users need to pay for the cache data storage.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.cachedContents/delete)` |  `DELETE /v1beta1/{name}`   
Deletes cached content  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.cachedContents/get)` |  `GET /v1beta1/{name}`   
Gets cached content configurations  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.cachedContents/list)` |  `GET /v1beta1/{parent}/cachedContents`   
Lists cached contents in a project  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.cachedContents/patch)` |  `PATCH /v1beta1/{cachedContent.name}`   
Updates cached content configurations  
  
## REST Resource: [v1beta1.projects.locations.customJobs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.customJobs)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.customJobs/cancel)` |  `POST /v1beta1/{name}:cancel`   
Cancels a CustomJob.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.customJobs/create)` |  `POST /v1beta1/{parent}/customJobs`   
Creates a CustomJob.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.customJobs/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a CustomJob.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.customJobs/get)` |  `GET /v1beta1/{name}`   
Gets a CustomJob.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.customJobs/list)` |  `GET /v1beta1/{parent}/customJobs`   
Lists CustomJobs in a Location.  
  
## REST Resource: [v1beta1.projects.locations.datasets](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets)

Methods  
---  
`[assemble](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets/assemble)` |  `POST /v1beta1/{name}:assemble`   
Assembles each row of a multimodal dataset and writes the result into a BigQuery table.  
`[assess](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets/assess)` |  `POST /v1beta1/{name}:assess`   
Assesses the state or validity of the dataset with respect to a given use case.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets/create)` |  `POST /v1beta1/{parent}/datasets`   
Creates a Dataset.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a Dataset.  
`[export](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets/export)` |  `POST /v1beta1/{name}:export`   
Exports data from a Dataset.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets/get)` |  `GET /v1beta1/{name}`   
Gets a Dataset.  
`[import](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets/import)` |  `POST /v1beta1/{name}:import`   
Imports data into a Dataset.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets/list)` |  `GET /v1beta1/{parent}/datasets`   
Lists Datasets in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets/patch)` |  `PATCH /v1beta1/{dataset.name}`   
Updates a Dataset.  
`[searchDataItems](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets/searchDataItems)` |  `GET /v1beta1/{dataset}:searchDataItems`   
Searches DataItems in a Dataset.  
  
## REST Resource: [v1beta1.projects.locations.datasets.annotationSpecs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.annotationSpecs)

Methods  
---  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.annotationSpecs/get)` |  `GET /v1beta1/{name}`   
Gets an AnnotationSpec.  
  
## REST Resource: [v1beta1.projects.locations.datasets.dataItems](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.dataItems)

Methods  
---  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.dataItems/list)` |  `GET /v1beta1/{parent}/dataItems`   
Lists DataItems in a Dataset.  
  
## REST Resource: [v1beta1.projects.locations.datasets.dataItems.annotations](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.dataItems.annotations)

Methods  
---  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.dataItems.annotations/list)` |  `GET /v1beta1/{parent}/annotations`   
Lists Annotations belongs to a dataitem.  
  
## REST Resource: [v1beta1.projects.locations.datasets.datasetVersions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.datasetVersions)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.datasetVersions/create)` |  `POST /v1beta1/{parent}/datasetVersions`   
Create a version from a Dataset.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.datasetVersions/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a Dataset version.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.datasetVersions/get)` |  `GET /v1beta1/{name}`   
Gets a Dataset version.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.datasetVersions/list)` |  `GET /v1beta1/{parent}/datasetVersions`   
Lists DatasetVersions in a Dataset.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.datasetVersions/patch)` |  `PATCH /v1beta1/{datasetVersion.name}`   
Updates a DatasetVersion.  
`[restore](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.datasetVersions/restore)` |  `GET /v1beta1/{name}:restore`   
Restores a dataset version.  
  
## REST Resource: [v1beta1.projects.locations.datasets.savedQueries](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.savedQueries)

Methods  
---  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.savedQueries/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a SavedQuery.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.datasets.savedQueries/list)` |  `GET /v1beta1/{parent}/savedQueries`   
Lists SavedQueries in a Dataset.  
  
## REST Resource: [v1beta1.projects.locations.deploymentResourcePools](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.deploymentResourcePools)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.deploymentResourcePools/create)` |  `POST /v1beta1/{parent}/deploymentResourcePools`   
Create a DeploymentResourcePool.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.deploymentResourcePools/delete)` |  `DELETE /v1beta1/{name}`   
Delete a DeploymentResourcePool.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.deploymentResourcePools/get)` |  `GET /v1beta1/{name}`   
Get a DeploymentResourcePool.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.deploymentResourcePools/list)` |  `GET /v1beta1/{parent}/deploymentResourcePools`   
List DeploymentResourcePools in a location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.deploymentResourcePools/patch)` |  `PATCH /v1beta1/{deploymentResourcePool.name}`   
Update a DeploymentResourcePool.  
`[queryDeployedModels](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.deploymentResourcePools/queryDeployedModels)` |  `GET /v1beta1/{deploymentResourcePool}:queryDeployedModels`   
List DeployedModels that have been deployed on this DeploymentResourcePool.  
  
## REST Resource: [v1beta1.projects.locations.endpoints](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints)

Methods  
---  
`[computeTokens](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/computeTokens)` |  `POST /v1beta1/{endpoint}:computeTokens`   
Return a list of tokens based on the input text.  
`[countTokens](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/countTokens)` |  `POST /v1beta1/{endpoint}:countTokens`   
Perform a token counting.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/create)` |  `POST /v1beta1/{parent}/endpoints`   
Creates an Endpoint.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/delete)` |  `DELETE /v1beta1/{name}`   
Deletes an Endpoint.  
`[deployModel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/deployModel)` |  `POST /v1beta1/{endpoint}:deployModel`   
Deploys a Model into this Endpoint, creating a DeployedModel within it.  
`[directPredict](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/directPredict)` |  `POST /v1beta1/{endpoint}:directPredict`   
Perform an unary online prediction request to a gRPC model server for Vertex first-party products and frameworks.  
`[directRawPredict](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/directRawPredict)` |  `POST /v1beta1/{endpoint}:directRawPredict`   
Perform an unary online prediction request to a gRPC model server for custom containers.  
`[explain](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/explain)` |  `POST /v1beta1/{endpoint}:explain`   
Perform an online explanation.  
`[generateContent](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/generateContent)` |  `POST /v1beta1/{model}:generateContent`   
Generate content with multimodal inputs.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/get)` |  `GET /v1beta1/{name}`   
Gets an Endpoint.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/getIamPolicy)` |  `POST /v1beta1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/list)` |  `GET /v1beta1/{parent}/endpoints`   
Lists Endpoints in a Location.  
`[mutateDeployedModel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/mutateDeployedModel)` |  `POST /v1beta1/{endpoint}:mutateDeployedModel`   
Updates an existing deployed model.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/patch)` |  `PATCH /v1beta1/{endpoint.name}`   
Updates an Endpoint.  
`[predict](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/predict)` |  `POST /v1beta1/{endpoint}:predict`   
Perform an online prediction.  
`[rawPredict](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/rawPredict)` |  `POST /v1beta1/{endpoint}:rawPredict`   
Perform an online prediction with an arbitrary HTTP payload.  
`[serverStreamingPredict](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/serverStreamingPredict)` |  `POST /v1beta1/{endpoint}:serverStreamingPredict`   
Perform a server-side streaming online prediction request for Vertex LLM streaming.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/setIamPolicy)` |  `POST /v1beta1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[streamRawPredict](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/streamRawPredict)` |  `POST /v1beta1/{endpoint}:streamRawPredict`   
Perform a streaming online prediction with an arbitrary HTTP payload.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/testIamPermissions)` |  `POST /v1beta1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
`[undeployModel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/undeployModel)` |  `POST /v1beta1/{endpoint}:undeployModel`   
Undeploys a Model from an Endpoint, removing a DeployedModel from it, and freeing all resources it's using.  
`[update](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints/update)` |  `POST /v1beta1/{endpoint.name}:update`   
Updates an Endpoint with a long running operation.  
  
## REST Resource: [v1beta1.projects.locations.endpoints.chat](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints.chat)

Methods  
---  
`[completions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints.chat/completions)` |  `POST /v1beta1/{endpoint}/chat/completions`   
Exposes an OpenAI-compatible endpoint for chat completions.  
  
## REST Resource: [v1beta1.projects.locations.exampleStores](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.exampleStores)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.exampleStores/create)` |  `POST /v1beta1/{parent}/exampleStores`   
Create an ExampleStore.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.exampleStores/delete)` |  `DELETE /v1beta1/{name}`   
Delete an ExampleStore.  
`[fetchExamples](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.exampleStores/fetchExamples)` |  `POST /v1beta1/{exampleStore}:fetchExamples`   
Get Examples from the Example Store.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.exampleStores/get)` |  `GET /v1beta1/{name}`   
Get an ExampleStore.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.exampleStores/list)` |  `GET /v1beta1/{parent}/exampleStores`   
List ExampleStores in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.exampleStores/patch)` |  `PATCH /v1beta1/{exampleStore.name}`   
Update an ExampleStore.  
`[removeExamples](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.exampleStores/removeExamples)` |  `POST /v1beta1/{exampleStore}:removeExamples`   
Remove Examples from the Example Store.  
`[searchExamples](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.exampleStores/searchExamples)` |  `POST /v1beta1/{exampleStore}:searchExamples`   
Search for similar Examples for given selection criteria.  
`[upsertExamples](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.exampleStores/upsertExamples)` |  `POST /v1beta1/{exampleStore}:upsertExamples`   
Create or update Examples in the Example Store.  
  
## REST Resource: [v1beta1.projects.locations.extensions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.extensions)

Methods  
---  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.extensions/delete)` |  `DELETE /v1beta1/{name}`   
Deletes an Extension.  
`[execute](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.extensions/execute)` |  `POST /v1beta1/{name}:execute`   
Executes the request against a given extension.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.extensions/get)` |  `GET /v1beta1/{name}`   
Gets an Extension.  
`[import](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.extensions/import)` |  `POST /v1beta1/{parent}/extensions:import`   
Imports an Extension.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.extensions/list)` |  `GET /v1beta1/{parent}/extensions`   
Lists Extensions in a location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.extensions/patch)` |  `PATCH /v1beta1/{extension.name}`   
Updates an Extension.  
`[query](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.extensions/query)` |  `POST /v1beta1/{name}:query`   
Queries an extension with a default controller.  
  
## REST Resource: [v1beta1.projects.locations.featureGroups](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups/create)` |  `POST /v1beta1/{parent}/featureGroups`   
Creates a new FeatureGroup in a given project and location.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a single FeatureGroup.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups/get)` |  `GET /v1beta1/{name}`   
Gets details of a single FeatureGroup.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups/getIamPolicy)` |  `POST /v1beta1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups/list)` |  `GET /v1beta1/{parent}/featureGroups`   
Lists FeatureGroups in a given project and location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups/patch)` |  `PATCH /v1beta1/{featureGroup.name}`   
Updates the parameters of a single FeatureGroup.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups/setIamPolicy)` |  `POST /v1beta1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups/testIamPermissions)` |  `POST /v1beta1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
  
## REST Resource: [v1beta1.projects.locations.featureGroups.featureMonitors](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.featureMonitors)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.featureMonitors/create)` |  `POST /v1beta1/{parent}/featureMonitors`   
Creates a new FeatureMonitor in a given project, location and FeatureGroup.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.featureMonitors/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a single FeatureMonitor.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.featureMonitors/get)` |  `GET /v1beta1/{name}`   
Gets details of a single FeatureMonitor.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.featureMonitors/list)` |  `GET /v1beta1/{parent}/featureMonitors`   
Lists FeatureGroups in a given project and location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.featureMonitors/patch)` |  `PATCH /v1beta1/{featureMonitor.name}`   
Updates the parameters of a single FeatureMonitor.  
  
## REST Resource: [v1beta1.projects.locations.featureGroups.featureMonitors.featureMonitorJobs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.featureMonitors.featureMonitorJobs)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.featureMonitors.featureMonitorJobs/create)` |  `POST /v1beta1/{parent}/featureMonitorJobs`   
Creates a new feature monitor job.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.featureMonitors.featureMonitorJobs/get)` |  `GET /v1beta1/{name}`   
Get a feature monitor job.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.featureMonitors.featureMonitorJobs/list)` |  `GET /v1beta1/{parent}/featureMonitorJobs`   
List feature monitor jobs.  
  
## REST Resource: [v1beta1.projects.locations.featureGroups.features](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.features)

Methods  
---  
`[batchCreate](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.features/batchCreate)` |  `POST /v1beta1/{parent}/features:batchCreate`   
Creates a batch of Features in a given FeatureGroup.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.features/create)` |  `POST /v1beta1/{parent}/features`   
Creates a new Feature in a given FeatureGroup.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.features/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a single Feature.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.features/get)` |  `GET /v1beta1/{name}`   
Gets details of a single Feature.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.features/list)` |  `GET /v1beta1/{parent}/features`   
Lists Features in a given FeatureGroup.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureGroups.features/patch)` |  `PATCH /v1beta1/{feature.name}`   
Updates the parameters of a single Feature.  
  
## REST Resource: [v1beta1.projects.locations.featureOnlineStores](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores/create)` |  `POST /v1beta1/{parent}/featureOnlineStores`   
Creates a new FeatureOnlineStore in a given project and location.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a single FeatureOnlineStore.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores/get)` |  `GET /v1beta1/{name}`   
Gets details of a single FeatureOnlineStore.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores/getIamPolicy)` |  `POST /v1beta1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores/list)` |  `GET /v1beta1/{parent}/featureOnlineStores`   
Lists FeatureOnlineStores in a given project and location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores/patch)` |  `PATCH /v1beta1/{featureOnlineStore.name}`   
Updates the parameters of a single FeatureOnlineStore.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores/setIamPolicy)` |  `POST /v1beta1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores/testIamPermissions)` |  `POST /v1beta1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
  
## REST Resource: [v1beta1.projects.locations.featureOnlineStores.featureViews](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/create)` |  `POST /v1beta1/{parent}/featureViews`   
Creates a new FeatureView in a given FeatureOnlineStore.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a single FeatureView.  
`[directWrite](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/directWrite)` |  `POST /v1beta1/{featureView}:directWrite`   
Bidirectional streaming RPC to directly write to feature values in a feature view.  
`[fetchFeatureValues](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/fetchFeatureValues)` |  `POST /v1beta1/{featureView}:fetchFeatureValues`   
Fetch feature values under a FeatureView.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/get)` |  `GET /v1beta1/{name}`   
Gets details of a single FeatureView.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/getIamPolicy)` |  `POST /v1beta1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/list)` |  `GET /v1beta1/{parent}/featureViews`   
Lists FeatureViews in a given FeatureOnlineStore.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/patch)` |  `PATCH /v1beta1/{featureView.name}`   
Updates the parameters of a single FeatureView.  
`[searchNearestEntities](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/searchNearestEntities)` |  `POST /v1beta1/{featureView}:searchNearestEntities`   
Search the nearest entities under a FeatureView.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/setIamPolicy)` |  `POST /v1beta1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[streamingFetchFeatureValues](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/streamingFetchFeatureValues)` |  `POST /v1beta1/{featureView}:streamingFetchFeatureValues`   
Bidirectional streaming RPC to fetch feature values under a FeatureView.  
`[sync](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/sync)` |  `POST /v1beta1/{featureView}:sync`   
Triggers on-demand sync for the FeatureView.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews/testIamPermissions)` |  `POST /v1beta1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
  
## REST Resource: [v1beta1.projects.locations.featureOnlineStores.featureViews.featureViewSyncs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews.featureViewSyncs)

Methods  
---  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews.featureViewSyncs/get)` |  `GET /v1beta1/{name}`   
Gets details of a single FeatureViewSync.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featureOnlineStores.featureViews.featureViewSyncs/list)` |  `GET /v1beta1/{parent}/featureViewSyncs`   
Lists FeatureViewSyncs in a given FeatureView.  
  
## REST Resource: [v1beta1.projects.locations.featurestores](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores)

Methods  
---  
`[batchReadFeatureValues](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores/batchReadFeatureValues)` |  `POST /v1beta1/{featurestore}:batchReadFeatureValues`   
Batch reads Feature values from a Featurestore.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores/create)` |  `POST /v1beta1/{parent}/featurestores`   
Creates a new Featurestore in a given project and location.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a single Featurestore.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores/get)` |  `GET /v1beta1/{name}`   
Gets details of a single Featurestore.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores/getIamPolicy)` |  `POST /v1beta1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores/list)` |  `GET /v1beta1/{parent}/featurestores`   
Lists Featurestores in a given project and location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores/patch)` |  `PATCH /v1beta1/{featurestore.name}`   
Updates the parameters of a single Featurestore.  
`[searchFeatures](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores/searchFeatures)` |  `GET /v1beta1/{location}/featurestores:searchFeatures`   
Searches Features matching a query in a given project.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores/setIamPolicy)` |  `POST /v1beta1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores/testIamPermissions)` |  `POST /v1beta1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
  
## REST Resource: [v1beta1.projects.locations.featurestores.entityTypes](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/create)` |  `POST /v1beta1/{parent}/entityTypes`   
Creates a new EntityType in a given Featurestore.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a single EntityType.  
`[deleteFeatureValues](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/deleteFeatureValues)` |  `POST /v1beta1/{entityType}:deleteFeatureValues`   
Delete Feature values from Featurestore.  
`[exportFeatureValues](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/exportFeatureValues)` |  `POST /v1beta1/{entityType}:exportFeatureValues`   
Exports Feature values from all the entities of a target EntityType.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/get)` |  `GET /v1beta1/{name}`   
Gets details of a single EntityType.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/getIamPolicy)` |  `POST /v1beta1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[importFeatureValues](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/importFeatureValues)` |  `POST /v1beta1/{entityType}:importFeatureValues`   
Imports Feature values into the Featurestore from a source storage.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/list)` |  `GET /v1beta1/{parent}/entityTypes`   
Lists EntityTypes in a given Featurestore.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/patch)` |  `PATCH /v1beta1/{entityType.name}`   
Updates the parameters of a single EntityType.  
`[readFeatureValues](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/readFeatureValues)` |  `POST /v1beta1/{entityType}:readFeatureValues`   
Reads Feature values of a specific entity of an EntityType.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/setIamPolicy)` |  `POST /v1beta1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[streamingReadFeatureValues](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/streamingReadFeatureValues)` |  `POST /v1beta1/{entityType}:streamingReadFeatureValues`   
Reads Feature values for multiple entities.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/testIamPermissions)` |  `POST /v1beta1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
`[writeFeatureValues](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes/writeFeatureValues)` |  `POST /v1beta1/{entityType}:writeFeatureValues`   
Writes Feature values of one or more entities of an EntityType.  
  
## REST Resource: [v1beta1.projects.locations.featurestores.entityTypes.features](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes.features)

Methods  
---  
`[batchCreate](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes.features/batchCreate)` |  `POST /v1beta1/{parent}/features:batchCreate`   
Creates a batch of Features in a given EntityType.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes.features/create)` |  `POST /v1beta1/{parent}/features`   
Creates a new Feature in a given EntityType.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes.features/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a single Feature.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes.features/get)` |  `GET /v1beta1/{name}`   
Gets details of a single Feature.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes.features/list)` |  `GET /v1beta1/{parent}/features`   
Lists Features in a given EntityType.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes.features/patch)` |  `PATCH /v1beta1/{feature.name}`   
Updates the parameters of a single Feature.  
  
## REST Resource: [v1beta1.projects.locations.hyperparameterTuningJobs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.hyperparameterTuningJobs)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.hyperparameterTuningJobs/cancel)` |  `POST /v1beta1/{name}:cancel`   
Cancels a HyperparameterTuningJob.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.hyperparameterTuningJobs/create)` |  `POST /v1beta1/{parent}/hyperparameterTuningJobs`   
Creates a HyperparameterTuningJob  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.hyperparameterTuningJobs/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a HyperparameterTuningJob.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.hyperparameterTuningJobs/get)` |  `GET /v1beta1/{name}`   
Gets a HyperparameterTuningJob  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.hyperparameterTuningJobs/list)` |  `GET /v1beta1/{parent}/hyperparameterTuningJobs`   
Lists HyperparameterTuningJobs in a Location.  
  
## REST Resource: [v1beta1.projects.locations.indexEndpoints](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexEndpoints)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexEndpoints/create)` |  `POST /v1beta1/{parent}/indexEndpoints`   
Creates an IndexEndpoint.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexEndpoints/delete)` |  `DELETE /v1beta1/{name}`   
Deletes an IndexEndpoint.  
`[deployIndex](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexEndpoints/deployIndex)` |  `POST /v1beta1/{indexEndpoint}:deployIndex`   
Deploys an Index into this IndexEndpoint, creating a DeployedIndex within it.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexEndpoints/get)` |  `GET /v1beta1/{name}`   
Gets an IndexEndpoint.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexEndpoints/list)` |  `GET /v1beta1/{parent}/indexEndpoints`   
Lists IndexEndpoints in a Location.  
`[mutateDeployedIndex](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexEndpoints/mutateDeployedIndex)` |  `POST /v1beta1/{indexEndpoint}:mutateDeployedIndex`   
Update an existing DeployedIndex under an IndexEndpoint.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexEndpoints/patch)` |  `PATCH /v1beta1/{indexEndpoint.name}`   
Updates an IndexEndpoint.  
`[undeployIndex](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexEndpoints/undeployIndex)` |  `POST /v1beta1/{indexEndpoint}:undeployIndex`   
Undeploys an Index from an IndexEndpoint, removing a DeployedIndex from it, and freeing all resources it's using.  
  
## REST Resource: [v1beta1.projects.locations.indexes](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexes)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexes/create)` |  `POST /v1beta1/{parent}/indexes`   
Creates an Index.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexes/delete)` |  `DELETE /v1beta1/{name}`   
Deletes an Index.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexes/get)` |  `GET /v1beta1/{name}`   
Gets an Index.  
`[import](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexes/import)` |  `POST /v1beta1/{name}:import`   
Imports an Index from an external source (e.g., BigQuery).  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexes/list)` |  `GET /v1beta1/{parent}/indexes`   
Lists Indexes in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexes/patch)` |  `PATCH /v1beta1/{index.name}`   
Updates an Index.  
`[removeDatapoints](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexes/removeDatapoints)` |  `POST /v1beta1/{index}:removeDatapoints`   
Remove Datapoints from an Index.  
`[upsertDatapoints](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.indexes/upsertDatapoints)` |  `POST /v1beta1/{index}:upsertDatapoints`   
Add/update Datapoints into an Index.  
  
## REST Resource: [v1beta1.projects.locations.metadataStores](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores/create)` |  `POST /v1beta1/{parent}/metadataStores`   
Initializes a MetadataStore, including allocation of resources.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a single MetadataStore and all its child resources (Artifacts, Executions, and Contexts).  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores/get)` |  `GET /v1beta1/{name}`   
Retrieves a specific MetadataStore.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores/list)` |  `GET /v1beta1/{parent}/metadataStores`   
Lists MetadataStores for a Location.  
  
## REST Resource: [v1beta1.projects.locations.metadataStores.artifacts](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.artifacts)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.artifacts/create)` |  `POST /v1beta1/{parent}/artifacts`   
Creates an Artifact associated with a MetadataStore.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.artifacts/delete)` |  `DELETE /v1beta1/{name}`   
Deletes an Artifact.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.artifacts/get)` |  `GET /v1beta1/{name}`   
Retrieves a specific Artifact.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.artifacts/list)` |  `GET /v1beta1/{parent}/artifacts`   
Lists Artifacts in the MetadataStore.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.artifacts/patch)` |  `PATCH /v1beta1/{artifact.name}`   
Updates a stored Artifact.  
`[purge](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.artifacts/purge)` |  `POST /v1beta1/{parent}/artifacts:purge`   
Purges Artifacts.  
`[queryArtifactLineageSubgraph](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.artifacts/queryArtifactLineageSubgraph)` |  `GET /v1beta1/{artifact}:queryArtifactLineageSubgraph`   
Retrieves lineage of an Artifact represented through Artifacts and Executions connected by Event edges and returned as a LineageSubgraph.  
  
## REST Resource: [v1beta1.projects.locations.metadataStores.contexts](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.contexts)

Methods  
---  
`[addContextArtifactsAndExecutions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.contexts/addContextArtifactsAndExecutions)` |  `POST /v1beta1/{context}:addContextArtifactsAndExecutions`   
Adds a set of Artifacts and Executions to a Context.  
`[addContextChildren](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.contexts/addContextChildren)` |  `POST /v1beta1/{context}:addContextChildren`   
Adds a set of Contexts as children to a parent Context.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.contexts/create)` |  `POST /v1beta1/{parent}/contexts`   
Creates a Context associated with a MetadataStore.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.contexts/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a stored Context.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.contexts/get)` |  `GET /v1beta1/{name}`   
Retrieves a specific Context.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.contexts/list)` |  `GET /v1beta1/{parent}/contexts`   
Lists Contexts on the MetadataStore.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.contexts/patch)` |  `PATCH /v1beta1/{context.name}`   
Updates a stored Context.  
`[purge](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.contexts/purge)` |  `POST /v1beta1/{parent}/contexts:purge`   
Purges Contexts.  
`[queryContextLineageSubgraph](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.contexts/queryContextLineageSubgraph)` |  `GET /v1beta1/{context}:queryContextLineageSubgraph`   
Retrieves Artifacts and Executions within the specified Context, connected by Event edges and returned as a LineageSubgraph.  
`[removeContextChildren](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.contexts/removeContextChildren)` |  `POST /v1beta1/{context}:removeContextChildren`   
Remove a set of children contexts from a parent Context.  
  
## REST Resource: [v1beta1.projects.locations.metadataStores.executions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.executions)

Methods  
---  
`[addExecutionEvents](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.executions/addExecutionEvents)` |  `POST /v1beta1/{execution}:addExecutionEvents`   
Adds Events to the specified Execution.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.executions/create)` |  `POST /v1beta1/{parent}/executions`   
Creates an Execution associated with a MetadataStore.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.executions/delete)` |  `DELETE /v1beta1/{name}`   
Deletes an Execution.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.executions/get)` |  `GET /v1beta1/{name}`   
Retrieves a specific Execution.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.executions/list)` |  `GET /v1beta1/{parent}/executions`   
Lists Executions in the MetadataStore.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.executions/patch)` |  `PATCH /v1beta1/{execution.name}`   
Updates a stored Execution.  
`[purge](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.executions/purge)` |  `POST /v1beta1/{parent}/executions:purge`   
Purges Executions.  
`[queryExecutionInputsAndOutputs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.executions/queryExecutionInputsAndOutputs)` |  `GET /v1beta1/{execution}:queryExecutionInputsAndOutputs`   
Obtains the set of input and output Artifacts for this Execution, in the form of LineageSubgraph that also contains the Execution and connecting Events.  
  
## REST Resource: [v1beta1.projects.locations.metadataStores.metadataSchemas](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.metadataSchemas)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.metadataSchemas/create)` |  `POST /v1beta1/{parent}/metadataSchemas`   
Creates a MetadataSchema.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.metadataSchemas/get)` |  `GET /v1beta1/{name}`   
Retrieves a specific MetadataSchema.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.metadataStores.metadataSchemas/list)` |  `GET /v1beta1/{parent}/metadataSchemas`   
Lists MetadataSchemas.  
  
## REST Resource: [v1beta1.projects.locations.migratableResources](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.migratableResources)

Methods  
---  
`[batchMigrate](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.migratableResources/batchMigrate)` |  `POST /v1beta1/{parent}/migratableResources:batchMigrate`   
Batch migrates resources from ml.googleapis.com, automl.googleapis.com, and datalabeling.googleapis.com to Vertex AI.  
`[search](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.migratableResources/search)` |  `POST /v1beta1/{parent}/migratableResources:search`   
Searches all of the resources in automl.googleapis.com, datalabeling.googleapis.com and ml.googleapis.com that can be migrated to Vertex AI's given location.  
  
## REST Resource: [v1beta1.projects.locations.modelDeploymentMonitoringJobs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelDeploymentMonitoringJobs)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelDeploymentMonitoringJobs/create)` |  `POST /v1beta1/{parent}/modelDeploymentMonitoringJobs`   
Creates a ModelDeploymentMonitoringJob.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelDeploymentMonitoringJobs/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a ModelDeploymentMonitoringJob.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelDeploymentMonitoringJobs/get)` |  `GET /v1beta1/{name}`   
Gets a ModelDeploymentMonitoringJob.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelDeploymentMonitoringJobs/list)` |  `GET /v1beta1/{parent}/modelDeploymentMonitoringJobs`   
Lists ModelDeploymentMonitoringJobs in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelDeploymentMonitoringJobs/patch)` |  `PATCH /v1beta1/{modelDeploymentMonitoringJob.name}`   
Updates a ModelDeploymentMonitoringJob.  
`[pause](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelDeploymentMonitoringJobs/pause)` |  `POST /v1beta1/{name}:pause`   
Pauses a ModelDeploymentMonitoringJob.  
`[resume](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelDeploymentMonitoringJobs/resume)` |  `POST /v1beta1/{name}:resume`   
Resumes a paused ModelDeploymentMonitoringJob.  
`[searchModelDeploymentMonitoringStatsAnomalies](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelDeploymentMonitoringJobs/searchModelDeploymentMonitoringStatsAnomalies)` |  `POST /v1beta1/{modelDeploymentMonitoringJob}:searchModelDeploymentMonitoringStatsAnomalies`   
Searches Model Monitoring Statistics generated within a given time window.  
  
## REST Resource: [v1beta1.projects.locations.modelMonitors](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors/create)` |  `POST /v1beta1/{parent}/modelMonitors`   
Creates a ModelMonitor.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a ModelMonitor.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors/get)` |  `GET /v1beta1/{name}`   
Gets a ModelMonitor.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors/list)` |  `GET /v1beta1/{parent}/modelMonitors`   
Lists ModelMonitors in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors/patch)` |  `PATCH /v1beta1/{modelMonitor.name}`   
Updates a ModelMonitor.  
`[searchModelMonitoringAlerts](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors/searchModelMonitoringAlerts)` |  `POST /v1beta1/{modelMonitor}:searchModelMonitoringAlerts`   
Returns the Model Monitoring alerts.  
`[searchModelMonitoringStats](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors/searchModelMonitoringStats)` |  `POST /v1beta1/{modelMonitor}:searchModelMonitoringStats`   
Searches Model Monitoring Stats generated within a given time window.  
  
## REST Resource: [v1beta1.projects.locations.modelMonitors.modelMonitoringJobs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors.modelMonitoringJobs)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors.modelMonitoringJobs/create)` |  `POST /v1beta1/{parent}/modelMonitoringJobs`   
Creates a ModelMonitoringJob.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors.modelMonitoringJobs/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a ModelMonitoringJob.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors.modelMonitoringJobs/get)` |  `GET /v1beta1/{name}`   
Gets a ModelMonitoringJob.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.modelMonitors.modelMonitoringJobs/list)` |  `GET /v1beta1/{parent}/modelMonitoringJobs`   
Lists ModelMonitoringJobs.  
  
## REST Resource: [v1beta1.projects.locations.models](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models)

Methods  
---  
`[copy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/copy)` |  `POST /v1beta1/{parent}/models:copy`   
Copies an already existing Vertex AI Model into the specified Location.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a Model.  
`[deleteVersion](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/deleteVersion)` |  `DELETE /v1beta1/{name}:deleteVersion`   
Deletes a Model version.  
`[export](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/export)` |  `POST /v1beta1/{name}:export`   
Exports a trained, exportable Model to a location specified by the user.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/get)` |  `GET /v1beta1/{name}`   
Gets a Model.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/getIamPolicy)` |  `POST /v1beta1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/list)` |  `GET /v1beta1/{parent}/models`   
Lists Models in a Location.  
`[listCheckpoints](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/listCheckpoints)` |  `GET /v1beta1/{name}:listCheckpoints`   
Lists checkpoints of the specified model version.  
`[listVersions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/listVersions)` |  `GET /v1beta1/{name}:listVersions`   
Lists versions of the specified model.  
`[mergeVersionAliases](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/mergeVersionAliases)` |  `POST /v1beta1/{name}:mergeVersionAliases`   
Merges a set of aliases for a Model version.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/patch)` |  `PATCH /v1beta1/{model.name}`   
Updates a Model.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/setIamPolicy)` |  `POST /v1beta1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/testIamPermissions)` |  `POST /v1beta1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
`[updateExplanationDataset](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/updateExplanationDataset)` |  `POST /v1beta1/{model}:updateExplanationDataset`   
Incrementally update the dataset used for an examples model.  
`[upload](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models/upload)` |  `POST /v1beta1/{parent}/models:upload`   
Uploads a Model artifact into Vertex AI.  
  
## REST Resource: [v1beta1.projects.locations.models.evaluations](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models.evaluations)

Methods  
---  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models.evaluations/get)` |  `GET /v1beta1/{name}`   
Gets a ModelEvaluation.  
`[import](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models.evaluations/import)` |  `POST /v1beta1/{parent}/evaluations:import`   
Imports an externally generated ModelEvaluation.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models.evaluations/list)` |  `GET /v1beta1/{parent}/evaluations`   
Lists ModelEvaluations in a Model.  
  
## REST Resource: [v1beta1.projects.locations.models.evaluations.slices](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models.evaluations.slices)

Methods  
---  
`[batchImport](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models.evaluations.slices/batchImport)` |  `POST /v1beta1/{parent}:batchImport`   
Imports a list of externally generated EvaluatedAnnotations.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models.evaluations.slices/get)` |  `GET /v1beta1/{name}`   
Gets a ModelEvaluationSlice.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.models.evaluations.slices/list)` |  `GET /v1beta1/{parent}/slices`   
Lists ModelEvaluationSlices in a ModelEvaluation.  
  
## REST Resource: [v1beta1.projects.locations.notebookExecutionJobs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookExecutionJobs)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookExecutionJobs/create)` |  `POST /v1beta1/{parent}/notebookExecutionJobs`   
Creates a NotebookExecutionJob.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookExecutionJobs/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a NotebookExecutionJob.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookExecutionJobs/get)` |  `GET /v1beta1/{name}`   
Gets a NotebookExecutionJob.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookExecutionJobs/list)` |  `GET /v1beta1/{parent}/notebookExecutionJobs`   
Lists NotebookExecutionJobs in a Location.  
  
## REST Resource: [v1beta1.projects.locations.notebookRuntimeTemplates](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimeTemplates)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimeTemplates/create)` |  `POST /v1beta1/{parent}/notebookRuntimeTemplates`   
Creates a NotebookRuntimeTemplate.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimeTemplates/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a NotebookRuntimeTemplate.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimeTemplates/get)` |  `GET /v1beta1/{name}`   
Gets a NotebookRuntimeTemplate.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimeTemplates/getIamPolicy)` |  `POST /v1beta1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimeTemplates/list)` |  `GET /v1beta1/{parent}/notebookRuntimeTemplates`   
Lists NotebookRuntimeTemplates in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimeTemplates/patch)` |  `PATCH /v1beta1/{notebookRuntimeTemplate.name}`   
Updates a NotebookRuntimeTemplate.  
`[setIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimeTemplates/setIamPolicy)` |  `POST /v1beta1/{resource}:setIamPolicy`   
Sets the access control policy on the specified resource.  
`[testIamPermissions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimeTemplates/testIamPermissions)` |  `POST /v1beta1/{resource}:testIamPermissions`   
Returns permissions that a caller has on the specified resource.  
  
## REST Resource: [v1beta1.projects.locations.notebookRuntimes](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimes)

Methods  
---  
`[assign](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimes/assign)` |  `POST /v1beta1/{parent}/notebookRuntimes:assign`   
Assigns a NotebookRuntime to a user for a particular Notebook file.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimes/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a NotebookRuntime.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimes/get)` |  `GET /v1beta1/{name}`   
Gets a NotebookRuntime.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimes/list)` |  `GET /v1beta1/{parent}/notebookRuntimes`   
Lists NotebookRuntimes in a Location.  
`[start](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimes/start)` |  `POST /v1beta1/{name}:start`   
Starts a NotebookRuntime.  
`[stop](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimes/stop)` |  `POST /v1beta1/{name}:stop`   
Stops a NotebookRuntime.  
`[upgrade](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.notebookRuntimes/upgrade)` |  `POST /v1beta1/{name}:upgrade`   
Upgrades a NotebookRuntime.  
  
## REST Resource: [v1beta1.projects.locations.operations](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.operations)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.operations/cancel)` |  `POST /v1beta1/{name}:cancel`   
Starts asynchronous cancellation on a long-running operation.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.operations/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a long-running operation.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.operations/get)` |  `GET /v1beta1/{name}`   
Gets the latest state of a long-running operation.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.operations/list)` |  `GET /v1beta1/{name}/operations`   
Lists operations that match the specified filter in the request.  
`[wait](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.operations/wait)` |  `POST /v1beta1/{name}:wait`   
Waits until the specified long-running operation is done or reaches at most a specified timeout, returning the latest state.  
  
## REST Resource: [v1beta1.projects.locations.persistentResources](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.persistentResources)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.persistentResources/create)` |  `POST /v1beta1/{parent}/persistentResources`   
Creates a PersistentResource.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.persistentResources/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a PersistentResource.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.persistentResources/get)` |  `GET /v1beta1/{name}`   
Gets a PersistentResource.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.persistentResources/list)` |  `GET /v1beta1/{parent}/persistentResources`   
Lists PersistentResources in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.persistentResources/patch)` |  `PATCH /v1beta1/{persistentResource.name}`   
Updates a PersistentResource.  
`[reboot](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.persistentResources/reboot)` |  `POST /v1beta1/{name}:reboot`   
Reboots a PersistentResource.  
  
## REST Resource: [v1beta1.projects.locations.pipelineJobs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.pipelineJobs)

Methods  
---  
`[batchCancel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.pipelineJobs/batchCancel)` |  `POST /v1beta1/{parent}/pipelineJobs:batchCancel`   
Batch cancel PipelineJobs.  
`[batchDelete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.pipelineJobs/batchDelete)` |  `POST /v1beta1/{parent}/pipelineJobs:batchDelete`   
Batch deletes PipelineJobs The Operation is atomic.  
`[cancel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.pipelineJobs/cancel)` |  `POST /v1beta1/{name}:cancel`   
Cancels a PipelineJob.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.pipelineJobs/create)` |  `POST /v1beta1/{parent}/pipelineJobs`   
Creates a PipelineJob.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.pipelineJobs/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a PipelineJob.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.pipelineJobs/get)` |  `GET /v1beta1/{name}`   
Gets a PipelineJob.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.pipelineJobs/list)` |  `GET /v1beta1/{parent}/pipelineJobs`   
Lists PipelineJobs in a Location.  
  
## REST Resource: [v1beta1.projects.locations.publishers.models](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models)

Methods  
---  
`[computeTokens](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/computeTokens)` |  `POST /v1beta1/{endpoint}:computeTokens`   
Return a list of tokens based on the input text.  
`[countTokens](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/countTokens)` |  `POST /v1beta1/{endpoint}:countTokens`   
Perform a token counting.  
`[export](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/export)` |  `POST /v1beta1/{parent}/{name}:export`   
Exports a publisher model to a user provided Google Cloud Storage bucket.  
`[fetchPublisherModelConfig](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/fetchPublisherModelConfig)` |  `GET /v1beta1/{name}:fetchPublisherModelConfig`   
Fetches the configs of publisher models.  
`[generateContent](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/generateContent)` |  `POST /v1beta1/{model}:generateContent`   
Generate content with multimodal inputs.  
`[getIamPolicy](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/getIamPolicy)` |  `POST /v1beta1/{resource}:getIamPolicy`   
Gets the access control policy for a resource.  
`[predict](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/predict)` |  `POST /v1beta1/{endpoint}:predict`   
Perform an online prediction.  
`[rawPredict](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/rawPredict)` |  `POST /v1beta1/{endpoint}:rawPredict`   
Perform an online prediction with an arbitrary HTTP payload.  
`[serverStreamingPredict](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/serverStreamingPredict)` |  `POST /v1beta1/{endpoint}:serverStreamingPredict`   
Perform a server-side streaming online prediction request for Vertex LLM streaming.  
`[setPublisherModelConfig](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/setPublisherModelConfig)` |  `POST /v1beta1/{name}:setPublisherModelConfig`   
Sets (creates or updates) configs of publisher models.  
`[streamRawPredict](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/streamRawPredict)` |  `POST /v1beta1/{endpoint}:streamRawPredict`   
Perform a streaming online prediction with an arbitrary HTTP payload.  
  
## REST Resource: [v1beta1.projects.locations.ragCorpora](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.ragCorpora)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.ragCorpora/create)` |  `POST /v1beta1/{parent}/ragCorpora`   
Creates a RagCorpus.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.ragCorpora/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a RagCorpus.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.ragCorpora/get)` |  `GET /v1beta1/{name}`   
Gets a RagCorpus.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.ragCorpora/list)` |  `GET /v1beta1/{parent}/ragCorpora`   
Lists RagCorpora in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.ragCorpora/patch)` |  `PATCH /v1beta1/{ragCorpus.name}`   
Updates a RagCorpus.  
  
## REST Resource: [v1beta1.projects.locations.ragCorpora.ragFiles](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.ragCorpora.ragFiles)

Methods  
---  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.ragCorpora.ragFiles/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a RagFile.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.ragCorpora.ragFiles/get)` |  `GET /v1beta1/{name}`   
Gets a RagFile.  
`[import](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.ragCorpora.ragFiles/import)` |  `POST /v1beta1/{parent}/ragFiles:import`   
Import files from Google Cloud Storage or Google Drive into a RagCorpus.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.ragCorpora.ragFiles/list)` |  `GET /v1beta1/{parent}/ragFiles`   
Lists RagFiles in a RagCorpus.  
  
## REST Resource: [v1beta1.projects.locations.reasoningEngines](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines/create)` |  `POST /v1beta1/{parent}/reasoningEngines`   
Creates a reasoning engine.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a reasoning engine.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines/get)` |  `GET /v1beta1/{name}`   
Gets a reasoning engine.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines/list)` |  `GET /v1beta1/{parent}/reasoningEngines`   
Lists reasoning engines in a location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines/patch)` |  `PATCH /v1beta1/{reasoningEngine.name}`   
Updates a reasoning engine.  
`[query](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines/query)` |  `POST /v1beta1/{name}:query`   
Queries using a reasoning engine.  
`[streamQuery](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines/streamQuery)` |  `POST /v1beta1/{name}:streamQuery`   
Streams queries using a reasoning engine.  
  
## REST Resource: [v1beta1.projects.locations.reasoningEngines.memories](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.memories)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.memories/create)` |  `POST /v1beta1/{parent}/memories`   
Create a Memory.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.memories/delete)` |  `DELETE /v1beta1/{name}`   
Delete a Memory.  
`[generate](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.memories/generate)` |  `POST /v1beta1/{parent}/memories:generate`   
Generate memories.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.memories/get)` |  `GET /v1beta1/{name}`   
Get a Memory.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.memories/list)` |  `GET /v1beta1/{parent}/memories`   
List Memories.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.memories/patch)` |  `PATCH /v1beta1/{memory.name}`   
Update a Memory.  
`[retrieve](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.memories/retrieve)` |  `POST /v1beta1/{parent}/memories:retrieve`   
Retrieve memories.  
  
## REST Resource: [v1beta1.projects.locations.reasoningEngines.sessions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions)

Methods  
---  
`[appendEvent](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions/appendEvent)` |  `POST /v1beta1/{name}:appendEvent`   
Appends an event to a given session.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions/create)` |  `POST /v1beta1/{parent}/sessions`   
Creates a new `[Session](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions#Session)`.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions/delete)` |  `DELETE /v1beta1/{name}`   
Deletes details of the specific `[Session](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions#Session)`.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions/get)` |  `GET /v1beta1/{name}`   
Gets details of the specific `[Session](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions#Session)`.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions/list)` |  `GET /v1beta1/{parent}/sessions`   
Lists `[Sessions](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions#Session)` in a given reasoning engine.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions/patch)` |  `PATCH /v1beta1/{session.name}`   
Updates the specific `[Session](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions#Session)`.  
  
## REST Resource: [v1beta1.projects.locations.reasoningEngines.sessions.events](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions.events)

Methods  
---  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions.events/list)` |  `GET /v1beta1/{parent}/events`   
Lists `[Events](/vertex-ai/docs/reference/rest/v1beta1/Event)` in a given session.  
  
## REST Resource: [v1beta1.projects.locations.schedules](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.schedules)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.schedules/create)` |  `POST /v1beta1/{parent}/schedules`   
Creates a Schedule.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.schedules/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a Schedule.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.schedules/get)` |  `GET /v1beta1/{name}`   
Gets a Schedule.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.schedules/list)` |  `GET /v1beta1/{parent}/schedules`   
Lists Schedules in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.schedules/patch)` |  `PATCH /v1beta1/{schedule.name}`   
Updates an active or paused Schedule.  
`[pause](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.schedules/pause)` |  `POST /v1beta1/{name}:pause`   
Pauses a Schedule.  
`[resume](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.schedules/resume)` |  `POST /v1beta1/{name}:resume`   
Resumes a paused Schedule to start scheduling new runs.  
  
## REST Resource: [v1beta1.projects.locations.specialistPools](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.specialistPools)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.specialistPools/create)` |  `POST /v1beta1/{parent}/specialistPools`   
Creates a SpecialistPool.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.specialistPools/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a SpecialistPool as well as all Specialists in the pool.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.specialistPools/get)` |  `GET /v1beta1/{name}`   
Gets a SpecialistPool.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.specialistPools/list)` |  `GET /v1beta1/{parent}/specialistPools`   
Lists SpecialistPools in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.specialistPools/patch)` |  `PATCH /v1beta1/{specialistPool.name}`   
Updates a SpecialistPool.  
  
## REST Resource: [v1beta1.projects.locations.studies](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies/create)` |  `POST /v1beta1/{parent}/studies`   
Creates a Study.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a Study.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies/get)` |  `GET /v1beta1/{name}`   
Gets a Study by name.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies/list)` |  `GET /v1beta1/{parent}/studies`   
Lists all the studies in a region for an associated project.  
`[lookup](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies/lookup)` |  `POST /v1beta1/{parent}/studies:lookup`   
Looks a study up using the user-defined display_name field instead of the fully qualified resource name.  
  
## REST Resource: [v1beta1.projects.locations.studies.trials](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies.trials)

Methods  
---  
`[addTrialMeasurement](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies.trials/addTrialMeasurement)` |  `POST /v1beta1/{trialName}:addTrialMeasurement`   
Adds a measurement of the objective metrics to a Trial.  
`[checkTrialEarlyStoppingState](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies.trials/checkTrialEarlyStoppingState)` |  `POST /v1beta1/{trialName}:checkTrialEarlyStoppingState`   
Checks whether a Trial should stop or not.  
`[complete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies.trials/complete)` |  `POST /v1beta1/{name}:complete`   
Marks a Trial as complete.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies.trials/create)` |  `POST /v1beta1/{parent}/trials`   
Adds a user provided Trial to a Study.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies.trials/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a Trial.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies.trials/get)` |  `GET /v1beta1/{name}`   
Gets a Trial.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies.trials/list)` |  `GET /v1beta1/{parent}/trials`   
Lists the Trials associated with a Study.  
`[listOptimalTrials](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies.trials/listOptimalTrials)` |  `POST /v1beta1/{parent}/trials:listOptimalTrials`   
Lists the pareto-optimal Trials for multi-objective Study or the optimal Trials for single-objective Study.  
`[stop](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies.trials/stop)` |  `POST /v1beta1/{name}:stop`   
Stops a Trial.  
`[suggest](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.studies.trials/suggest)` |  `POST /v1beta1/{parent}/trials:suggest`   
Adds one or more Trials to a Study, with parameter values suggested by Vertex AI Vizier.  
  
## REST Resource: [v1beta1.projects.locations.tensorboards](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards)

Methods  
---  
`[batchRead](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards/batchRead)` |  `GET /v1beta1/{tensorboard}:batchRead`   
Reads multiple TensorboardTimeSeries' data.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards/create)` |  `POST /v1beta1/{parent}/tensorboards`   
Creates a Tensorboard.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a Tensorboard.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards/get)` |  `GET /v1beta1/{name}`   
Gets a Tensorboard.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards/list)` |  `GET /v1beta1/{parent}/tensorboards`   
Lists Tensorboards in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards/patch)` |  `PATCH /v1beta1/{tensorboard.name}`   
Updates a Tensorboard.  
`[readSize](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards/readSize)` |  `GET /v1beta1/{tensorboard}:readSize`   
Returns the storage size for a given TensorBoard instance.  
`[readUsage](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards/readUsage)` |  `GET /v1beta1/{tensorboard}:readUsage`   
Returns a list of monthly active users for a given TensorBoard instance.  
  
## REST Resource: [v1beta1.projects.locations.tensorboards.experiments](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments)

Methods  
---  
`[batchCreate](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments/batchCreate)` |  `POST /v1beta1/{parent}:batchCreate`   
Batch create TensorboardTimeSeries that belong to a TensorboardExperiment.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments/create)` |  `POST /v1beta1/{parent}/experiments`   
Creates a TensorboardExperiment.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a TensorboardExperiment.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments/get)` |  `GET /v1beta1/{name}`   
Gets a TensorboardExperiment.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments/list)` |  `GET /v1beta1/{parent}/experiments`   
Lists TensorboardExperiments in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments/patch)` |  `PATCH /v1beta1/{tensorboardExperiment.name}`   
Updates a TensorboardExperiment.  
`[write](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments/write)` |  `POST /v1beta1/{tensorboardExperiment}:write`   
Write time series data points of multiple TensorboardTimeSeries in multiple TensorboardRun's.  
  
## REST Resource: [v1beta1.projects.locations.tensorboards.experiments.runs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs)

Methods  
---  
`[batchCreate](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs/batchCreate)` |  `POST /v1beta1/{parent}/runs:batchCreate`   
Batch create TensorboardRuns.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs/create)` |  `POST /v1beta1/{parent}/runs`   
Creates a TensorboardRun.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a TensorboardRun.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs/get)` |  `GET /v1beta1/{name}`   
Gets a TensorboardRun.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs/list)` |  `GET /v1beta1/{parent}/runs`   
Lists TensorboardRuns in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs/patch)` |  `PATCH /v1beta1/{tensorboardRun.name}`   
Updates a TensorboardRun.  
`[write](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs/write)` |  `POST /v1beta1/{tensorboardRun}:write`   
Write time series data points into multiple TensorboardTimeSeries under a TensorboardRun.  
  
## REST Resource: [v1beta1.projects.locations.tensorboards.experiments.runs.timeSeries](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs.timeSeries)

Methods  
---  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs.timeSeries/create)` |  `POST /v1beta1/{parent}/timeSeries`   
Creates a TensorboardTimeSeries.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs.timeSeries/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a TensorboardTimeSeries.  
`[exportTensorboardTimeSeries](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs.timeSeries/exportTensorboardTimeSeries)` |  `POST /v1beta1/{tensorboardTimeSeries}:exportTensorboardTimeSeries`   
Exports a TensorboardTimeSeries' data.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs.timeSeries/get)` |  `GET /v1beta1/{name}`   
Gets a TensorboardTimeSeries.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs.timeSeries/list)` |  `GET /v1beta1/{parent}/timeSeries`   
Lists TensorboardTimeSeries in a Location.  
`[patch](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs.timeSeries/patch)` |  `PATCH /v1beta1/{tensorboardTimeSeries.name}`   
Updates a TensorboardTimeSeries.  
`[read](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs.timeSeries/read)` |  `GET /v1beta1/{tensorboardTimeSeries}:read`   
Reads a TensorboardTimeSeries' data.  
`[readBlobData](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tensorboards.experiments.runs.timeSeries/readBlobData)` |  `GET /v1beta1/{timeSeries}:readBlobData`   
Gets bytes of TensorboardBlobs.  
  
## REST Resource: [v1beta1.projects.locations.trainingPipelines](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.trainingPipelines)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.trainingPipelines/cancel)` |  `POST /v1beta1/{name}:cancel`   
Cancels a TrainingPipeline.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.trainingPipelines/create)` |  `POST /v1beta1/{parent}/trainingPipelines`   
Creates a TrainingPipeline.  
`[delete](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.trainingPipelines/delete)` |  `DELETE /v1beta1/{name}`   
Deletes a TrainingPipeline.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.trainingPipelines/get)` |  `GET /v1beta1/{name}`   
Gets a TrainingPipeline.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.trainingPipelines/list)` |  `GET /v1beta1/{parent}/trainingPipelines`   
Lists TrainingPipelines in a Location.  
  
## REST Resource: [v1beta1.projects.locations.tuningJobs](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tuningJobs)

Methods  
---  
`[cancel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tuningJobs/cancel)` |  `POST /v1beta1/{name}:cancel`   
Cancels a TuningJob.  
`[create](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tuningJobs/create)` |  `POST /v1beta1/{parent}/tuningJobs`   
Creates a TuningJob.  
`[get](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tuningJobs/get)` |  `GET /v1beta1/{name}`   
Gets a TuningJob.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tuningJobs/list)` |  `GET /v1beta1/{parent}/tuningJobs`   
Lists TuningJobs in a Location.  
`[rebaseTunedModel](/vertex-ai/docs/reference/rest/v1beta1/projects.locations.tuningJobs/rebaseTunedModel)` |  `POST /v1beta1/{parent}/tuningJobs:rebaseTunedModel`   
Rebase a TunedModel.  
  
## REST Resource: [v1beta1.projects.modelGardenEula](/vertex-ai/docs/reference/rest/v1beta1/projects.modelGardenEula)

Methods  
---  
`[accept](/vertex-ai/docs/reference/rest/v1beta1/projects.modelGardenEula/accept)` |  `POST /v1beta1/{parent}/modelGardenEula:accept`   
Accepts the EULA acceptance status of a publisher model.  
`[check](/vertex-ai/docs/reference/rest/v1beta1/projects.modelGardenEula/check)` |  `POST /v1beta1/{parent}/modelGardenEula:check`   
Checks the EULA acceptance status of a publisher model.  
  
## REST Resource: [v1beta1.publishers.models](/vertex-ai/docs/reference/rest/v1beta1/publishers.models)

Methods  
---  
`[get](/vertex-ai/docs/reference/rest/v1beta1/publishers.models/get)` |  `GET /v1beta1/{name}`   
Gets a Model Garden publisher model.  
`[list](/vertex-ai/docs/reference/rest/v1beta1/publishers.models/list)` |  `GET /v1beta1/{parent}/models`   
Lists publisher models in Model Garden.  
  
Send feedback 

Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-10-10 UTC.

Need to tell us more?  [[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Hard to understand","hardToUnderstand","thumb-down"],["Incorrect information or sample code","incorrectInformationOrSampleCode","thumb-down"],["Missing the information/samples I need","missingTheInformationSamplesINeed","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-10-10 UTC."],[],[]] 
Skip to main content 

[ ![Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v0a8f38b07c3863b7ced1d678d2584c8bd483c306fc4b8f547093e71dea088feb/cloud/images/cloud-logo.svg) ](/)

  * 


`/`

  * English
  * Deutsch
  * Español
  * Español – América Latina
  * Français
  * Indonesia
  * Italiano
  * Português
  * Português – Brasil
  * 中文 – 简体
  * 中文 – 繁體
  * 日本語
  * 한국어

[ Console ](//console.cloud.google.com/) Sign in

  * [ Vertex AI ](https://cloud.google.com/vertex-ai/docs)



[Contact Us](https://cloud.google.com/contact) [Start free](//console.cloud.google.com/freetrial)

  * [ Home ](https://cloud.google.com/)
  * [ Documentation ](https://cloud.google.com/docs)
  * [ AI and ML ](https://cloud.google.com/docs/ai-ml)
  * [ Vertex AI ](https://cloud.google.com/vertex-ai/docs)



Send feedback 

#  Tutorials overview

Stay organized with collections  Save and categorize content based on your preferences. 

Each of the tutorials presented here walks you through a specific artificial intelligence (AI) workflow, created to represent the most common tasks and to illustrate the capabilities of Vertex AI. Choose the tutorial that best matches your data type and AI task. After following the tutorial, you can use the patterns that you have learned to solve your own AI problem. Vertex AI offers Google Cloud console tutorials and notebook tutorials that use the Python SDK. You can open a notebook tutorial directly in Colab, download the notebook to your preferred environment, or open the notebook tutorial in Vertex AI Workbench.

## Train a classification model for tabular data

![Tabular classification training introduction](/static/vertex-ai/docs/images/automl-tables.svg) |  Create a Vertex AI dataset from tabular data, and then train a classification model with AutoML. Deploy the model to an endpoint and make online predictions.  **Google Cloud console** : You can choose tutorial guides with step-by-step instructions for the Google Cloud console.  
[Show on cloud.google.com](/vertex-ai/docs/tutorials/tabular-automl/overview) | [Show in an interactive format in Google Cloud console](https://console.cloud.google.com/?walkthrough_id=vertex_tabular_part1) **Notebook** : You can choose to run this tutorial as a notebook.  
[Run in Colab](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl-tabular-classification.ipynb) | [Open in Colab Enterprise](https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fautoml%2Fautoml-tabular-classification.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl-tabular-classification.ipynb) | [Open in Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/automl/automl-tabular-classification.ipynb)

## Train a regression model for tabular data

|  ![Tabular regression training introduction](/static/vertex-ai/docs/images/automl-tables.svg) |  Create a Vertex AI dataset from tabular data, and then train a regression model with AutoML. Deploy the model to an endpoint and make online predictions or make predictions in batch format.  **Notebook** : You can choose to run this tutorial and make **online predictions** using a notebook.  
[Run in Colab](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/sdk_automl_tabular_regression_online_bq.ipynb) | [Open in Colab Enterprise](https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fautoml%2Fsdk_automl_tabular_regression_online_bq.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/sdk_automl_tabular_regression_online_bq.ipynb) | [Open in Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/automl/sdk_automl_tabular_regression_online_bq.ipynb) **Notebook** : You can choose to run this tutorial and make **batch predictions** using a notebook.  
[Run in Colab](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/sdk_automl_tabular_regression_batch_bq.ipynb) | [Open in Colab Enterprise](https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fautoml%2Fsdk_automl_tabular_regression_batch_bq.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/sdk_automl_tabular_regression_batch_bq.ipynb) | [Open in Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/automl/sdk_automl_tabular_regression_batch_bq.ipynb)

## Train a time-series forecasting model for tabular data

|  ![Tabular forecasting training introduction](/static/vertex-ai/docs/images/automl-tables.svg) |  Create a Vertex AI dataset from tabular data, and then train a forecasting model with AutoML. Make predictions in batch format.  **Notebook** : You can choose to run this tutorial as a notebook.  
[Run in Colab](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/sdk_automl_tabular_forecasting_batch.ipynb) | [Open in Colab Enterprise](https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fautoml%2Fsdk_automl_tabular_forecasting_batch.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/sdk_automl_tabular_forecasting_batch.ipynb) | [Open in Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/automl/sdk_automl_tabular_forecasting_batch.ipynb)

## Train a classification model for image data

|  ![Image classification training introduction](/static/vertex-ai/docs/images/automl-vision.svg) |  Create a Vertex AI dataset for image data, and then train a classification model with AutoML. Deploy the model to an endpoint and make online predictions.  **Google Cloud console** : You can choose tutorial guides with step-by-step instructions for the Google Cloud console.  
[Show on cloud.google.com](/vertex-ai/docs/tutorials/image-classification-automl/overview) | [Show in an interactive format in Google Cloud console](https://console.cloud.google.com/?walkthrough_id=vertex_image_classification_automl_console)

## How to open a notebook in Vertex AI Workbench

To open a notebook tutorial in a Vertex AI Workbench instance: 

  1. Click the **Vertex AI Workbench** link in the [notebook list](/vertex-ai/docs/tutorials/jupyter-notebooks). The link opens the Vertex AI Workbench console. 
  2. In the **Deploy to notebook** screen, type a name for your new Vertex AI Workbench instance and click **Create**. 
  3. In the **Ready to open notebook** dialog that appears after the instance starts, click **Open**. 
  4. On the **Confirm deployment to notebook server** page, select **Confirm**. 
  5. Before running the notebook, select **Kernel > Restart Kernel and Clear all Outputs**. 



## What's next

  * View the full list of [Vertex AI notebook tutorials](/vertex-ai/docs/tutorials/jupyter-notebooks).
  * Learn more about [model training](/vertex-ai/docs/training-overview).

Send feedback  Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates. Need to tell us more?  [[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Hard to understand","hardToUnderstand","thumb-down"],["Incorrect information or sample code","incorrectInformationOrSampleCode","thumb-down"],["Missing the information/samples I need","missingTheInformationSamplesINeed","thumb-down"],["Other","otherDown","thumb-down"]],[],[],[]] 
[![](https://cdn.prod.website-files.com/63f3b75480ddf706ad2f8ca6/66fea6d5047132741fb785c7_Logo.svg)](/)

[Log In](https://app.cloudchipr.com/)[Start Free Trial](https://app.cloudchipr.com/)[Book a Demo](/book-a-demo)

[Cloud Services](/tags/cloud-services)

[Google Cloud](/tags/google-cloud)

[Cloud Operations](/tags/cloud-operations)

[Tools](/tags/tools)

# What Is Vertex AI? Streamlining ML Workflows on Google Cloud

June 12, 2025

10

min read

[Cloud Services](/tags/cloud-services)

[Google Cloud](/tags/google-cloud)

[Cloud Operations](/tags/cloud-operations)

[Tools](/tags/tools)

![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/684abb908203777d80e91bdb_image%20\(81\).png)

## **Introduction**

**Vertex AI** is Google Cloudâs unified machine learning platform designed to streamline the entire ML lifecycle, from data preparation to model deployment and monitoring. In simple terms, Vertex AI brings together all the tools and services needed to **train, deploy, and manage ML models and AI applications on Google Cloud**. Instead of piecing together separate services for data science, model training, and MLOps, Google Vertex AI offers a one-stop environment that **combines data engineering, data science, and ML engineering workflows** into a unified toolset. This unified approach enables teams to collaborate more easily and scale their AI solutions using Google Cloud's robust infrastructure.

If youâve ever wondered _what Vertex AI is_ and how it differs from the myriad of AI offerings out there, youâre not alone. Think of Vertex AI as **âthe ML platform on GCPâ** (Google Cloud Platform) that consolidates capabilities that were previously spread across multiple services. It supersedes Googleâs legacy AI Platform/AutoML products with a more cohesive experience. Whether youâre a data scientist experimenting with new models or a business decision-maker looking for faster AI-driven insights, Vertex AI aims to simplify the journey. In this article, weâll break down Vertex AIâs key components (including **Vertex AI models** and the new **Vertex AI Agent Builder**), explore how it works, discuss Google Vertex AI pricing, and look at real-world examples of Vertex AI in action. By the end, you should have a clear understanding of _what Vertex AI is_ , what value it offers, and why it has become a cornerstone of AI strategy for many enterprises.

## **What is Vertex AI ?**

![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/684abbec59b2312c1630329c_overall_workflow.max-1200x1200.png)

Image Source: <https://cloud.google.com/>

At its core, **Vertex AI is a managed platform for building and deploying machine learning models on Google Cloud**. It matters because it greatly reduces the complexity traditionally involved in moving ML projects from research to production. In the past, an ML team might use one tool for data prep, another for training models, and yet another for serving predictions. Vertex AI unifies these steps so you can focus on developing insights rather than wrangling infrastructure.

### **Vertex AI in a Nutshell**

Vertex AI lets you do everything from importing data and training models to hosting those models for prediction, all within a consistent environment. It supports both **no-code/low-code model training** and **custom code training** , catering to users of all skill levels:

  * **AutoML:** If you have tabular data, images, text, or videos and you want a model without writing code, Vertex AIâs AutoML will handle it. You can train high-quality models on your dataset with just a few clicks â no manual model coding or data splitting needed . This is great for rapid prototyping or for teams with limited ML coding expertise. AutoML models can then be directly **deployed for online predictions or used for batch predictions** on large datasets.
  * **Custom Training:** For experienced ML engineers who need full control, Vertex AI also supports custom model training. You can bring your own code written in TensorFlow, PyTorch, scikit-learn, or any framework, and run it on Googleâs managed infrastructure. This includes options for hyperparameter tuning (e.g., using Vertex AI Vizier) and using custom containers. After training, your custom model can be registered in the Model Registry and deployed to an endpoint with a few API calls or clicks . In other words, Vertex AI handles the heavy lifting of provisioning GPU/TPU compute, distributed training, etc., while you focus on your model logic.



Beyond training, Vertex AI offers a **host of MLOps features** to operationalize AI:

![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/684abbff2741d088a85414ab_Secure_Software_Blog_2_4.max-2600x2600.png)

Image Source: <https://cloud.google.com/>

  * **Model Deployment & Serving:** With Vertex AI, deploying a model is straightforward. You can host your model on a scalable endpoint for real-time serving (online predictions) with a single command or through the console . Vertex AI will manage the compute instances behind the scenes. If you only need periodic predictions on a batch of examples, you can use batch prediction which reads data from sources like Cloud Storage or BigQuery and writes results back, **without needing a live endpoint**.
  * **Pipelines & Automation:** Using **Vertex AI Pipelines** , you can orchestrate complex workflows (from data prep to evaluation to deployment) in a reproducible manner. This helps in automating retraining jobs or setting up CI/CD for ML models. For example, you might schedule a pipeline to ingest new training data, retrain a model, evaluate it, and deploy it if performance is improved â all automatically.
  * **Feature Store:** Vertex AI includes a **Feature Store** for managing machine learning features centrally. This service lets you serve common features to models in production with low latency and monitor feature drift over time.
  * **Experiment Tracking & Model Registry:** Experimentation is key in ML. Vertex AI offers tools to track experiments (parameters and results) and a **Model Registry** to version your models. You can think of the Model Registry as a central catalog of all your ML models (with versions, metadata, and evaluations), making it easier to hand off models from data scientists to ML engineers for deployment.
  * **Monitoring & Explainability:** Once your model is live, Vertex AI can monitor it for you. **Vertex AI Model Monitoring** will watch incoming predictions for anomalies like data drift or training-serving skew, sending alerts if something seems off. Additionally, **Vertex Explainable AI** provides feature attributions to help interpret model predictions. This is crucial in enterprise settings where understanding _why_ a model made a decision is as important as the decision itself (think of regulated industries needing AI transparency).



![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/684abc29c609acc1cec34124_Screenshot_2024-06-11_at_10.18.53AM.max-1800x1800.png)

Image Source: <https://cloud.google.com/>

In essence, Vertex AI covers the end-to-end cycle of ML development. It **enables a true MLOps practice** on Google Cloud â from the moment you start cleaning data to the moment your model is making predictions in production and being monitored for quality. By centralizing these capabilities, Vertex AI helps enterprises shorten the time **âfrom idea to impactâ** for ML projects.

## **End-to-End Workflow: How Vertex AI Streamlines ML Development**

![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/684abc40ec4803b6f750622c_ml-workflow.svg)

Image Source: <https://cloud.google.com/>

To **demystify Vertex AI** , it helps to walk through a typical machine learning workflow and see where Vertex AI comes into play at each step. The platform is designed to support each stage of an ML project:

  1. **Data Preparation:** Successful models start with good data. In Vertex AI, you can use **Vertex AI Workbench** notebooks (managed JupyterLab environments) to explore and preprocess your data. Workbench notebooks come with integrations to Google Cloud Storage and BigQuery, so you can easily pull in large datasets without jumping between platforms. For large-scale data processing, you can even launch Spark jobs (via Dataproc Serverless) directly from the notebook. In short, Vertex AI ensures that whether youâre doing simple EDA or big data wrangling, you have the tools at your fingertips in a hosted, collaborative environment.
  2. **Model Training:** Once your data is ready, Vertex AI offers flexible training options. If you choose **AutoML** , you simply select your data source and target column (for tabular) or label set (for images/text), and Vertex AI will train a model for you using Googleâs state-of-the-art architectures â no code needed. AutoML supports a variety of tasks (classification, regression, image detection, etc.) across different data types. On the other hand, if you have custom code, Vertex AIâs custom training will provision the compute resources (including GPUs/TPUs if specified) and run your training code in a Docker container. You can scale out hyperparameter tuning jobs or utilize Vertex AI Vizier to intelligently search for optimal model parameters. Vertex AI also allows logging of metrics and storing models during training, so you can review training progress and results after the fact. When training completes, youâll register the new model in Vertex AIâs Model Registry for the next stage.
  3. **Model Evaluation & Iteration:** Model development is an iterative process. Vertex AI makes it easy to evaluate your model â either using built-in evaluation tools or by generating evaluation metrics and comparing them in the platform. If the model isnât performing as needed, you might go back for more data cleaning or try a different modeling approach. Vertex AIâs experiment tracking helps record these iterations so you can compare which version of a model performed best. The goal is to foster a **cycle of continuous improvement** , and Vertex AI supports this by linking the evaluation results with the training runs and dataset versions used.
  4. **Deployment (Model Serving):** Once satisfied with a model, you can deploy it to a **Vertex AI endpoint**. Deployment is as easy as selecting the model in the registry and choosing a machine type for serving. Vertex AI will containerize the model (using either a prebuilt serving container for common frameworks or a custom container you provide) and spin up the required infrastructure automatically. The result is an HTTPS endpoint that clients can call to get predictions. This fully managed serving means you donât have to maintain your own Kubernetes cluster or VMs for model inference â Vertex AI handles scaling, health checks, and even multi-model hosting if you want to deploy several models to the same endpoint to save costs. For use cases that donât need an always-on model, you can run **batch predictions** , which read a bunch of inputs, process them through the model, and save outputs to a file or table. Batch jobs are useful for nightly analytics or processing large datasets through the model in one go.
  5. **Monitoring & Maintenance:** After deployment, the journey isnât over â models can degrade over time as data patterns change. Vertex AI provides **Model Monitoring** to watch for issues like data drift (when incoming data starts to differ significantly from training data) or skew (when the relationship between features and predictions changes). If something unusual is detected â say usersâ input data distributions shift â you get alerted to investigate. Vertex AI can also log predictions and explanations, which you can feed back into retraining pipelines. This closed-loop enables an ML system that **learns and adapts continuously**. In addition, using Vertex AIâs Explainable AI tools, you can periodically ensure the modelâs decisions make sense (for example, confirming that a loan approval model is basing decisions on relevant financial history features and not on any sensitive or spurious data).



Throughout all these stages, **Vertex AI emphasizes a âfully managedâ experience**. You arenât manually configuring servers for a training job or setting up monitoring dashboards from scratch â those capabilities are built-in. This not only accelerates development but also ensures best practices (like using the right machine types, securing endpoints, etc.) are followed by default. As a seasoned ML engineer might say, Vertex AI lets you _ride on the rails_ of Googleâs infrastructure, so you can spend more time on data and models, and less on plumbing.

## **Pre-Trained Models and the Vertex AI Model Garden**

![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/684abc97bfa65c78f5910757_1_Generative_AI_support_in_Vertex_AI.max-2000x2000.webp)

Image Source: <https://cloud.google.com/>

One of the most exciting aspects of Vertex AI is how it opens up access to **pre-trained models, including Googleâs state-of-the-art âfoundation modelsâ**. In todayâs AI landscape, leveraging existing models (especially large models trained on vast data) can give you a huge head start. Vertex AI makes this possible through its **Model Garden** and generative AI offerings.

**Vertex AI Model Garden** is essentially an AI model library or marketplace that includes models from Google and select partners. You can browse a variety of models â from large language models (LLMs) for text and chat, to image generation models, speech recognition, and more. These include Googleâs own cutting-edge models (for example, the **PaLM family of LLMs, or the Imagen image generator**) as well as popular open-source models and those from Googleâs partners. The beauty of Model Garden is that all these models are accessible in one place, with a **consistent user experience for deploying and using them**. Whether itâs a massive text model or a vision model, you usually can click to deploy it to a Vertex AI endpoint or interact with it via the API/SDK with minimal setup.

Why does this matter? It means even if you donât have the resources to train a huge model from scratch, you can still **tap into âVertex AI modelsâ that are pre-trained on millions of data points**. For example, if you need a chatbot or need to summarize documents, you could utilize a Google Cloud LLM via Vertex AI. These models can often be **customized (fine-tuned or prompt-tuned) on your own data** using Vertex AIâs tools, so you get a bespoke model without the heavy lifting of full training . Google Vertex AI provides tuning tools that let you _customize large language models (LLMs) for your applications_ , often with just a few hundred examples or even just by specifying rules/prompt examples.

The integration of generative AI into Vertex AI is a recent development and a game-changer for developers and businesses. For instance, Googleâs **Gemini models** (which are multimodal generative AI models) can be accessed through Vertex AI to generate text, analyze images, or even write code. This is part of Google Cloudâs effort to bring **Generative AI** capabilities to enterprises in a safe and scalable way. Instead of calling some external AI service, you use Vertex AIâs endpoints and get the power of models like PaLM 2, Codey (for code completion), Imagen, etc., with enterprise-grade security and governance.

To illustrate the impact: **Kraft Heinz** â yes, the global food company â [leveraged Googleâs generative models](https://cloud.google.com/blog/products/ai-machine-learning/expanding-generative-media-for-enterprise-on-vertex-ai#:~:text=Enablement%2C%20L%E2%80%99Oreal%20Groupe-,Kraft%20Heinz%3A%C2%A0,-Kraft%20Heinz%E2%80%99s%20Tastemaker) (Imagen and a video model called Veo) via Vertex AI to radically speed up their marketing creative process. According to Google Cloud, _Kraft Heinz is using Googleâs media generation models on Vertex AI, speeding up campaign creation from eight weeks to eight hours_. This 8-weeks-to-8-hours leap shows how accessing pre-trained generative models can unlock agility; what once took entire design teams and multiple iterations can now be done in a workday, allowing more experiments and faster go-to-market for campaigns.

Another important point is that **Model Garden isnât limited to Googleâs own models**. It also features open-source models (like Stable Diffusion for images or various Hugging Face models) and partner solutions, all **scanned and vetted for security by Google**. When you deploy an open-source model from Model Garden, Vertex AI handles the serving infrastructure and even vulnerability scanning of the model artifacts , so you can trust that the model wonât introduce security risks. Model Garden essentially centralizes model governance â for example, an admin can set an organization policy to allow or block usage of certain third-party models.

## **Vertex AI Agent Builder**

![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/684abcadf7f05cf27268af1d_agent-builder-overview.png)

Image Source: <https://cloud.google.com/>

If the Model Garden provides individual AI models, Agent Builder helps you orchestrate _entire fleets of AI agents_ to accomplish complex tasks. But what exactly is an âAI agentâ in this context? An AI agent typically refers to a program that can **autonomously perform actions or tasks by combining AI models with reasoning and tool usage** â for example, a customer service chatbot that can answer questions (using an LLM) and also fetch data from your databases or trigger workflows.

**Vertex AI Agent Builder** is a suite of features designed to make it easier to build, test, and deploy these kinds of intelligent agents on Google Cloud. Google describes it as helping _âturn your processes into multi-agent experiencesâ_ by building on what you already have without disruption. In practical terms, Agent Builder provides several components:

  * **Agent Development Kit (ADK):** This is an open-source framework that simplifies creating multi-agent systems. With the ADK, you can define how agents should behave, what tools or data sources they can use, and how they interact. Google boasts that you can build production-ready agents in under 100 lines of code using ADK. It provides guardrails and orchestration logic so that even if you have multiple agents (say, one agent handling user conversation, another doing calculations, another pulling knowledge base info), they can coordinate effectively. It even supports _bi-directional streaming_ , meaning agents can have live conversations (with audio/video) if needed.
  * **Agent Garden:** This is like a library of ready-made agents and tools. If ADK is your toolbox for building agents, **Agent Garden** is the catalog of blueprints and components you can draw from. For example, you might find sample agents for common tasks (a FAQ bot, a shopping assistant, etc.) or connectors (tools) that let an agent use Google Search, databases, or other services. Agent Garden is there to accelerate development â you donât have to start every agent from scratch.
  * **Agent Tools and Integrations:** Agents often need to access external information or perform actions (think of an agent that can look up product inventory, or call an external API). Vertex AI Agent Builder comes with a collection of **built-in tools** like the ability to do web searches, use Vertex AI itself (yes, agents can call other Vertex AI models), execute code, or perform **retrieval-augmented generation (RAG)** from your documents. It also integrates with **Google Cloudâs Apigee API hub and over 100 enterprise applications through connectors**. This means your agent can, for instance, retrieve customer info from a CRM or trigger a workflow in an ERP system if those are connected. Essentially, Agent Builder is mindful that enterprise AI agents must work with enterprise data â so it provides the plumbing to connect AI brains (LLMs) with business systems (via APIs, connectors, etc.).
  * **Agent Engine:** Once youâve built an agent (or a set of agents), you need to run them reliably. The **Vertex AI Agent Engine** is a fully managed runtime to deploy and scale your agents. You can think of it as a specialized hosting service for AI agents. It handles the concurrency, state management (short-term and long-term memory for conversations), and monitoring of agents in production. The Agent Engine also provides evaluation and tracing tools â so you can **monitor how your agent is performing, see the steps itâs taking, and refine its behavior over time**. For example, if an agent is supposed to follow certain business rules, the tracing capability lets you audit its decisions and ensure compliance.



![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/684abcbd75b0d2706e2ebbf2_build-app.png)

Image Source: <https://cloud.google.com/>

Vertex AI Agent Builder is Googleâs streamlined solution for building generative AI agents that can take action, not just chat. It empowers developers to quickly create sophisticated applicationsâlike virtual assistants or process automation botsâwithout stitching together multiple tools or custom infrastructure. For example, you can build an e-commerce support agent that uses LLMs to understand questions, taps Google Search or your database for answers, and manages the conversation flowâall with ready-made components from Agent Garden.

Notably, Agent Builder is open and flexible: it supports industry standards like the Agent2Agent (A2A) protocol for interoperability and lets you use non-Google models or frameworks. This open approach helps organizations avoid vendor lock-in and build agents that fit their unique needs.

## **Vertex AI Pricing â How Costs Are Managed**

No discussion of Vertex AI would be complete without addressing **Vertex AI pricing**. After all, when adopting any cloud service, understanding the cost structure is crucial for both developers and decision-makers. The good news is that **Google Vertex AI pricing is a pay-as-you-go model** , meaning you **pay only for what you use with no upfront commitments or lock-in**. This aligns with general Google Cloud pricing principles and makes it easier to start small and scale up.

Hereâs a breakdown of how pricing works across Vertex AIâs components (based on official Google Cloud pricing documentation):

  * **Training Costs:** If you use Vertex AI to train models (either AutoML or custom training), youâll be billed for the compute resources (CPU, GPU, TPU) and time consumed during training. Vertex AI offers predefined machine types for AutoML training jobs, each with an hourly rate. For example, training an AutoML image classification model might cost around $3.46 per node-hour on a standard machine type. The exact cost scales with the complexity â e.g., training a large vision model or a BigQuery ML model could use more resources. Importantly, **thereâs no minimum charge** for training jobs â usage is billed in 30-second increments. If a training job only runs for 10 minutes, you pay for 10 minutes (plus a 30-second rounding). And if a training job fails due to a platform issue (not user error), Google doesnât charge you for that run.



> _Tip:_ You can set budget alerts or use [Googleâs pricing calculator](https://cloud.google.com/products/calculator?hl=en) to estimate these costs before running huge jobs.

  * **Deployment & Online Prediction Costs:** When you deploy a model to an endpoint for real-time predictions, you will incur charges for the **nodes (VMs) running that endpoint**. Essentially, youâre paying for the serving infrastructure by the hour. The price per hour depends on the machine type and region. For example, an n1-standard-4 (4 CPU, 15 GB RAM) in US regions might be on the order of ~$0.17 per node-hour for serving. If you scale your endpoint to multiple nodes (for handling high traffic or for high availability), the cost multiplies accordingly. One thing to note: unlike some legacy systems, **Vertex AI endpoints do not auto-scale to zero** when idle â if you have a model deployed, at least one node is always up (and charged) unless you manually turn it off. So, itâs good practice to **undeploy models that youâre not actively using** to avoid unnecessary charges. Google has improved cost flexibility by allowing **model co-hosting** (deploying multiple models to one shared node) to optimize utilization, and offering an **optimized TensorFlow runtime** that can reduce serving costs for TF models.
  * **Batch Prediction Costs:** For batch inference jobs, pricing is typically based on the compute time and resources used to process the batch. Vertex AI might spin up temporary workers to read your data, run the model on each input, and write outputs. The cost can be thought of similarly to training costs (since under the hood itâs running a job), but sometimes itâs simplified to a per-instance or per-1000 prediction charge for certain AutoML models. For example, AutoML video model batch predictions are priced per node-hour used, whereas AutoML text might be priced per 1000 text records processed. Always check the latest pricing page for specifics, as the numbers can vary by model type and are updated.
  * **Generative AI (Foundation Model) Usage:** Using Googleâs code generation models via Vertex AI comes with a usage-based pricing model. Typically, youâre billed according to the amount of data processedâspecifically, the number of characters in your prompts (input) and the responses generated (output). Batch discounts may apply for higher volumes, but standard rates are used by default. The key takeaway is that your costs scale with both the frequency and size of your code generation requests, giving you flexibility and predictability in managing your spend
  * **Vertex AI Workbench and Notebooks:** Managed notebooks (Vertex AI Workbench) are charged by the underlying VMâs price per hour, plus any attached GPU if you use one. For example, an enterprise AI notebook with certain specs might cost a predictable hourly rate (similar to renting a VM of that size). The convenience is you get a pre-configured environment; the trade-off is youâre paying for that compute continuously while the notebook instance is running. Thereâs a free tier for some lightweight notebook usage on Google Cloud, but advanced usage will be billable.
  * **Other Services:** Tools like **Vertex AI Feature Store** or **Model Monitoring** have associated costs usually based on data storage and processing. Feature Store charges for storage of feature data and for online retrievals (with prices per 100K reads in the fractions of a cent). Model Monitoring and pipelines might incur small charges for the resources they use (e.g., a continuous evaluation job running on a schedule).



Vertex AIâs pricing is transparent and usage-based, letting you pay only for what you consumeâwhether thatâs compute hours, storage, or data processing. There are no extra licensing fees just for enabling Vertex AI; costs only accrue when you actually run jobs like training, predictions, or deploying models Google provides a pricing calculator and detailed SKUs to help you estimate expenses in advance, and new users get $300 in free credits plus some free tier usage to experiment at no cost.

To control spend, monitor your usage closelyâespecially with large models or big datasets, as costs can scale quickly. Vertex AIâs managed services can also help optimize costs by auto-scaling endpoints and using spot instances for cheaper batch processing if enabled. You remain in control by choosing smaller machine types, setting usage limits, or throttling jobs to fit your budget.

In short, Vertex AI offers flexible, granular pricing that scales with your needsâfrom small experiments to large-scale deployments. By understanding which activities incur costs and leveraging built-in cost controls, you can keep your ML projects cost-effective on Google Cloud.

## **Monitor Your Vertex AI Spend Spend with Cloudchipr**

![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/684abcd22cf9316120bb5779_image%20\(82\).png)

Launching your Vertex AI projects is just the startâactively managing cloud spend is crucial for staying on budget. Cloudchipr provides an intuitive platform that delivers multi-cloud cost visibility, helping you monitor your Vertex AI usage, eliminate waste, and optimize resources across AWS, Azure, and GCP.

### **Key Features of Cloudchipr**

â[**Automated Resource Management:**](https://cloudchipr.com/automations)

Easily identify and eliminate idle or underused resources with no-code automation workflows. This ensures you minimize unnecessary spending while keeping your cloud environment efficient.

[**Rightsizing Recommendations:**](https://cloudchipr.com/recommendations)

Receive actionable, data-backed advice on the best instance sizes, storage setups, and compute resources. This enables you to achieve optimal performance without exceeding your budget.

[**Commitments Tracking:**](https://cloudchipr.com/commitments)

Keep track of your Reserved Instances and Savings Plans to maximize their use.

[**Live Usage & Management:**](https://cloudchipr.com/live-usage-and-mgmt)

Monitor real-time usage and performance metrics across AWS, Azure, and GCP. Quickly identify inefficiencies and make proactive adjustments, enhancing your infrastructure.

[**DevOps as a Service:**](https://cloudchipr.com/devops-services)

Take advantage of Cloudchiprâs on-demand, certified DevOps team that eliminates the hiring hassles and off-boarding worries. This service provides accelerated Day 1 setup through infrastructure as code, automated deployment pipelines, and robust monitoring. On Day 2, it ensures continuous operation with 24/7 support, proactive incident management, and tailored solutions to suit your organizationâs unique needs. Integrating this service means you get the expertise needed to optimize not only your cloud costs but also your overall operational agility and resilience.

> Experience the advantages of integrated multi-cloud management and proactive cost optimization by signing up for a **14-day free trial** today, no hidden charges, no commitments.

## **Conclusion â A Human-Centric AI Platform**

Vertex AI streamlines machine learning for organizations by unifying the entire workflow on a single, accessible platform. It brings together everyone from data scientists to business analysts, making collaboration and production deployment much simpler. With tight integration across Google Cloud services, Vertex AI ensures your AI projects are connected to your real business data and processes, not siloed experiments.

The platform stands out for its comprehensive toolset, support for both pre-trained and custom models, and open yet managed approachâletting you move faster without getting bogged down in infrastructure. Vertex AIâs transparent pricing and enterprise-grade security make it a practical choice for businesses ready to scale AI, while its usability means you donât need to be an expert to get started.

Ultimately, Vertex AI is about making advanced AI accessible and actionable for real teams and real goals, allowing you to focus on solving problems while Google handles the complexity.

Share this article:

24/7 Cloud Optimization and Real Time Observability

Book a DemoSchedule now

Subscribe to our newsletter to get our latest updates!

Thank you!

Your submission has been received!

Oops! Something went wrong while submitting the form.

Related articles

[](/blog/gemini-code-assist)

![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/68e3c678a5aa472cddade27a_Gemini%20Code%20Assist.png)

Gemini Code Assist: What It Does, How It Works, and What It Costs

October 6, 2025

10

min read

[](/blog/dataproc)

![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/68da2d645313e51b91fa3ae3_image%20\(128\).png)

Demystifying Google Cloud Dataproc in 2025: The Practical Guide

September 29, 2025

8

min read

[](/blog/what-is-dataplex)

![](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/68d3bffb0c39b2551fff9cb4_image%20\(126\).png)

What Is Dataplex? A Google Cloud Dataplex Overview

September 24, 2025

7

min read

![](https://px.ads.linkedin.com/collect/?pid=7464482&fmt=gif)
[Sitemap](/sitemap/sitemap.xml)

[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb1f457cd7d0b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)

Sign up

[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40ironhack%2Fwhat-is-vertex-ai-b1f457cd7d0b&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)

[Medium Logo](/?source=post_page---top_nav_layout_nav-----------------------------------------)

[Write](/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)

[Search](/search?source=post_page---top_nav_layout_nav-----------------------------------------)

Sign up

[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40ironhack%2Fwhat-is-vertex-ai-b1f457cd7d0b&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)

![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)

# What is Vertex AI?

[![Ironhack](https://miro.medium.com/v2/resize:fill:64:64/1*R4stmAmUMIwzP2yjrR82Fw.png)](/@ironhack?source=post_page---byline--b1f457cd7d0b---------------------------------------)

[Ironhack](/@ironhack?source=post_page---byline--b1f457cd7d0b---------------------------------------)

6 min read

·

Dec 13, 2024

[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fb1f457cd7d0b&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40ironhack%2Fwhat-is-vertex-ai-b1f457cd7d0b&user=Ironhack&userId=1ff093a3da32&source=---header_actions--b1f457cd7d0b---------------------clap_footer------------------)

\--

[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb1f457cd7d0b&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40ironhack%2Fwhat-is-vertex-ai-b1f457cd7d0b&source=---header_actions--b1f457cd7d0b---------------------bookmark_footer------------------)

Listen

Share

**Unlock the Power of Machine Learning with Google’s Scalable AI Platform.**

Press enter or click to view image in full size

Hey there! 👋 The article you’re about to read was originally posted to The Ironhack Blog, where you can enjoy even more free tech knowhow and get inspired to launch your career in tech!

The digital world is rapidly evolving, with AI models and technological advances changing the way organizations and businesses function and operate. Hence, there are far too many AI tools and solutions to choose from, which can become complex for businesses to navigate their work efficiently– allowing Vertex AI to come and save the day!

Vertex AI is a powerful and versatile platform that enables you to train and deploy [machine learning](https://www.ironhack.com/es/blog/machine-learning-what-is-it) models and AI applications, combining data engineering, data science, and machine learning engineering workflows to facilitate collaboration.

Vertex AI is specifically designed by Google Cloud, which collects a range of tools and services that [deploy AI models](https://www.ironhack.com/us/blog/ai-model-deployment-101-from-prototype-to-production-in-simple-steps)into the real world without having to multitask with different tools. This simplifies the entire process of AI development, making it easier to build, test, deploy, and manage AI models with the integration of other [Google cloud services](https://www.ironhack.com/us/blog/introduction-to-cloud-infrastructure-building-scalable-solutions?utm_source=medium&utm_medium=organic&utm_campaign=24-12_GLO_glo_GLO_apps_medium_&utm_content=organic-content).

Yet what makes Vertex AI? How is it able to execute its function? Why is it beneficial in our tech-oriented world? Let’s dive into what Vertex AI is all about!

## Vertex AI Features

Vertex AI contains features and tools that assist with the machine learning workflow, that includes data preparation, model training, model evaluation, model deployment, model monitoring, and model explainability.

**Model monitoring and performance analysis**

Model monitoring ensures that the machine learning models are performing as expected, by enabling routine checks to monitor and track various performance metrics. This **helps to identify and address potential issues, ensuring models maintain high quality and reliability.**

The model’s performance analysis tools measure essential metrics such as accuracy, precision, and assessing the effectiveness of the model.

**TensorBoard**

Tensorboard is a visualization tool used by [machine learning models](https://www.ironhack.com/us/blog/bridging-the-gap-between-machine-learning-models-and-human-interpretability), offering graphical representations of the model’s performance and its real-time monitoring capabilities. The benefit of this is that it helps users visualize the model’s behavior, which simplifies the identification of issues, allowing for an understanding of how changes can impact performance. Overall **this improves the model’s ability, enhancing its efficiency.**

**AutoML**

AutoML is a feature that automates the process of [training and fine tuning](https://www.ironhack.com/us/blog/internal-knowledge-processing-with-retrieved-augmented-generation) the model for a variety of data types and tasks. This simplifies model development, as it reduces reliance on deep technical expertise. This feature assists those with little to no experience who are eager to build their own customized machine learning model.

**Generative AI**

Utilizing advanced models developed by Google, [Generative AI](https://www.ironhack.com/us/blog/generative-ai-what-it-is-and-how-to-use-it?utm_source=medium&utm_medium=organic&utm_campaign=24-12_GLO_glo_GLO_apps_medium_&utm_content=organic-content) deploys various types of content that include text, images, code, and speech. This is specifically **important in personalization, as models using this feature can meet and align with your needs, visions, and objectives** , which can be integrated into your applications. This enables AI solutions to become more dynamic and beneficial to the user.

## Architecture of Vertex AI

The importance of such a multifaceted platform is how it is designed and built, being made out of many features that add to its functionality and efficiency.

## Model garden

Toolkit that provides pre-trained models with different functions that include tabular [data analysis,](https://www.ironhack.com/us/blog/data-analytics-in-2024-emerging-technologies-and-applications) computer vision, and natural language processing. In being a collection of tools and ready-made machine learning models, it covers a range of tasks such as recognising images, understanding text, and analyzing data.

There are three classes of model types in the model garden:

  * First party models
  * Open source models
  * Third party models



The main benefit of utilizing models from the model garden is the potential to save significant costs, by avoiding the cost of training foundation models from scratch. Additionally, it allows users to quickly deploy machine learning models in an environment based on production– which is done through the integration of other Google cloud platform services.

## AI platform features

Extensions are designed to connect trained models with real-time data, with the help of various sources such as [APIs.](https://www.ironhack.com/gb/blog/what-is-an-api?utm_source=medium&utm_medium=organic&utm_campaign=24-12_GLO_glo_GLO_apps_medium_&utm_content=organic-content)This feature is specifically important for chatbots, search engines, and automated workflows. Extensions function to improve the model’s performance by providing fresh data and producing valuable features and insights.

Connectors is the integration of Vertex AI with other Google data cloud services, such as BigQuery, Cloud Storage, Dataflow, etc. These integrations simplify the process of preparing and analyzing large amounts of data, allowing datasets to be manageable and accessible.

Prompt refers to any form of text, question, coding or information that prompts AI to respond. This feature allows responses to kickstart development. On the other hand, grounding is a feature that assists with citations and evidence, to back up the information given in the response by prompt.

## Search and Conversation in Vertex AI

Search feature helps data scientists and developers build start-to-finish search applications, by using Vertex AI’s training pipelines, they train search models then deploy them as search endpoints. Search models understand natural language inquiries, recover relevant results from data sources and organize the results with relevance.

Conversation feature enables developers to build AI-powered [conversational chatbots](https://www.ironhack.com/us/blog/what-s-next-for-conversational-ai) and interfaces. Also by using vertex AI’s training pipelines, they train conversation models then deploy them as endpoints for real-time conclusion. This feature provides pre-trained models and templates, which are based on conversational goals that can be customized and extended.

## Benefits of Vertex AI

  * One platform for all tasks under AI and machine learning
  * Seamless model deployment
  * It contains a fully managed infrastructure
  * Advanced AI features
  * Cost-effective
  * Scalable
  * Rapid go-to-market (GTM)



## Why is Vertex AI Important?

  * **Scalability** : Vertex AI’s scalability enables it to support diverse AI applications, regardless of their size, fitting any need or objective.
  * **Accelerating model development and deployment** : AI solutions that automate the development process enables accessibility to deploy high-quality models.
  * **Increasing speed:** Within automating the model development process, chatbots are trained and deployed faster, which makes it easier and faster to create AI apps.
  * **Adaptable in hybrid environments:** Vertex AI’s integration into a multi-cloud infrastructure allows organizations to utilize AI with multiple providers making it highly adaptable, allowing businesses to align their AI initiatives with their present tech resources.
  * **Consistency:** Vertex AI’s maintenance across the board enables constant quality output, minimizing the potentiality of errors.



In its essence, Vertex AI allows organizations to truly utilize the power of machine learning without the need to rely on traditional resources and expertise. As a unified, accessible, and scalable platform, Vertex AI is a crucial tool for organizations to leverage AI in order to drive innovation and continuous improvement to remain competitive in a rapidly changing market.

If you are an AI enthusiast or someone who is interested in machine learning, [Ironhack’s Data Science and Machine Learning Bootcamp](https://www.ironhack.com/es/data-science-machine-learning/remoto) can guide you with the right tools like Google’s Vertex AI and skills for you to build, deploy, scale AI models. Enroll now and transform your future!

**About the author:** Tala Sammar is the Events and Content Marketing Intern at Ironhack based in Madrid, where she contributes to creating engaging content, assisting with blogs and events. With a background in International Relations**,** she is passionate about social justice, humanitarian development, and writing. Moreover**,** she is always expressing herself artistically, seeking to unlock layers of creativity. Her strong sense of empathy, specifically within the marketing field, is one of her greatest strengths.[ Catch her on LinkedIn here.](https://www.linkedin.com/in/tala-sammar-920b9b216/)

If you enjoyed that, wait till you see what our [Artificial Intelligence Engineering Bootcamp](https://www.ironhack.com/gb/artificial-intelligence/remote?utm_source=medium&utm_medium=organic&utm_campaign=24-12_GLO_glo_GLO_apps_medium_&utm_content=organic-content) can do for you! It combines cutting-edge training in AI and machine learning technologies (from Python and deep learning to data engineering) with personalized Career Services to guide you through the job search. Step into the rapidly growing AI industry, land your first role in tech, and build a career shaping the future!

[Vertex AI](/tag/vertex-ai?source=post_page-----b1f457cd7d0b---------------------------------------)

[AI](/tag/ai?source=post_page-----b1f457cd7d0b---------------------------------------)

[Artificial Intelligence](/tag/artificial-intelligence?source=post_page-----b1f457cd7d0b---------------------------------------)

[Machine Learning](/tag/machine-learning?source=post_page-----b1f457cd7d0b---------------------------------------)

[Ironhack](/tag/ironhack?source=post_page-----b1f457cd7d0b---------------------------------------)

[![Ironhack](https://miro.medium.com/v2/resize:fill:96:96/1*R4stmAmUMIwzP2yjrR82Fw.png)](/@ironhack?source=post_page---post_author_info--b1f457cd7d0b---------------------------------------)

[![Ironhack](https://miro.medium.com/v2/resize:fill:128:128/1*R4stmAmUMIwzP2yjrR82Fw.png)](/@ironhack?source=post_page---post_author_info--b1f457cd7d0b---------------------------------------)

## [Written by Ironhack](/@ironhack?source=post_page---post_author_info--b1f457cd7d0b---------------------------------------)

[3.8K followers](/@ironhack/followers?source=post_page---post_author_info--b1f457cd7d0b---------------------------------------)

·[753 following](/@ironhack/following?source=post_page---post_author_info--b1f457cd7d0b---------------------------------------)

Ironhack is a global tech school in Miami, Madrid, Barcelona, Paris, Lisbon & Berlin offering courses in WebDev, UX/UI, Data Analytics & Cybersecurity

## No responses yet

[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--b1f457cd7d0b---------------------------------------)

[Help](https://help.medium.com/hc/en-us?source=post_page-----b1f457cd7d0b---------------------------------------)

[Status](https://status.medium.com/?source=post_page-----b1f457cd7d0b---------------------------------------)

[About](/about?autoplay=1&source=post_page-----b1f457cd7d0b---------------------------------------)

[Careers](/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----b1f457cd7d0b---------------------------------------)

[Press](mailto:pressinquiries@medium.com)

[Blog](https://blog.medium.com/?source=post_page-----b1f457cd7d0b---------------------------------------)

[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b1f457cd7d0b---------------------------------------)

[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----b1f457cd7d0b---------------------------------------)

[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b1f457cd7d0b---------------------------------------)

[Text to speech](https://speechify.com/medium?source=post_page-----b1f457cd7d0b---------------------------------------)
